<html>
<head>
<title>coo.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
coo.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2021 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">&quot;&quot;&quot;COO (coordinate format) matrix object and associated primitives.&quot;&quot;&quot;</span>
<span class="s3">from </span><span class="s1">__future__ </span><span class="s3">import </span><span class="s1">annotations</span>

<span class="s3">from </span><span class="s1">functools </span><span class="s3">import </span><span class="s1">partial</span>
<span class="s3">import </span><span class="s1">operator</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">Any</span><span class="s3">, </span><span class="s1">Dict</span><span class="s3">, </span><span class="s1">NamedTuple</span><span class="s3">, </span><span class="s1">Optional</span><span class="s3">, </span><span class="s1">Sequence</span><span class="s3">, </span><span class="s1">Tuple</span>
<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">import </span><span class="s1">jax</span>
<span class="s3">from </span><span class="s1">jax </span><span class="s3">import </span><span class="s1">lax</span>
<span class="s3">from </span><span class="s1">jax.interpreters </span><span class="s3">import </span><span class="s1">mlir</span>
<span class="s3">from </span><span class="s1">jax.experimental.sparse._base </span><span class="s3">import </span><span class="s1">JAXSparse</span>
<span class="s3">from </span><span class="s1">jax.experimental.sparse.util </span><span class="s3">import </span><span class="s1">_coo_extract</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning</span>
<span class="s3">from </span><span class="s1">jax </span><span class="s3">import </span><span class="s1">tree_util</span>
<span class="s3">from </span><span class="s1">jax._src </span><span class="s3">import </span><span class="s1">core</span>
<span class="s3">from </span><span class="s1">jax._src </span><span class="s3">import </span><span class="s1">dispatch</span>
<span class="s3">from </span><span class="s1">jax._src.interpreters </span><span class="s3">import </span><span class="s1">ad</span>
<span class="s3">from </span><span class="s1">jax._src.lax.lax </span><span class="s3">import </span><span class="s1">_const</span>
<span class="s3">from </span><span class="s1">jax._src.lib.mlir.dialects </span><span class="s3">import </span><span class="s1">hlo</span>
<span class="s3">from </span><span class="s1">jax._src.lib </span><span class="s3">import </span><span class="s1">gpu_sparse</span>
<span class="s3">from </span><span class="s1">jax._src.numpy.util </span><span class="s3">import </span><span class="s1">promote_dtypes</span>
<span class="s3">from </span><span class="s1">jax._src.typing </span><span class="s3">import </span><span class="s1">Array</span><span class="s3">, </span><span class="s1">ArrayLike</span><span class="s3">, </span><span class="s1">DTypeLike</span>
<span class="s3">import </span><span class="s1">jax.numpy </span><span class="s3">as </span><span class="s1">jnp</span>


<span class="s1">Dtype = Any</span>
<span class="s1">Shape = Tuple[int</span><span class="s3">, </span><span class="s1">...]</span>

<span class="s3">class </span><span class="s1">COOInfo(NamedTuple):</span>
  <span class="s1">shape: Shape</span>
  <span class="s1">rows_sorted: bool = </span><span class="s3">False</span>
  <span class="s1">cols_sorted: bool = </span><span class="s3">False</span>


<span class="s1">@tree_util.register_pytree_node_class</span>
<span class="s3">class </span><span class="s1">COO(JAXSparse):</span>
  <span class="s2">&quot;&quot;&quot;Experimental COO matrix implemented in JAX. 
 
  Note: this class has minimal compatibility with JAX transforms such as 
  grad and autodiff, and offers very little functionality. In general you 
  should prefer :class:`jax.experimental.sparse.BCOO`. 
 
  Additionally, there are known failures in the case that `nse` is larger 
  than the true number of nonzeros in the represented matrix. This situation 
  is better handled in BCOO. 
  &quot;&quot;&quot;</span>
  <span class="s1">data: jax.Array</span>
  <span class="s1">row: jax.Array</span>
  <span class="s1">col: jax.Array</span>
  <span class="s1">shape: Tuple[int</span><span class="s3">, </span><span class="s1">int]</span>
  <span class="s1">nse = property(</span><span class="s3">lambda </span><span class="s1">self: self.data.size)</span>
  <span class="s1">dtype = property(</span><span class="s3">lambda </span><span class="s1">self: self.data.dtype)</span>
  <span class="s1">_info = property(</span><span class="s3">lambda </span><span class="s1">self: COOInfo(</span>
      <span class="s1">shape=self.shape</span><span class="s3">, </span><span class="s1">rows_sorted=self._rows_sorted</span><span class="s3">,</span>
      <span class="s1">cols_sorted=self._cols_sorted))</span>
  <span class="s1">_bufs = property(</span><span class="s3">lambda </span><span class="s1">self: (self.data</span><span class="s3">, </span><span class="s1">self.row</span><span class="s3">, </span><span class="s1">self.col))</span>
  <span class="s1">_rows_sorted: bool</span>
  <span class="s1">_cols_sorted: bool</span>

  <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">args: Tuple[Array</span><span class="s3">, </span><span class="s1">Array</span><span class="s3">, </span><span class="s1">Array]</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape: Shape</span><span class="s3">,</span>
               <span class="s1">rows_sorted: bool = </span><span class="s3">False, </span><span class="s1">cols_sorted: bool = </span><span class="s3">False</span><span class="s1">):</span>
    <span class="s1">self.data</span><span class="s3">, </span><span class="s1">self.row</span><span class="s3">, </span><span class="s1">self.col = map(jnp.asarray</span><span class="s3">, </span><span class="s1">args)</span>
    <span class="s1">self._rows_sorted = rows_sorted</span>
    <span class="s1">self._cols_sorted = cols_sorted</span>
    <span class="s1">super().__init__(args</span><span class="s3">, </span><span class="s1">shape=shape)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">fromdense(cls</span><span class="s3">, </span><span class="s1">mat: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse: Optional[int] = </span><span class="s3">None, </span><span class="s1">index_dtype: DTypeLike = np.int32) -&gt; COO:</span>
    <span class="s3">return </span><span class="s1">coo_fromdense(mat</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>

  <span class="s3">def </span><span class="s1">_sort_indices(self) -&gt; COO:</span>
    <span class="s2">&quot;&quot;&quot;Return a copy of the COO matrix with sorted indices. 
 
    The matrix is sorted by row indices and column indices per row. 
    If self._rows_sorted is True, this returns ``self`` without a copy. 
    &quot;&quot;&quot;</span>
    <span class="s0"># TODO(jakevdp): would be benefit from lowering this to cusparse sort_rows utility?</span>
    <span class="s3">if </span><span class="s1">self._rows_sorted:</span>
      <span class="s3">return </span><span class="s1">self</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">data = lax.sort((self.row</span><span class="s3">, </span><span class="s1">self.col</span><span class="s3">, </span><span class="s1">self.data)</span><span class="s3">, </span><span class="s1">num_keys=</span><span class="s4">2</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">self.__class__((data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col)</span><span class="s3">, </span><span class="s1">shape=self.shape</span><span class="s3">,</span>
                          <span class="s1">rows_sorted=</span><span class="s3">True</span><span class="s1">)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">_empty(cls</span><span class="s3">, </span><span class="s1">shape: Sequence[int]</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">dtype: Optional[DTypeLike] = </span><span class="s3">None,</span>
             <span class="s1">index_dtype: DTypeLike = </span><span class="s5">'int32'</span><span class="s1">) -&gt; COO:</span>
    <span class="s2">&quot;&quot;&quot;Create an empty COO instance. Public method is sparse.empty().&quot;&quot;&quot;</span>
    <span class="s1">shape = tuple(shape)</span>
    <span class="s3">if </span><span class="s1">len(shape) != </span><span class="s4">2</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;COO must have ndim=2; got </span><span class="s3">{</span><span class="s1">shape=</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
    <span class="s1">data = jnp.empty(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">dtype)</span>
    <span class="s1">row = col = jnp.empty(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">index_dtype)</span>
    <span class="s3">return </span><span class="s1">cls((data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col)</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">rows_sorted=</span><span class="s3">True,</span>
               <span class="s1">cols_sorted=</span><span class="s3">True</span><span class="s1">)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">_eye(cls</span><span class="s3">, </span><span class="s1">N: int</span><span class="s3">, </span><span class="s1">M: int</span><span class="s3">, </span><span class="s1">k: int</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">dtype: Optional[DTypeLike] = </span><span class="s3">None,</span>
           <span class="s1">index_dtype: DTypeLike = </span><span class="s5">'int32'</span><span class="s1">) -&gt; COO:</span>
    <span class="s3">if </span><span class="s1">k &gt; </span><span class="s4">0</span><span class="s1">:</span>
      <span class="s1">diag_size = min(N</span><span class="s3">, </span><span class="s1">M - k)</span>
    <span class="s3">else</span><span class="s1">:</span>
      <span class="s1">diag_size = min(N + k</span><span class="s3">, </span><span class="s1">M)</span>

    <span class="s3">if </span><span class="s1">diag_size &lt;= </span><span class="s4">0</span><span class="s1">:</span>
      <span class="s0"># if k is out of range, return an empty matrix.</span>
      <span class="s3">return </span><span class="s1">cls._empty((N</span><span class="s3">, </span><span class="s1">M)</span><span class="s3">, </span><span class="s1">dtype=dtype</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>

    <span class="s1">data = jnp.ones(diag_size</span><span class="s3">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">idx = jnp.arange(diag_size</span><span class="s3">, </span><span class="s1">dtype=index_dtype)</span>
    <span class="s1">zero = _const(idx</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">k = _const(idx</span><span class="s3">, </span><span class="s1">k)</span>
    <span class="s1">row = lax.sub(idx</span><span class="s3">, </span><span class="s1">lax.cond(k &gt;= </span><span class="s4">0</span><span class="s3">, lambda</span><span class="s1">: zero</span><span class="s3">, lambda</span><span class="s1">: k))</span>
    <span class="s1">col = lax.add(idx</span><span class="s3">, </span><span class="s1">lax.cond(k &lt;= </span><span class="s4">0</span><span class="s3">, lambda</span><span class="s1">: zero</span><span class="s3">, lambda</span><span class="s1">: k))</span>
    <span class="s3">return </span><span class="s1">cls((data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col)</span><span class="s3">, </span><span class="s1">shape=(N</span><span class="s3">, </span><span class="s1">M)</span><span class="s3">, </span><span class="s1">rows_sorted=</span><span class="s3">True, </span><span class="s1">cols_sorted=</span><span class="s3">True</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">todense(self) -&gt; Array:</span>
    <span class="s3">return </span><span class="s1">coo_todense(self)</span>

  <span class="s3">def </span><span class="s1">transpose(self</span><span class="s3">, </span><span class="s1">axes: Optional[Tuple[int</span><span class="s3">, </span><span class="s1">...]] = </span><span class="s3">None</span><span class="s1">) -&gt; COO:</span>
    <span class="s3">if </span><span class="s1">axes </span><span class="s3">is not None</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">&quot;axes argument to transpose()&quot;</span><span class="s1">)</span>
    <span class="s3">return </span><span class="s1">COO((self.data</span><span class="s3">, </span><span class="s1">self.col</span><span class="s3">, </span><span class="s1">self.row)</span><span class="s3">, </span><span class="s1">shape=self.shape[::-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">,</span>
               <span class="s1">rows_sorted=self._cols_sorted</span><span class="s3">, </span><span class="s1">cols_sorted=self._rows_sorted)</span>

  <span class="s3">def </span><span class="s1">tree_flatten(self) -&gt; Tuple[Tuple[Array</span><span class="s3">, </span><span class="s1">Array</span><span class="s3">, </span><span class="s1">Array]</span><span class="s3">, </span><span class="s1">Dict[str</span><span class="s3">, </span><span class="s1">Any]]:</span>
    <span class="s3">return </span><span class="s1">(self.data</span><span class="s3">, </span><span class="s1">self.row</span><span class="s3">, </span><span class="s1">self.col)</span><span class="s3">, </span><span class="s1">self._info._asdict()</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">tree_unflatten(cls</span><span class="s3">, </span><span class="s1">aux_data</span><span class="s3">, </span><span class="s1">children):</span>
    <span class="s1">obj = object.__new__(cls)</span>
    <span class="s1">obj.data</span><span class="s3">, </span><span class="s1">obj.row</span><span class="s3">, </span><span class="s1">obj.col = children</span>
    <span class="s3">if </span><span class="s1">aux_data.keys() != {</span><span class="s5">'shape'</span><span class="s3">, </span><span class="s5">'rows_sorted'</span><span class="s3">, </span><span class="s5">'cols_sorted'</span><span class="s1">}:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;COO.tree_unflatten: invalid </span><span class="s3">{</span><span class="s1">aux_data=</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
    <span class="s1">obj.shape = aux_data[</span><span class="s5">'shape'</span><span class="s1">]</span>
    <span class="s1">obj._rows_sorted = aux_data[</span><span class="s5">'rows_sorted'</span><span class="s1">]</span>
    <span class="s1">obj._cols_sorted = aux_data[</span><span class="s5">'cols_sorted'</span><span class="s1">]</span>
    <span class="s3">return </span><span class="s1">obj</span>

  <span class="s3">def </span><span class="s1">__matmul__(self</span><span class="s3">, </span><span class="s1">other: ArrayLike) -&gt; Array:</span>
    <span class="s3">if </span><span class="s1">isinstance(other</span><span class="s3">, </span><span class="s1">JAXSparse):</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">&quot;matmul between two sparse objects.&quot;</span><span class="s1">)</span>
    <span class="s1">other = jnp.asarray(other)</span>
    <span class="s1">data</span><span class="s3">, </span><span class="s1">other = promote_dtypes(self.data</span><span class="s3">, </span><span class="s1">other)</span>
    <span class="s1">self_promoted = COO((data</span><span class="s3">, </span><span class="s1">self.row</span><span class="s3">, </span><span class="s1">self.col)</span><span class="s3">, </span><span class="s1">**self._info._asdict())</span>
    <span class="s3">if </span><span class="s1">other.ndim == </span><span class="s4">1</span><span class="s1">:</span>
      <span class="s3">return </span><span class="s1">coo_matvec(self_promoted</span><span class="s3">, </span><span class="s1">other)</span>
    <span class="s3">elif </span><span class="s1">other.ndim == </span><span class="s4">2</span><span class="s1">:</span>
      <span class="s3">return </span><span class="s1">coo_matmat(self_promoted</span><span class="s3">, </span><span class="s1">other)</span>
    <span class="s3">else</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">f&quot;matmul with object of shape </span><span class="s3">{</span><span class="s1">other.shape</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>

<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># coo_todense</span>

<span class="s1">coo_todense_p = core.Primitive(</span><span class="s5">'coo_todense'</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">coo_todense(mat: COO) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Convert a COO-format sparse matrix to a dense matrix. 
 
  Args: 
    mat : COO matrix 
  Returns: 
    mat_dense: dense version of ``mat`` 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">_coo_todense(mat.data</span><span class="s3">, </span><span class="s1">mat.row</span><span class="s3">, </span><span class="s1">mat.col</span><span class="s3">, </span><span class="s1">spinfo=mat._info)</span>

<span class="s3">def </span><span class="s1">_coo_todense(data: Array</span><span class="s3">, </span><span class="s1">row: Array</span><span class="s3">, </span><span class="s1">col: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo: COOInfo) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Convert CSR-format sparse matrix to a dense matrix. 
 
  Args: 
    data : array of shape ``(nse,)``. 
    row : array of shape ``(nse,)`` 
    col : array of shape ``(nse,)`` and dtype ``row.dtype`` 
    spinfo : COOInfo object containing matrix metadata 
 
  Returns: 
    mat : array with specified shape and dtype matching ``data`` 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">coo_todense_p.bind(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">spinfo=spinfo)</span>

<span class="s3">def </span><span class="s1">_coo_todense_impl(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo):</span>
  <span class="s3">return </span><span class="s1">jnp.zeros(spinfo.shape</span><span class="s3">, </span><span class="s1">data.dtype).at[row</span><span class="s3">, </span><span class="s1">col].add(data)</span>

<span class="s1">@coo_todense_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_coo_todense_abstract_eval(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo):</span>
  <span class="s3">return </span><span class="s1">core.ShapedArray(spinfo.shape</span><span class="s3">, </span><span class="s1">data.dtype)</span>

<span class="s1">_coo_todense_lowering = mlir.lower_fun(</span>
    <span class="s1">_coo_todense_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">False</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_coo_todense_gpu_lowering(coo_todense_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo):</span>
  <span class="s1">data_aval</span><span class="s3">, </span><span class="s1">row_aval</span><span class="s3">, </span><span class="s1">_ = ctx.avals_in</span>
  <span class="s1">dtype = data_aval.dtype</span>
  <span class="s3">if not </span><span class="s1">(np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.floating) </span><span class="s3">or </span><span class="s1">np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.complexfloating)):</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;coo_todense cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_todense_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">spinfo=spinfo)</span>

  <span class="s3">if </span><span class="s1">spinfo.rows_sorted:</span>
    <span class="s1">shape = spinfo.shape</span>
    <span class="s1">transpose = </span><span class="s3">False</span>
  <span class="s3">elif </span><span class="s1">spinfo.cols_sorted:</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = col</span><span class="s3">, </span><span class="s1">row</span>
    <span class="s1">transpose = </span><span class="s3">True</span>
    <span class="s1">shape = spinfo.shape[::-</span><span class="s4">1</span><span class="s1">]</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">warnings.warn(</span><span class="s5">&quot;coo_todense GPU lowering requires matrices with sorted rows or sorted cols. &quot;</span>
                  <span class="s5">&quot;To sort the rows in your matrix, use e.g. mat = mat._sort_indices(). Falling &quot;</span>
                  <span class="s5">&quot;back to the default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_todense_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">spinfo=spinfo)</span>

  <span class="s1">result = coo_todense_hlo(</span>
      <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">data_dtype=dtype</span><span class="s3">, </span><span class="s1">index_dtype=row_aval.dtype)</span>
  <span class="s3">return </span><span class="s1">(</span>
      <span class="s1">[hlo.TransposeOp(result</span><span class="s3">, </span><span class="s1">mlir.dense_int_elements([</span><span class="s4">1</span><span class="s3">, </span><span class="s4">0</span><span class="s1">])).result]</span>
      <span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">[result])</span>


<span class="s3">def </span><span class="s1">_coo_todense_jvp(data_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo):</span>
  <span class="s3">return </span><span class="s1">_coo_todense(data_dot</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">spinfo=spinfo)</span>

<span class="s3">def </span><span class="s1">_coo_todense_transpose(ct</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo):</span>
  <span class="s0"># Note: we assume that transpose has the same sparsity pattern.</span>
  <span class="s0"># Can we check this?</span>
  <span class="s3">assert </span><span class="s1">ad.is_undefined_primal(data)</span>
  <span class="s3">if </span><span class="s1">ad.is_undefined_primal(row) </span><span class="s3">or </span><span class="s1">ad.is_undefined_primal(col):</span>
    <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Cannot transpose with respect to sparse indices&quot;</span><span class="s1">)</span>
  <span class="s3">assert </span><span class="s1">ct.shape == spinfo.shape</span>
  <span class="s3">assert </span><span class="s1">row.aval.dtype == col.aval.dtype</span>
  <span class="s3">assert </span><span class="s1">ct.dtype == data.aval.dtype</span>
  <span class="s3">return </span><span class="s1">_coo_extract(row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">ct)</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span>

<span class="s1">ad.defjvp(coo_todense_p</span><span class="s3">, </span><span class="s1">_coo_todense_jvp</span><span class="s3">, None, None</span><span class="s1">)</span>
<span class="s1">ad.primitive_transposes[coo_todense_p] = _coo_todense_transpose</span>
<span class="s1">mlir.register_lowering(coo_todense_p</span><span class="s3">, </span><span class="s1">_coo_todense_lowering)</span>
<span class="s1">dispatch.simple_impl(coo_todense_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_todense_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_todense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_coo_todense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_todense_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_todense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_coo_todense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>

<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># coo_fromdense</span>

<span class="s1">coo_fromdense_p = core.Primitive(</span><span class="s5">'coo_fromdense'</span><span class="s1">)</span>
<span class="s1">coo_fromdense_p.multiple_results = </span><span class="s3">True</span>

<span class="s3">def </span><span class="s1">coo_fromdense(mat: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse: Optional[int] = </span><span class="s3">None, </span><span class="s1">index_dtype: DTypeLike = jnp.int32) -&gt; COO:</span>
  <span class="s2">&quot;&quot;&quot;Create a COO-format sparse matrix from a dense matrix. 
 
  Args: 
    mat : array to be converted to COO. 
    nse : number of specified entries in ``mat``. If not specified, 
      it will be computed from the input matrix. 
    index_dtype : dtype of sparse indices 
 
  Returns: 
    mat_coo : COO representation of the matrix. 
  &quot;&quot;&quot;</span>
  <span class="s3">if </span><span class="s1">nse </span><span class="s3">is None</span><span class="s1">:</span>
    <span class="s1">nse = int((mat != </span><span class="s4">0</span><span class="s1">).sum())</span>
  <span class="s1">nse_int = core.concrete_or_error(operator.index</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s5">&quot;coo_fromdense nse argument&quot;</span><span class="s1">)</span>
  <span class="s3">return </span><span class="s1">COO(_coo_fromdense(mat</span><span class="s3">, </span><span class="s1">nse=nse_int</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span><span class="s3">,</span>
             <span class="s1">shape=mat.shape</span><span class="s3">, </span><span class="s1">rows_sorted=</span><span class="s3">True</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_coo_fromdense(mat: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse: int</span><span class="s3">, </span><span class="s1">index_dtype: DTypeLike = jnp.int32) -&gt; Tuple[Array</span><span class="s3">, </span><span class="s1">Array</span><span class="s3">, </span><span class="s1">Array]:</span>
  <span class="s2">&quot;&quot;&quot;Create COO-format sparse matrix from a dense matrix. 
 
  Args: 
    mat : array to be converted to COO. 
    nse : number of specified entries in ``mat`` 
    index_dtype : dtype of sparse indices 
 
  Returns: 
    data : array of shape ``(nse,)`` and dtype ``mat.dtype`` 
    row : array of shape ``(nse,)`` and dtype ``index_dtype`` 
    col : array of shape ``(nse,)`` and dtype ``index_dtype`` 
  &quot;&quot;&quot;</span>
  <span class="s1">mat = jnp.asarray(mat)</span>
  <span class="s1">nse = core.concrete_or_error(operator.index</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s5">&quot;nse argument of coo_fromdense()&quot;</span><span class="s1">)</span>
  <span class="s3">return </span><span class="s1">coo_fromdense_p.bind(mat</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>

<span class="s3">def </span><span class="s1">_coo_fromdense_impl(mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">mat = jnp.asarray(mat)</span>
  <span class="s3">assert </span><span class="s1">mat.ndim == </span><span class="s4">2</span>

  <span class="s1">row</span><span class="s3">, </span><span class="s1">col = jnp.nonzero(mat</span><span class="s3">, </span><span class="s1">size=nse)</span>
  <span class="s1">data = mat[row</span><span class="s3">, </span><span class="s1">col]</span>

  <span class="s1">true_nonzeros = jnp.arange(nse) &lt; (mat != </span><span class="s4">0</span><span class="s1">).sum()</span>
  <span class="s1">data = jnp.where(true_nonzeros</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>

  <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row.astype(index_dtype)</span><span class="s3">, </span><span class="s1">col.astype(index_dtype)</span>

<span class="s1">@coo_fromdense_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_coo_fromdense_abstract_eval(mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">data = core.ShapedArray((nse</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">mat.dtype)</span>
  <span class="s1">row = col = core.ShapedArray((nse</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">index_dtype)</span>
  <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span>

<span class="s1">_coo_fromdense_lowering = mlir.lower_fun(</span>
    <span class="s1">_coo_fromdense_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">True</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_coo_fromdense_gpu_lowering(coo_fromdense_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">,</span>
                                <span class="s1">index_dtype):</span>
  <span class="s1">dtype = ctx.avals_in[</span><span class="s4">0</span><span class="s1">].dtype</span>
  <span class="s3">if not </span><span class="s1">(np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.floating) </span><span class="s3">or </span><span class="s1">np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.complexfloating)):</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;coo_fromdense cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_fromdense_lowering(ctx</span><span class="s3">, </span><span class="s1">mat</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col = coo_fromdense_hlo(</span>
      <span class="s1">mat</span><span class="s3">, </span><span class="s1">nnz=nse</span><span class="s3">,</span>
      <span class="s1">data_dtype=dtype</span><span class="s3">,</span>
      <span class="s1">index_dtype=np.dtype(index_dtype)</span><span class="s3">,</span>
      <span class="s1">index_type=mlir.dtype_to_ir_type(np.dtype(index_dtype)))</span>
  <span class="s3">return </span><span class="s1">[data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col]</span>


<span class="s3">def </span><span class="s1">_coo_fromdense_jvp(primals</span><span class="s3">, </span><span class="s1">tangents</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">M</span><span class="s3">, </span><span class="s1">= primals</span>
  <span class="s1">Mdot</span><span class="s3">, </span><span class="s1">= tangents</span>

  <span class="s1">primals_out = _coo_fromdense(M</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col = primals_out</span>

  <span class="s3">if </span><span class="s1">type(Mdot) </span><span class="s3">is </span><span class="s1">ad.Zero:</span>
    <span class="s1">data_dot = ad.Zero.from_value(data)</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">data_dot = _coo_extract(row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">Mdot)</span>

  <span class="s1">tangents_out = (data_dot</span><span class="s3">, </span><span class="s1">ad.Zero.from_value(row)</span><span class="s3">, </span><span class="s1">ad.Zero.from_value(col))</span>

  <span class="s3">return </span><span class="s1">primals_out</span><span class="s3">, </span><span class="s1">tangents_out</span>

<span class="s3">def </span><span class="s1">_coo_fromdense_transpose(ct</span><span class="s3">, </span><span class="s1">M</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col = ct</span>
  <span class="s3">assert </span><span class="s1">len(data) == nse</span>
  <span class="s3">assert </span><span class="s1">row.dtype == col.dtype == index_dtype</span>
  <span class="s3">if </span><span class="s1">isinstance(row</span><span class="s3">, </span><span class="s1">ad.Zero) </span><span class="s3">or </span><span class="s1">isinstance(col</span><span class="s3">, </span><span class="s1">ad.Zero):</span>
    <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Cannot transpose with respect to sparse indices&quot;</span><span class="s1">)</span>
  <span class="s3">assert </span><span class="s1">ad.is_undefined_primal(M)</span>
  <span class="s3">return </span><span class="s1">_coo_todense(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">spinfo=COOInfo(shape=M.aval.shape))</span>

<span class="s1">ad.primitive_jvps[coo_fromdense_p] = _coo_fromdense_jvp</span>
<span class="s1">ad.primitive_transposes[coo_fromdense_p] = _coo_fromdense_transpose</span>
<span class="s1">mlir.register_lowering(coo_fromdense_p</span><span class="s3">, </span><span class="s1">_coo_fromdense_lowering)</span>
<span class="s1">dispatch.simple_impl(coo_fromdense_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_fromdense_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_fromdense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_coo_fromdense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_fromdense_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_fromdense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_coo_fromdense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>

<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># coo_matvec</span>

<span class="s1">coo_matvec_p = core.Primitive(</span><span class="s5">'coo_matvec'</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">coo_matvec(mat: COO</span><span class="s3">, </span><span class="s1">v: Array</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of COO sparse matrix and a dense vector. 
 
  Args: 
    mat : COO matrix 
    v : one-dimensional array of size ``(shape[0] if transpose else shape[1],)`` and 
      dtype ``mat.dtype`` 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    y : array of shape ``(mat.shape[1] if transpose else mat.shape[0],)`` representing 
      the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col = mat._bufs</span>
  <span class="s3">return </span><span class="s1">_coo_matvec(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">spinfo=mat._info</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matvec(data: Array</span><span class="s3">, </span><span class="s1">row: Array</span><span class="s3">, </span><span class="s1">col: Array</span><span class="s3">, </span><span class="s1">v: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo: COOInfo</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of COO sparse matrix and a dense vector. 
 
  Args: 
    data : array of shape ``(nse,)``. 
    row : array of shape ``(nse,)`` 
    col : array of shape ``(nse,)`` and dtype ``row.dtype`` 
    v : array of shape ``(shape[0] if transpose else shape[1],)`` and 
      dtype ``data.dtype`` 
    shape : length-2 tuple representing the matrix shape 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    y : array of shape ``(shape[1] if transpose else shape[0],)`` representing 
      the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">coo_matvec_p.bind(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matvec_impl(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s1">v = jnp.asarray(v)</span>
  <span class="s3">if </span><span class="s1">transpose:</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = col</span><span class="s3">, </span><span class="s1">row</span>
  <span class="s1">out_shape = spinfo.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">spinfo.shape[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s1">dv = data * v[col]</span>
  <span class="s3">return </span><span class="s1">jnp.zeros(out_shape</span><span class="s3">, </span><span class="s1">dv.dtype).at[row].add(dv)</span>

<span class="s1">@coo_matvec_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_coo_matvec_abstract_eval(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert </span><span class="s1">data.shape == row.shape == col.shape</span>
  <span class="s3">assert </span><span class="s1">data.dtype == v.dtype</span>
  <span class="s3">assert </span><span class="s1">row.dtype == col.dtype</span>
  <span class="s3">assert </span><span class="s1">len(spinfo.shape) == </span><span class="s4">2</span>
  <span class="s3">assert </span><span class="s1">v.ndim == </span><span class="s4">1</span>
  <span class="s3">assert </span><span class="s1">v.shape[</span><span class="s4">0</span><span class="s1">] == (spinfo.shape[</span><span class="s4">0</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">spinfo.shape[</span><span class="s4">1</span><span class="s1">])</span>
  <span class="s1">out_shape = spinfo.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">spinfo.shape[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s3">return </span><span class="s1">core.ShapedArray((out_shape</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">data.dtype)</span>

<span class="s1">_coo_matvec_lowering = mlir.lower_fun(</span>
    <span class="s1">_coo_matvec_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">False</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_coo_matvec_gpu_lowering(coo_matvec_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">,</span>
                             <span class="s1">transpose):</span>
  <span class="s1">data_aval</span><span class="s3">, </span><span class="s1">row_aval</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">x_aval = ctx.avals_in</span>
  <span class="s1">dtype = data_aval.dtype</span>
  <span class="s3">if </span><span class="s1">dtype </span><span class="s3">not in </span><span class="s1">[np.float32</span><span class="s3">, </span><span class="s1">np.float64</span><span class="s3">, </span><span class="s1">np.complex64</span><span class="s3">, </span><span class="s1">np.complex128]:</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;coo_matvec cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_matvec_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

  <span class="s3">if </span><span class="s1">spinfo.rows_sorted:</span>
    <span class="s1">shape = spinfo.shape</span>
  <span class="s3">elif </span><span class="s1">spinfo.cols_sorted:</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = col</span><span class="s3">, </span><span class="s1">row</span>
    <span class="s1">transpose = </span><span class="s3">not </span><span class="s1">transpose</span>
    <span class="s1">shape = spinfo.shape[::-</span><span class="s4">1</span><span class="s1">]</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">warnings.warn(</span><span class="s5">&quot;coo_matvec GPU lowering requires matrices with sorted rows or sorted cols. &quot;</span>
                  <span class="s5">&quot;To sort the rows in your matrix, use e.g. mat = mat._sort_indices(). Falling &quot;</span>
                  <span class="s5">&quot;back to the default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_matvec_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">,</span>
                                <span class="s1">transpose=transpose)</span>

  <span class="s3">return </span><span class="s1">[coo_matvec_hlo(</span>
      <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose</span><span class="s3">,</span>
      <span class="s1">index_dtype=row_aval.dtype</span><span class="s3">, </span><span class="s1">data_dtype=dtype</span><span class="s3">, </span><span class="s1">x_dtype=x_aval.dtype)]</span>


<span class="s3">def </span><span class="s1">_coo_matvec_jvp_mat(data_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_coo_matvec(data_dot</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matvec_jvp_vec(v_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_coo_matvec(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v_dot</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matvec_transpose(ct</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(row)</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(col)</span>

  <span class="s3">if </span><span class="s1">ad.is_undefined_primal(v):</span>
    <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">_coo_matvec(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">ct</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">not </span><span class="s1">transpose)</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">v = jnp.asarray(v)</span>
    <span class="s0"># The following line does this, but more efficiently:</span>
    <span class="s0"># return _coo_extract(row, col, jnp.outer(ct, v)), row, col, v</span>
    <span class="s3">return </span><span class="s1">ct[row] * v[col]</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">v</span>

<span class="s1">ad.defjvp(coo_matvec_p</span><span class="s3">, </span><span class="s1">_coo_matvec_jvp_mat</span><span class="s3">, None, None, </span><span class="s1">_coo_matvec_jvp_vec)</span>
<span class="s1">ad.primitive_transposes[coo_matvec_p] = _coo_matvec_transpose</span>
<span class="s1">mlir.register_lowering(coo_matvec_p</span><span class="s3">, </span><span class="s1">_coo_matvec_lowering)</span>
<span class="s1">dispatch.simple_impl(coo_matvec_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_matvec_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_matvec_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_coo_matvec)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_matvec_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_matvec_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_coo_matvec)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>


<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># coo_matmat</span>

<span class="s1">coo_matmat_p = core.Primitive(</span><span class="s5">'coo_matmat'</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">coo_matmat(mat: COO</span><span class="s3">, </span><span class="s1">B: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of COO sparse matrix and a dense matrix. 
 
  Args: 
    mat : COO matrix 
    B : array of shape ``(mat.shape[0] if transpose else mat.shape[1], cols)`` and 
      dtype ``mat.dtype`` 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    C : array of shape ``(mat.shape[1] if transpose else mat.shape[0], cols)`` 
      representing the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col = mat._bufs</span>
  <span class="s3">return </span><span class="s1">_coo_matmat(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">spinfo=mat._info</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matmat(data: Array</span><span class="s3">, </span><span class="s1">row: Array</span><span class="s3">, </span><span class="s1">col: Array</span><span class="s3">, </span><span class="s1">B: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo: COOInfo</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of COO sparse matrix and a dense matrix. 
 
  Args: 
    data : array of shape ``(nse,)``. 
    row : array of shape ``(nse,)`` 
    col : array of shape ``(nse,)`` and dtype ``row.dtype`` 
    B : array of shape ``(shape[0] if transpose else shape[1], cols)`` and 
      dtype ``data.dtype`` 
    shape : length-2 tuple representing the matrix shape 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    C : array of shape ``(shape[1] if transpose else shape[0], cols)`` 
      representing the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">coo_matmat_p.bind(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matmat_impl(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s1">B = jnp.asarray(B)</span>
  <span class="s3">if </span><span class="s1">transpose:</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = col</span><span class="s3">, </span><span class="s1">row</span>
  <span class="s1">out_shape = spinfo.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">spinfo.shape[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s1">dB = data[:</span><span class="s3">, None</span><span class="s1">] * B[col]</span>
  <span class="s3">return </span><span class="s1">jnp.zeros((out_shape</span><span class="s3">, </span><span class="s1">B.shape[</span><span class="s4">1</span><span class="s1">])</span><span class="s3">, </span><span class="s1">dB.dtype).at[row].add(dB)</span>

<span class="s1">@coo_matmat_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_coo_matmat_abstract_eval(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert </span><span class="s1">data.shape == row.shape == col.shape</span>
  <span class="s3">assert </span><span class="s1">data.dtype == B.dtype</span>
  <span class="s3">assert </span><span class="s1">B.ndim == </span><span class="s4">2</span>
  <span class="s3">assert </span><span class="s1">len(spinfo.shape) == </span><span class="s4">2</span>
  <span class="s3">assert </span><span class="s1">B.shape[</span><span class="s4">0</span><span class="s1">] == (spinfo.shape[</span><span class="s4">0</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">spinfo.shape[</span><span class="s4">1</span><span class="s1">])</span>
  <span class="s1">out_shape = spinfo.shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">spinfo.shape[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s3">return </span><span class="s1">core.ShapedArray((out_shape</span><span class="s3">, </span><span class="s1">B.shape[</span><span class="s4">1</span><span class="s1">])</span><span class="s3">, </span><span class="s1">data.dtype)</span>

<span class="s1">_coo_matmat_lowering = mlir.lower_fun(_coo_matmat_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">False</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_coo_matmat_gpu_lowering(coo_matmat_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">,</span>
                             <span class="s1">transpose):</span>
  <span class="s1">data_aval</span><span class="s3">, </span><span class="s1">row_aval</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">B_aval = ctx.avals_in</span>
  <span class="s1">dtype = data_aval.dtype</span>
  <span class="s3">if </span><span class="s1">dtype </span><span class="s3">not in </span><span class="s1">[np.float32</span><span class="s3">, </span><span class="s1">np.float64</span><span class="s3">, </span><span class="s1">np.complex64</span><span class="s3">, </span><span class="s1">np.complex128]:</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;coo_matmat cusparse/hipsprse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_matmat_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

  <span class="s3">if </span><span class="s1">spinfo.rows_sorted:</span>
    <span class="s1">shape = spinfo.shape</span>
  <span class="s3">elif </span><span class="s1">spinfo.cols_sorted:</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = col</span><span class="s3">, </span><span class="s1">row</span>
    <span class="s1">transpose = </span><span class="s3">not </span><span class="s1">transpose</span>
    <span class="s1">shape = spinfo.shape[::-</span><span class="s4">1</span><span class="s1">]</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">warnings.warn(</span><span class="s5">&quot;coo_matmat GPU lowering requires matrices with sorted rows or sorted cols. &quot;</span>
                  <span class="s5">&quot;To sort the rows in your matrix, use e.g. mat = mat._sort_indices(). Falling &quot;</span>
                  <span class="s5">&quot;back to the default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_coo_matmat_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">,</span>
                                <span class="s1">transpose=transpose)</span>

  <span class="s3">return </span><span class="s1">[coo_matmat_hlo(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">,</span>
                                      <span class="s1">transpose=transpose</span><span class="s3">, </span><span class="s1">x_dtype=B_aval.dtype</span><span class="s3">,</span>
                                      <span class="s1">data_dtype=data_aval.dtype</span><span class="s3">,</span>
                                      <span class="s1">index_dtype=row_aval.dtype)]</span>


<span class="s3">def </span><span class="s1">_coo_matmat_jvp_left(data_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_coo_matmat(data_dot</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matmat_jvp_right(B_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_coo_matmat(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B_dot</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_coo_matmat_transpose(ct</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">spinfo</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(row)</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(col)</span>
  <span class="s3">if </span><span class="s1">ad.is_undefined_primal(B):</span>
    <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">_coo_matmat(data</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">ct</span><span class="s3">, </span><span class="s1">spinfo=spinfo</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">not </span><span class="s1">transpose)</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">B = jnp.asarray(B)</span>
    <span class="s3">return </span><span class="s1">(ct[row] * B[col]).sum(</span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">col</span><span class="s3">, </span><span class="s1">B</span>

<span class="s1">ad.defjvp(coo_matmat_p</span><span class="s3">, </span><span class="s1">_coo_matmat_jvp_left</span><span class="s3">, None, None, </span><span class="s1">_coo_matmat_jvp_right)</span>
<span class="s1">ad.primitive_transposes[coo_matmat_p] = _coo_matmat_transpose</span>
<span class="s1">mlir.register_lowering(coo_matmat_p</span><span class="s3">, </span><span class="s1">_coo_matmat_lowering)</span>
<span class="s1">dispatch.simple_impl(coo_matmat_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_matmat_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_matmat_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_coo_matmat)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">coo_matmat_p</span><span class="s3">,</span>
      <span class="s1">partial(_coo_matmat_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_coo_matmat)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>
</pre>
</body>
</html>