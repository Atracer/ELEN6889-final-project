<html>
<head>
<title>keras_reuse_main.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
keras_reuse_main.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2020 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">&quot;&quot;&quot;Demonstrates reuse of a jax2tf model in Keras. 
 
Includes the flags from saved_model_main.py. 
 
See README.md. 
&quot;&quot;&quot;</span>
<span class="s3">import </span><span class="s1">logging</span>
<span class="s3">from </span><span class="s1">absl </span><span class="s3">import </span><span class="s1">app</span>
<span class="s3">from </span><span class="s1">absl </span><span class="s3">import </span><span class="s1">flags</span>
<span class="s3">from </span><span class="s1">jax.experimental.jax2tf.examples </span><span class="s3">import </span><span class="s1">mnist_lib  </span><span class="s0"># type: ignore</span>
<span class="s3">from </span><span class="s1">jax.experimental.jax2tf.examples </span><span class="s3">import </span><span class="s1">saved_model_main  </span><span class="s0"># type: ignore</span>
<span class="s3">import </span><span class="s1">tensorflow </span><span class="s3">as </span><span class="s1">tf  </span><span class="s0"># type: ignore</span>
<span class="s3">import </span><span class="s1">tensorflow_datasets </span><span class="s3">as </span><span class="s1">tfds  </span><span class="s0"># type: ignore</span>
<span class="s3">import </span><span class="s1">tensorflow_hub </span><span class="s3">as </span><span class="s1">hub  </span><span class="s0"># type: ignore</span>


<span class="s1">FLAGS = flags.FLAGS</span>


<span class="s3">def </span><span class="s1">main(_):</span>
  <span class="s1">FLAGS.model_classifier_layer = </span><span class="s3">False  </span><span class="s0"># We only need the features</span>
  <span class="s0"># Train the model and save the feature extractor</span>
  <span class="s1">saved_model_main.train_and_save()</span>

  <span class="s1">tf_accelerator</span><span class="s3">, </span><span class="s1">_ = saved_model_main.tf_accelerator_and_tolerances()</span>
  <span class="s1">feature_model_dir = saved_model_main.savedmodel_dir()</span>

  <span class="s0"># With Keras, we use the tf.distribute.OneDeviceStrategy as the high-level</span>
  <span class="s0"># analogue of the tf.device(...) placement seen above.</span>
  <span class="s0"># It works on CPU, GPU and TPU.</span>
  <span class="s0"># Actual high-performance training would use the appropriately replicated</span>
  <span class="s0"># TF Distribution Strategy.</span>
  <span class="s1">strategy = tf.distribute.OneDeviceStrategy(tf_accelerator)</span>
  <span class="s3">with </span><span class="s1">strategy.scope():</span>
    <span class="s1">images = tf.keras.layers.Input(</span>
        <span class="s1">mnist_lib.input_shape</span><span class="s3">, </span><span class="s1">batch_size=mnist_lib.train_batch_size)</span>
    <span class="s1">keras_feature_extractor = hub.KerasLayer(feature_model_dir</span><span class="s3">, </span><span class="s1">trainable=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s1">features = keras_feature_extractor(images)</span>
    <span class="s1">predictor = tf.keras.layers.Dense(</span><span class="s4">10</span><span class="s3">, </span><span class="s1">activation=</span><span class="s5">&quot;softmax&quot;</span><span class="s1">)</span>
    <span class="s1">predictions = predictor(features)</span>
    <span class="s1">keras_model = tf.keras.Model(images</span><span class="s3">, </span><span class="s1">predictions)</span>

  <span class="s1">keras_model.compile(</span>
      <span class="s1">loss=tf.keras.losses.categorical_crossentropy</span><span class="s3">,</span>
      <span class="s1">optimizer=tf.keras.optimizers.SGD(learning_rate=</span><span class="s4">0.01</span><span class="s1">)</span><span class="s3">,</span>
      <span class="s1">metrics=[</span><span class="s5">&quot;accuracy&quot;</span><span class="s1">])</span>
  <span class="s1">logging.info(keras_model.summary())</span>

  <span class="s1">train_ds = mnist_lib.load_mnist(</span>
      <span class="s1">tfds.Split.TRAIN</span><span class="s3">, </span><span class="s1">batch_size=mnist_lib.train_batch_size)</span>
  <span class="s1">test_ds = mnist_lib.load_mnist(</span>
      <span class="s1">tfds.Split.TEST</span><span class="s3">, </span><span class="s1">batch_size=mnist_lib.test_batch_size)</span>
  <span class="s1">keras_model.fit(train_ds</span><span class="s3">, </span><span class="s1">epochs=FLAGS.num_epochs</span><span class="s3">, </span><span class="s1">validation_data=test_ds)</span>

  <span class="s3">if </span><span class="s1">FLAGS.show_images:</span>
    <span class="s1">mnist_lib.plot_images(</span>
        <span class="s1">test_ds</span><span class="s3">,</span>
        <span class="s4">1</span><span class="s3">,</span>
        <span class="s4">5</span><span class="s3">,</span>
        <span class="s5">f&quot;Keras inference with reuse of </span><span class="s3">{</span><span class="s1">saved_model_main.model_description()</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s3">,</span>
        <span class="s1">inference_fn=</span><span class="s3">lambda </span><span class="s1">images: keras_model(tf.convert_to_tensor(images)))</span>


<span class="s3">if </span><span class="s1">__name__ == </span><span class="s5">&quot;__main__&quot;</span><span class="s1">:</span>
  <span class="s1">app.run(main)</span>
</pre>
</body>
</html>