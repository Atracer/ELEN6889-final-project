<html>
<head>
<title>setops.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
.s5 { color: #629755; font-style: italic;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
setops.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2022 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>
<span class="s2">import </span><span class="s1">math</span>
<span class="s2">import </span><span class="s1">operator</span>
<span class="s2">from </span><span class="s1">textwrap </span><span class="s2">import </span><span class="s1">dedent </span><span class="s2">as </span><span class="s1">_dedent</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">Optional</span><span class="s2">, </span><span class="s1">Tuple</span><span class="s2">, </span><span class="s1">Union</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">jax </span><span class="s2">import </span><span class="s1">jit</span>
<span class="s2">from </span><span class="s1">jax </span><span class="s2">import </span><span class="s1">lax</span>

<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">core</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">dtypes</span>
<span class="s2">from </span><span class="s1">jax._src.lax </span><span class="s2">import </span><span class="s1">lax </span><span class="s2">as </span><span class="s1">lax_internal</span>
<span class="s2">from </span><span class="s1">jax._src.numpy.lax_numpy </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">append</span><span class="s2">, </span><span class="s1">arange</span><span class="s2">, </span><span class="s1">array</span><span class="s2">, </span><span class="s1">asarray</span><span class="s2">, </span><span class="s1">concatenate</span><span class="s2">, </span><span class="s1">diff</span><span class="s2">,</span>
    <span class="s1">empty</span><span class="s2">, </span><span class="s1">full_like</span><span class="s2">, </span><span class="s1">lexsort</span><span class="s2">, </span><span class="s1">moveaxis</span><span class="s2">, </span><span class="s1">nonzero</span><span class="s2">, </span><span class="s1">ones</span><span class="s2">, </span><span class="s1">ravel</span><span class="s2">,</span>
    <span class="s1">sort</span><span class="s2">, </span><span class="s1">where</span><span class="s2">, </span><span class="s1">zeros)</span>
<span class="s2">from </span><span class="s1">jax._src.numpy.reductions </span><span class="s2">import </span><span class="s1">any</span><span class="s2">, </span><span class="s1">cumsum</span>
<span class="s2">from </span><span class="s1">jax._src.numpy.ufuncs </span><span class="s2">import </span><span class="s1">isnan</span>
<span class="s2">from </span><span class="s1">jax._src.numpy.util </span><span class="s2">import </span><span class="s1">check_arraylike</span><span class="s2">, </span><span class="s1">_wraps</span>
<span class="s2">from </span><span class="s1">jax._src.typing </span><span class="s2">import </span><span class="s1">Array</span><span class="s2">, </span><span class="s1">ArrayLike</span>


<span class="s1">_lax_const = lax_internal._const</span>


<span class="s1">@_wraps(np.in1d</span><span class="s2">, </span><span class="s1">lax_description=</span><span class="s3">&quot;&quot;&quot; 
In the JAX version, the `assume_unique` argument is not referenced. 
&quot;&quot;&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">in1d(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">, </span><span class="s1">assume_unique: bool = </span><span class="s2">False, </span><span class="s1">invert: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">del </span><span class="s1">assume_unique  </span><span class="s0"># unused</span>
  <span class="s2">return </span><span class="s1">_in1d(ar1</span><span class="s2">, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s1">invert)</span>

<span class="s1">@partial(jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'invert'</span><span class="s2">,</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">_in1d(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">, </span><span class="s1">invert: bool) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;in1d&quot;</span><span class="s2">, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s1">ar2)</span>
  <span class="s1">ar1_flat = ravel(ar1)</span>
  <span class="s1">ar2_flat = ravel(ar2)</span>
  <span class="s0"># Note: an algorithm based on searchsorted has better scaling, but in practice</span>
  <span class="s0"># is very slow on accelerators because it relies on lax control flow. If XLA</span>
  <span class="s0"># ever supports binary search natively, we should switch to this:</span>
  <span class="s0">#   ar2_flat = jnp.sort(ar2_flat)</span>
  <span class="s0">#   ind = jnp.searchsorted(ar2_flat, ar1_flat)</span>
  <span class="s0">#   if invert:</span>
  <span class="s0">#     return ar1_flat != ar2_flat[ind]</span>
  <span class="s0">#   else:</span>
  <span class="s0">#     return ar1_flat == ar2_flat[ind]</span>
  <span class="s2">if </span><span class="s1">invert:</span>
    <span class="s2">return </span><span class="s1">(ar1_flat[:</span><span class="s2">, None</span><span class="s1">] != ar2_flat[</span><span class="s2">None, </span><span class="s1">:]).all(-</span><span class="s4">1</span><span class="s1">)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">(ar1_flat[:</span><span class="s2">, None</span><span class="s1">] == ar2_flat[</span><span class="s2">None, </span><span class="s1">:]).any(-</span><span class="s4">1</span><span class="s1">)</span>

<span class="s1">@_wraps(np.setdiff1d</span><span class="s2">,</span>
  <span class="s1">lax_description=_dedent(</span><span class="s3">&quot;&quot;&quot; 
    Because the size of the output of ``setdiff1d`` is data-dependent, the function is not 
    typically compatible with JIT. The JAX version adds the optional ``size`` argument which 
    must be specified statically for ``jnp.setdiff1d`` to be used within some of JAX's 
    transformations.&quot;&quot;&quot;</span><span class="s1">)</span><span class="s2">,</span>
  <span class="s1">extra_params=_dedent(</span><span class="s3">&quot;&quot;&quot; 
    size : int, optional 
        If specified, the first ``size`` elements of the result will be returned. If there are 
        fewer elements than ``size`` indicates, the return value will be padded with ``fill_value``. 
    fill_value : array_like, optional 
        When ``size`` is specified and there are fewer than the indicated number of elements, the 
        remaining elements will be filled with ``fill_value``, which defaults to zero.&quot;&quot;&quot;</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">setdiff1d(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">, </span><span class="s1">assume_unique: bool = </span><span class="s2">False,</span>
              <span class="s1">*</span><span class="s2">, </span><span class="s1">size: Optional[int] = </span><span class="s2">None, </span><span class="s1">fill_value: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;setdiff1d&quot;</span><span class="s2">, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s1">ar2)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">ar1 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s3">&quot;The error arose in setdiff1d()&quot;</span><span class="s1">)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">size = core.concrete_or_error(operator.index</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s3">&quot;The error arose in setdiff1d()&quot;</span><span class="s1">)</span>
  <span class="s1">arr1 = asarray(ar1)</span>
  <span class="s1">fill_value = asarray(</span><span class="s4">0 </span><span class="s2">if </span><span class="s1">fill_value </span><span class="s2">is None else </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">dtype=arr1.dtype)</span>
  <span class="s2">if </span><span class="s1">arr1.size == </span><span class="s4">0</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">full_like(arr1</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">shape=size </span><span class="s2">or </span><span class="s4">0</span><span class="s1">)</span>
  <span class="s2">if not </span><span class="s1">assume_unique:</span>
    <span class="s1">arr1 = unique(arr1</span><span class="s2">, </span><span class="s1">size=size </span><span class="s2">and </span><span class="s1">arr1.size)</span>
  <span class="s1">mask = in1d(arr1</span><span class="s2">, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s1">invert=</span><span class="s2">True</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">arr1[mask]</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">if not </span><span class="s1">(assume_unique </span><span class="s2">or </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">):</span>
      <span class="s0"># Set mask to zero at locations corresponding to unique() padding.</span>
      <span class="s1">n_unique = arr1.size + </span><span class="s4">1 </span><span class="s1">- (arr1 == arr1[</span><span class="s4">0</span><span class="s1">]).sum()  </span><span class="s0"># pytype: disable=attribute-error  # always-use-return-annotations</span>
      <span class="s1">mask = where(arange(arr1.size) &lt; n_unique</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, False</span><span class="s1">)  </span><span class="s0"># pytype: disable=attribute-error  # always-use-return-annotations</span>
    <span class="s2">return </span><span class="s1">where(arange(size) &lt; mask.sum()</span><span class="s2">, </span><span class="s1">arr1[where(mask</span><span class="s2">, </span><span class="s1">size=size)]</span><span class="s2">, </span><span class="s1">fill_value)</span>


<span class="s1">@_wraps(np.union1d</span><span class="s2">,</span>
  <span class="s1">lax_description=_dedent(</span><span class="s3">&quot;&quot;&quot; 
    Because the size of the output of ``union1d`` is data-dependent, the function is not 
    typically compatible with JIT. The JAX version adds the optional ``size`` argument which 
    must be specified statically for ``jnp.union1d`` to be used within some of JAX's 
    transformations.&quot;&quot;&quot;</span><span class="s1">)</span><span class="s2">,</span>
  <span class="s1">extra_params=_dedent(</span><span class="s3">&quot;&quot;&quot; 
    size : int, optional 
        If specified, the first ``size`` elements of the result will be returned. If there are 
        fewer elements than ``size`` indicates, the return value will be padded with ``fill_value``. 
    fill_value : array_like, optional 
        When ``size`` is specified and there are fewer than the indicated number of elements, the 
        remaining elements will be filled with ``fill_value``, which defaults to the minimum 
        value of the union.&quot;&quot;&quot;</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">union1d(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">,</span>
            <span class="s1">*</span><span class="s2">, </span><span class="s1">size: Optional[int] = </span><span class="s2">None, </span><span class="s1">fill_value: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;union1d&quot;</span><span class="s2">, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s1">ar2)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">ar1 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s3">&quot;The error arose in union1d()&quot;</span><span class="s1">)</span>
    <span class="s1">ar2 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s3">&quot;The error arose in union1d()&quot;</span><span class="s1">)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">size = core.concrete_or_error(operator.index</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s3">&quot;The error arose in union1d()&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">unique(concatenate((ar1</span><span class="s2">, </span><span class="s1">ar2)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s2">None</span><span class="s1">)</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">fill_value=fill_value)  </span><span class="s0"># pytype: disable=bad-return-type  # always-use-return-annotations</span>


<span class="s1">@_wraps(np.setxor1d</span><span class="s2">, </span><span class="s1">lax_description=</span><span class="s3">&quot;&quot;&quot; 
In the JAX version, the input arrays are explicitly flattened regardless 
of assume_unique value. 
&quot;&quot;&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">setxor1d(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">, </span><span class="s1">assume_unique: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;setxor1d&quot;</span><span class="s2">, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s1">ar2)</span>
  <span class="s1">ar1 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s3">&quot;The error arose in setxor1d()&quot;</span><span class="s1">)</span>
  <span class="s1">ar2 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s3">&quot;The error arose in setxor1d()&quot;</span><span class="s1">)</span>

  <span class="s1">ar1 = ravel(ar1)</span>
  <span class="s1">ar2 = ravel(ar2)</span>

  <span class="s2">if not </span><span class="s1">assume_unique:</span>
    <span class="s1">ar1 = unique(ar1)</span>
    <span class="s1">ar2 = unique(ar2)</span>

  <span class="s1">aux = concatenate((ar1</span><span class="s2">, </span><span class="s1">ar2))</span>
  <span class="s2">if </span><span class="s1">aux.size == </span><span class="s4">0</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">aux</span>

  <span class="s1">aux = sort(aux)</span>
  <span class="s1">flag = concatenate((array([</span><span class="s2">True</span><span class="s1">])</span><span class="s2">, </span><span class="s1">aux[</span><span class="s4">1</span><span class="s1">:] != aux[:-</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">array([</span><span class="s2">True</span><span class="s1">])))</span>
  <span class="s2">return </span><span class="s1">aux[flag[</span><span class="s4">1</span><span class="s1">:] &amp; flag[:-</span><span class="s4">1</span><span class="s1">]]</span>


<span class="s1">@partial(jit</span><span class="s2">, </span><span class="s1">static_argnames=[</span><span class="s3">'return_indices'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">_intersect1d_sorted_mask(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">, </span><span class="s1">return_indices: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Tuple[Array</span><span class="s2">, </span><span class="s1">...]:</span>
  <span class="s5">&quot;&quot;&quot; 
    Helper function for intersect1d which is jit-able 
    &quot;&quot;&quot;</span>
  <span class="s1">ar = concatenate((ar1</span><span class="s2">, </span><span class="s1">ar2))</span>
  <span class="s2">if </span><span class="s1">return_indices:</span>
    <span class="s1">iota = lax.broadcasted_iota(np.int64</span><span class="s2">, </span><span class="s1">np.shape(ar)</span><span class="s2">, </span><span class="s1">dimension=</span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">aux</span><span class="s2">, </span><span class="s1">indices = lax.sort_key_val(ar</span><span class="s2">, </span><span class="s1">iota)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">aux = sort(ar)</span>

  <span class="s1">mask = aux[</span><span class="s4">1</span><span class="s1">:] == aux[:-</span><span class="s4">1</span><span class="s1">]</span>
  <span class="s2">if </span><span class="s1">return_indices:</span>
    <span class="s2">return </span><span class="s1">aux</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">indices</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">aux</span><span class="s2">, </span><span class="s1">mask</span>


<span class="s1">@_wraps(np.intersect1d)</span>
<span class="s2">def </span><span class="s1">intersect1d(ar1: ArrayLike</span><span class="s2">, </span><span class="s1">ar2: ArrayLike</span><span class="s2">, </span><span class="s1">assume_unique: bool = </span><span class="s2">False,</span>
                <span class="s1">return_indices: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Union[Array</span><span class="s2">, </span><span class="s1">Tuple[Array</span><span class="s2">, </span><span class="s1">Array</span><span class="s2">, </span><span class="s1">Array]]:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;intersect1d&quot;</span><span class="s2">, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s1">ar2)</span>
  <span class="s1">ar1 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar1</span><span class="s2">, </span><span class="s3">&quot;The error arose in intersect1d()&quot;</span><span class="s1">)</span>
  <span class="s1">ar2 = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s3">&quot;The error arose in intersect1d()&quot;</span><span class="s1">)</span>

  <span class="s2">if not </span><span class="s1">assume_unique:</span>
    <span class="s2">if </span><span class="s1">return_indices:</span>
      <span class="s1">ar1</span><span class="s2">, </span><span class="s1">ind1 = unique(ar1</span><span class="s2">, </span><span class="s1">return_index=</span><span class="s2">True</span><span class="s1">)</span>
      <span class="s1">ar2</span><span class="s2">, </span><span class="s1">ind2 = unique(ar2</span><span class="s2">, </span><span class="s1">return_index=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">ar1 = unique(ar1)</span>
      <span class="s1">ar2 = unique(ar2)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">ar1 = ravel(ar1)</span>
    <span class="s1">ar2 = ravel(ar2)</span>

  <span class="s2">if </span><span class="s1">return_indices:</span>
    <span class="s1">aux</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">aux_sort_indices = _intersect1d_sorted_mask(ar1</span><span class="s2">, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s1">return_indices)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">aux</span><span class="s2">, </span><span class="s1">mask = _intersect1d_sorted_mask(ar1</span><span class="s2">, </span><span class="s1">ar2</span><span class="s2">, </span><span class="s1">return_indices)</span>

  <span class="s1">int1d = aux[:-</span><span class="s4">1</span><span class="s1">][mask]</span>

  <span class="s2">if </span><span class="s1">return_indices:</span>
    <span class="s1">ar1_indices = aux_sort_indices[:-</span><span class="s4">1</span><span class="s1">][mask]</span>
    <span class="s1">ar2_indices = aux_sort_indices[</span><span class="s4">1</span><span class="s1">:][mask] - np.size(ar1)</span>
    <span class="s2">if not </span><span class="s1">assume_unique:</span>
      <span class="s1">ar1_indices = ind1[ar1_indices]</span>
      <span class="s1">ar2_indices = ind2[ar2_indices]</span>

    <span class="s2">return </span><span class="s1">int1d</span><span class="s2">, </span><span class="s1">ar1_indices</span><span class="s2">, </span><span class="s1">ar2_indices</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">int1d</span>


<span class="s1">@_wraps(np.isin</span><span class="s2">, </span><span class="s1">lax_description=</span><span class="s3">&quot;&quot;&quot; 
In the JAX version, the `assume_unique` argument is not referenced. 
&quot;&quot;&quot;</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">isin(element: ArrayLike</span><span class="s2">, </span><span class="s1">test_elements: ArrayLike</span><span class="s2">,</span>
         <span class="s1">assume_unique: bool = </span><span class="s2">False, </span><span class="s1">invert: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">result = in1d(element</span><span class="s2">, </span><span class="s1">test_elements</span><span class="s2">, </span><span class="s1">assume_unique=assume_unique</span><span class="s2">, </span><span class="s1">invert=invert)</span>
  <span class="s2">return </span><span class="s1">result.reshape(np.shape(element))</span>


<span class="s0">### SetOps</span>

<span class="s1">UNIQUE_SIZE_HINT = (</span>
  <span class="s3">&quot;To make jnp.unique() compatible with JIT and other transforms, you can specify &quot;</span>
  <span class="s3">&quot;a concrete value for the size argument, which will determine the output size.&quot;</span><span class="s1">)</span>

<span class="s1">@partial(jit</span><span class="s2">, </span><span class="s1">static_argnums=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_unique_sorted_mask(ar: Array</span><span class="s2">, </span><span class="s1">axis: int) -&gt; Tuple[Array</span><span class="s2">, </span><span class="s1">Array</span><span class="s2">, </span><span class="s1">Array]:</span>
  <span class="s1">aux = moveaxis(ar</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">np.issubdtype(aux.dtype</span><span class="s2">, </span><span class="s1">np.complexfloating):</span>
    <span class="s0"># Work around issue in sorting of complex numbers with Nan only in the</span>
    <span class="s0"># imaginary component. This can be removed if sorting in this situation</span>
    <span class="s0"># is fixed to match numpy.</span>
    <span class="s1">aux = where(isnan(aux)</span><span class="s2">, </span><span class="s1">_lax_const(aux</span><span class="s2">, </span><span class="s1">np.nan)</span><span class="s2">, </span><span class="s1">aux)</span>
  <span class="s1">size</span><span class="s2">, </span><span class="s1">*out_shape = aux.shape</span>
  <span class="s2">if </span><span class="s1">math.prod(out_shape) == </span><span class="s4">0</span><span class="s1">:</span>
    <span class="s1">size = </span><span class="s4">1</span>
    <span class="s1">perm = zeros(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">dtype=int)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">perm = lexsort(aux.reshape(size</span><span class="s2">, </span><span class="s1">math.prod(out_shape)).T[::-</span><span class="s4">1</span><span class="s1">])</span>
  <span class="s1">aux = aux[perm]</span>
  <span class="s2">if </span><span class="s1">aux.size:</span>
    <span class="s2">if </span><span class="s1">dtypes.issubdtype(aux.dtype</span><span class="s2">, </span><span class="s1">np.inexact):</span>
      <span class="s0"># This is appropriate for both float and complex due to the documented behavior of np.unique:</span>
      <span class="s0"># See https://github.com/numpy/numpy/blob/v1.22.0/numpy/lib/arraysetops.py#L212-L220</span>
      <span class="s1">neq = </span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: lax.ne(x</span><span class="s2">, </span><span class="s1">y) &amp; ~(isnan(x) &amp; isnan(y))</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">neq = lax.ne</span>
    <span class="s1">mask = ones(size</span><span class="s2">, </span><span class="s1">dtype=bool).at[</span><span class="s4">1</span><span class="s1">:].set(any(neq(aux[</span><span class="s4">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">aux[:-</span><span class="s4">1</span><span class="s1">])</span><span class="s2">, </span><span class="s1">tuple(range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">aux.ndim))))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">mask = zeros(size</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
  <span class="s2">return </span><span class="s1">aux</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">perm</span>

<span class="s2">def </span><span class="s1">_unique(ar: Array</span><span class="s2">, </span><span class="s1">axis: int</span><span class="s2">, </span><span class="s1">return_index: bool = </span><span class="s2">False, </span><span class="s1">return_inverse: bool = </span><span class="s2">False,</span>
            <span class="s1">return_counts: bool = </span><span class="s2">False, </span><span class="s1">size: Optional[int] = </span><span class="s2">None,</span>
            <span class="s1">fill_value: Optional[ArrayLike] = </span><span class="s2">None, </span><span class="s1">return_true_size: bool = </span><span class="s2">False</span>
            <span class="s1">) -&gt; Union[Array</span><span class="s2">, </span><span class="s1">Tuple[Array</span><span class="s2">, </span><span class="s1">...]]:</span>
  <span class="s5">&quot;&quot;&quot; 
  Find the unique elements of an array along a particular axis. 
  &quot;&quot;&quot;</span>
  <span class="s2">if </span><span class="s1">ar.shape[axis] == </span><span class="s4">0 </span><span class="s2">and </span><span class="s1">size </span><span class="s2">and </span><span class="s1">fill_value </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span>
      <span class="s3">&quot;jnp.unique: for zero-sized input with nonzero size argument, fill_value must be specified&quot;</span><span class="s1">)</span>

  <span class="s1">aux</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">perm = _unique_sorted_mask(ar</span><span class="s2">, </span><span class="s1">axis)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">ind = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">mask</span><span class="s2">,</span>
        <span class="s3">&quot;The error arose in jnp.unique(). &quot; </span><span class="s1">+ UNIQUE_SIZE_HINT)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">ind = nonzero(mask</span><span class="s2">, </span><span class="s1">size=size)[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s1">result = aux[ind] </span><span class="s2">if </span><span class="s1">aux.size </span><span class="s2">else </span><span class="s1">aux</span>
  <span class="s2">if </span><span class="s1">fill_value </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">fill_value = asarray(fill_value</span><span class="s2">, </span><span class="s1">dtype=result.dtype)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is not None and </span><span class="s1">fill_value </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">if </span><span class="s1">result.shape[</span><span class="s4">0</span><span class="s1">]:</span>
      <span class="s1">valid = lax.expand_dims(arange(size) &lt; mask.sum()</span><span class="s2">, </span><span class="s1">tuple(range(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">result.ndim)))</span>
      <span class="s1">result = where(valid</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">fill_value)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">result = full_like(result</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">shape=(size</span><span class="s2">, </span><span class="s1">*result.shape[</span><span class="s4">1</span><span class="s1">:]))</span>
  <span class="s1">result = moveaxis(result</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">axis)</span>

  <span class="s1">ret: Tuple[Array</span><span class="s2">, </span><span class="s1">...] = (result</span><span class="s2">,</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">return_index:</span>
    <span class="s2">if </span><span class="s1">aux.size:</span>
      <span class="s1">ret += (perm[ind]</span><span class="s2">,</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">ret += (perm</span><span class="s2">,</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">return_inverse:</span>
    <span class="s2">if </span><span class="s1">aux.size:</span>
      <span class="s1">imask = cumsum(mask) - </span><span class="s4">1</span>
      <span class="s1">inv_idx = zeros(mask.shape</span><span class="s2">, </span><span class="s1">dtype=dtypes.canonicalize_dtype(dtypes.int_))</span>
      <span class="s1">inv_idx = inv_idx.at[perm].set(imask)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">inv_idx = zeros(ar.shape[axis]</span><span class="s2">, </span><span class="s1">dtype=int)</span>
    <span class="s1">ret += (inv_idx</span><span class="s2">,</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">return_counts:</span>
    <span class="s2">if </span><span class="s1">aux.size:</span>
      <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">idx = append(nonzero(mask)[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">mask.size)</span>
      <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">idx = nonzero(mask</span><span class="s2">, </span><span class="s1">size=size + </span><span class="s4">1</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s1">idx = idx.at[</span><span class="s4">1</span><span class="s1">:].set(where(idx[</span><span class="s4">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">idx[</span><span class="s4">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">mask.size))</span>
      <span class="s1">ret += (diff(idx)</span><span class="s2">,</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">ar.shape[axis]:</span>
      <span class="s1">ret += (array([ar.shape[axis]]</span><span class="s2">, </span><span class="s1">dtype=dtypes.canonicalize_dtype(dtypes.int_))</span><span class="s2">,</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">ret += (empty(</span><span class="s4">0</span><span class="s2">, </span><span class="s1">dtype=int)</span><span class="s2">,</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">return_true_size:</span>
    <span class="s0"># Useful for internal uses of unique().</span>
    <span class="s1">ret += (mask.sum()</span><span class="s2">,</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">ret[</span><span class="s4">0</span><span class="s1">] </span><span class="s2">if </span><span class="s1">len(ret) == </span><span class="s4">1 </span><span class="s2">else </span><span class="s1">ret</span>

<span class="s1">@_wraps(np.unique</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'axis'</span><span class="s1">]</span><span class="s2">,</span>
  <span class="s1">lax_description=_dedent(</span><span class="s3">&quot;&quot;&quot; 
    Because the size of the output of ``unique`` is data-dependent, the function is not 
    typically compatible with JIT. The JAX version adds the optional ``size`` argument which 
    must be specified statically for ``jnp.unique`` to be used within some of JAX's 
    transformations.&quot;&quot;&quot;</span><span class="s1">)</span><span class="s2">,</span>
  <span class="s1">extra_params=_dedent(</span><span class="s3">&quot;&quot;&quot; 
    size : int, optional 
        If specified, the first ``size`` unique elements will be returned. If there are fewer unique 
        elements than ``size`` indicates, the return value will be padded with ``fill_value``. 
    fill_value : array_like, optional 
        When ``size`` is specified and there are fewer than the indicated number of elements, the 
        remaining elements will be filled with ``fill_value``. The default is the minimum value 
        along the specified axis of the input.&quot;&quot;&quot;</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">unique(ar: ArrayLike</span><span class="s2">, </span><span class="s1">return_index: bool = </span><span class="s2">False, </span><span class="s1">return_inverse: bool = </span><span class="s2">False,</span>
           <span class="s1">return_counts: bool = </span><span class="s2">False, </span><span class="s1">axis: Optional[int] = </span><span class="s2">None,</span>
           <span class="s1">*</span><span class="s2">, </span><span class="s1">size: Optional[int] = </span><span class="s2">None, </span><span class="s1">fill_value: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">):</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;unique&quot;</span><span class="s2">, </span><span class="s1">ar)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">ar = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">ar</span><span class="s2">,</span>
        <span class="s3">&quot;The error arose for the first argument of jnp.unique(). &quot; </span><span class="s1">+ UNIQUE_SIZE_HINT)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">size = core.concrete_or_error(operator.index</span><span class="s2">, </span><span class="s1">size</span><span class="s2">,</span>
         <span class="s3">&quot;The error arose for the size argument of jnp.unique(). &quot; </span><span class="s1">+ UNIQUE_SIZE_HINT)</span>
  <span class="s1">arr = asarray(ar)</span>
  <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">axis = </span><span class="s4">0</span>
    <span class="s1">arr = arr.flatten()</span>
  <span class="s1">axis_int: int = core.concrete_or_error(operator.index</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s3">&quot;axis argument of jnp.unique()&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">_unique(arr</span><span class="s2">, </span><span class="s1">axis_int</span><span class="s2">, </span><span class="s1">return_index</span><span class="s2">, </span><span class="s1">return_inverse</span><span class="s2">,</span>
                 <span class="s1">return_counts</span><span class="s2">, </span><span class="s1">size=size</span><span class="s2">, </span><span class="s1">fill_value=fill_value)</span>
</pre>
</body>
</html>