<html>
<head>
<title>reductions.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
reductions.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2022 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">import </span><span class="s1">builtins</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>
<span class="s2">import </span><span class="s1">math</span>
<span class="s2">import </span><span class="s1">operator</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">overload</span><span class="s2">, </span><span class="s1">Any</span><span class="s2">, </span><span class="s1">Callable</span><span class="s2">, </span><span class="s1">Literal</span><span class="s2">, </span><span class="s1">Optional</span><span class="s2">, </span><span class="s1">Sequence</span><span class="s2">, </span><span class="s1">Tuple</span><span class="s2">, </span><span class="s1">Union</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">jax </span><span class="s2">import </span><span class="s1">lax</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">api</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">core</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">dtypes</span>
<span class="s2">from </span><span class="s1">jax._src.numpy </span><span class="s2">import </span><span class="s1">ufuncs</span>
<span class="s2">from </span><span class="s1">jax._src.numpy.util </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">_broadcast_to</span><span class="s2">, </span><span class="s1">check_arraylike</span><span class="s2">, </span><span class="s1">_complex_elem_type</span><span class="s2">,</span>
    <span class="s1">promote_dtypes_inexact</span><span class="s2">, </span><span class="s1">promote_dtypes_numeric</span><span class="s2">, </span><span class="s1">_where</span><span class="s2">, </span><span class="s1">_wraps)</span>
<span class="s2">from </span><span class="s1">jax._src.lax </span><span class="s2">import </span><span class="s1">lax </span><span class="s2">as </span><span class="s1">lax_internal</span>
<span class="s2">from </span><span class="s1">jax._src.typing </span><span class="s2">import </span><span class="s1">Array</span><span class="s2">, </span><span class="s1">ArrayLike</span><span class="s2">, </span><span class="s1">DType</span><span class="s2">, </span><span class="s1">DTypeLike</span>
<span class="s2">from </span><span class="s1">jax._src.util </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">canonicalize_axis </span><span class="s2">as </span><span class="s1">_canonicalize_axis</span><span class="s2">, </span><span class="s1">maybe_named_axis)</span>


<span class="s1">_all = builtins.all</span>
<span class="s1">_lax_const = lax_internal._const</span>


<span class="s1">Axis = Union[</span><span class="s2">None, </span><span class="s1">int</span><span class="s2">, </span><span class="s1">Sequence[int]]</span>


<span class="s2">def </span><span class="s1">_asarray(a: ArrayLike) -&gt; Array:</span>
  <span class="s0"># simplified version of jnp.asarray() for local use.</span>
  <span class="s2">return </span><span class="s1">a </span><span class="s2">if </span><span class="s1">isinstance(a</span><span class="s2">, </span><span class="s1">Array) </span><span class="s2">else </span><span class="s1">api.device_put(a)</span>

<span class="s2">def </span><span class="s1">_isscalar(element: Any) -&gt; bool:</span>
  <span class="s2">if </span><span class="s1">hasattr(element</span><span class="s2">, </span><span class="s3">'__jax_array__'</span><span class="s1">):</span>
    <span class="s1">element = element.__jax_array__()</span>
  <span class="s2">return </span><span class="s1">dtypes.is_python_scalar(element) </span><span class="s2">or </span><span class="s1">np.isscalar(element)</span>

<span class="s2">def </span><span class="s1">_moveaxis(a: ArrayLike</span><span class="s2">, </span><span class="s1">source: int</span><span class="s2">, </span><span class="s1">destination: int) -&gt; Array:</span>
  <span class="s0"># simplified version of jnp.moveaxis() for local use.</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;moveaxis&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">a = _asarray(a)</span>
  <span class="s1">source = _canonicalize_axis(source</span><span class="s2">, </span><span class="s1">np.ndim(a))</span>
  <span class="s1">destination = _canonicalize_axis(destination</span><span class="s2">, </span><span class="s1">np.ndim(a))</span>
  <span class="s1">perm = [i </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(np.ndim(a)) </span><span class="s2">if </span><span class="s1">i != source]</span>
  <span class="s1">perm.insert(destination</span><span class="s2">, </span><span class="s1">source)</span>
  <span class="s2">return </span><span class="s1">lax.transpose(a</span><span class="s2">, </span><span class="s1">perm)</span>

<span class="s2">def </span><span class="s1">_upcast_f16(dtype: DTypeLike) -&gt; DType:</span>
  <span class="s2">if </span><span class="s1">np.dtype(dtype) </span><span class="s2">in </span><span class="s1">[np.float16</span><span class="s2">, </span><span class="s1">dtypes.bfloat16]:</span>
    <span class="s2">return </span><span class="s1">np.dtype(</span><span class="s3">'float32'</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">np.dtype(dtype)</span>

<span class="s1">ReductionOp = Callable[[Any</span><span class="s2">, </span><span class="s1">Any]</span><span class="s2">, </span><span class="s1">Any]</span>

<span class="s2">def </span><span class="s1">_reduction(a: ArrayLike</span><span class="s2">, </span><span class="s1">name: str</span><span class="s2">, </span><span class="s1">np_fun: Any</span><span class="s2">, </span><span class="s1">op: ReductionOp</span><span class="s2">, </span><span class="s1">init_val: ArrayLike</span><span class="s2">,</span>
               <span class="s1">*</span><span class="s2">, </span><span class="s1">has_identity: bool = </span><span class="s2">True,</span>
               <span class="s1">preproc: Optional[Callable[[ArrayLike]</span><span class="s2">, </span><span class="s1">ArrayLike]] = </span><span class="s2">None,</span>
               <span class="s1">bool_op: Optional[ReductionOp] = </span><span class="s2">None,</span>
               <span class="s1">upcast_f16_for_computation: bool = </span><span class="s2">False,</span>
               <span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
               <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
               <span class="s1">where_: Optional[ArrayLike] = </span><span class="s2">None,</span>
               <span class="s1">parallel_reduce: Optional[Callable[...</span><span class="s2">, </span><span class="s1">Array]] = </span><span class="s2">None,</span>
               <span class="s1">promote_integers: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">bool_op = bool_op </span><span class="s2">or </span><span class="s1">op</span>
  <span class="s0"># Note: we must accept out=None as an argument, because numpy reductions delegate to</span>
  <span class="s0"># object methods. For example `np.sum(x)` will call `x.sum()` if the `sum()` method</span>
  <span class="s0"># exists, passing along all its arguments.</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">f&quot;The 'out' argument to jnp.</span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s3">is not supported.&quot;</span><span class="s1">)</span>
  <span class="s1">check_arraylike(name</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s1">name)</span>
  <span class="s1">axis = core.concrete_or_error(</span><span class="s2">None, </span><span class="s1">axis</span><span class="s2">, </span><span class="s3">f&quot;axis argument to jnp.</span><span class="s2">{</span><span class="s1">name</span><span class="s2">}</span><span class="s3">().&quot;</span><span class="s1">)</span>

  <span class="s2">if </span><span class="s1">initial </span><span class="s2">is None and not </span><span class="s1">has_identity </span><span class="s2">and </span><span class="s1">where_ </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;reduction operation </span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s3">does not have an identity, so to use a &quot;</span>
                     <span class="s3">f&quot;where mask one has to specify 'initial'&quot;</span><span class="s1">)</span>

  <span class="s1">a = a </span><span class="s2">if </span><span class="s1">isinstance(a</span><span class="s2">, </span><span class="s1">Array) </span><span class="s2">else </span><span class="s1">_asarray(a)</span>
  <span class="s1">a = preproc(a) </span><span class="s2">if </span><span class="s1">preproc </span><span class="s2">else </span><span class="s1">a</span>
  <span class="s1">pos_dims</span><span class="s2">, </span><span class="s1">dims = _reduction_dims(a</span><span class="s2">, </span><span class="s1">axis)</span>

  <span class="s2">if </span><span class="s1">initial </span><span class="s2">is None and not </span><span class="s1">has_identity:</span>
    <span class="s1">shape = np.shape(a)</span>
    <span class="s2">if not </span><span class="s1">_all(core.greater_equal_dim(shape[d]</span><span class="s2">, </span><span class="s4">1</span><span class="s1">) </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">pos_dims):</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;zero-size array to reduction operation </span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s3">which has no identity&quot;</span><span class="s1">)</span>

  <span class="s1">result_dtype = dtype </span><span class="s2">or </span><span class="s1">dtypes.dtype(a)</span>

  <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is None and </span><span class="s1">promote_integers:</span>
    <span class="s0"># Note: NumPy always promotes to 64-bit; jax instead promotes to the</span>
    <span class="s0"># default dtype as defined by dtypes.int_ or dtypes.uint.</span>
    <span class="s2">if </span><span class="s1">dtypes.issubdtype(result_dtype</span><span class="s2">, </span><span class="s1">np.bool_):</span>
      <span class="s1">result_dtype = dtypes.int_</span>
    <span class="s2">elif </span><span class="s1">dtypes.issubdtype(result_dtype</span><span class="s2">, </span><span class="s1">np.unsignedinteger):</span>
      <span class="s2">if </span><span class="s1">np.iinfo(result_dtype).bits &lt; np.iinfo(dtypes.uint).bits:</span>
        <span class="s1">result_dtype = dtypes.uint</span>
    <span class="s2">elif </span><span class="s1">dtypes.issubdtype(result_dtype</span><span class="s2">, </span><span class="s1">np.integer):</span>
      <span class="s2">if </span><span class="s1">np.iinfo(result_dtype).bits &lt; np.iinfo(dtypes.int_).bits:</span>
        <span class="s1">result_dtype = dtypes.int_</span>

  <span class="s1">result_dtype = dtypes.canonicalize_dtype(result_dtype)</span>

  <span class="s2">if </span><span class="s1">upcast_f16_for_computation </span><span class="s2">and </span><span class="s1">dtypes.issubdtype(result_dtype</span><span class="s2">, </span><span class="s1">np.inexact):</span>
    <span class="s1">computation_dtype = _upcast_f16(result_dtype)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">computation_dtype = result_dtype</span>
  <span class="s1">a = lax.convert_element_type(a</span><span class="s2">, </span><span class="s1">computation_dtype)</span>
  <span class="s1">op = op </span><span class="s2">if </span><span class="s1">computation_dtype != np.bool_ </span><span class="s2">else </span><span class="s1">bool_op</span>
  <span class="s0"># NB: in XLA, init_val must be an identity for the op, so the user-specified</span>
  <span class="s0"># initial value must be applied afterward.</span>
  <span class="s1">init_val = _reduction_init_val(a</span><span class="s2">, </span><span class="s1">init_val)</span>
  <span class="s2">if </span><span class="s1">where_ </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">a = _where(where_</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">init_val)</span>
  <span class="s2">if </span><span class="s1">pos_dims </span><span class="s2">is not </span><span class="s1">dims:</span>
    <span class="s2">if </span><span class="s1">parallel_reduce </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">f&quot;Named reductions not implemented for jnp.</span><span class="s2">{</span><span class="s1">name</span><span class="s2">}</span><span class="s3">()&quot;</span><span class="s1">)</span>
    <span class="s1">result = parallel_reduce(a</span><span class="s2">, </span><span class="s1">dims)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">result = lax.reduce(a</span><span class="s2">, </span><span class="s1">init_val</span><span class="s2">, </span><span class="s1">op</span><span class="s2">, </span><span class="s1">dims)</span>
  <span class="s2">if </span><span class="s1">initial </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">initial_arr = lax.convert_element_type(initial</span><span class="s2">, </span><span class="s1">_asarray(a).dtype)</span>
    <span class="s2">if </span><span class="s1">initial_arr.shape != ():</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;initial value must be a scalar. &quot;</span>
                       <span class="s3">f&quot;Got array of shape </span><span class="s2">{</span><span class="s1">initial_arr.shape</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>
    <span class="s1">result = op(initial_arr</span><span class="s2">, </span><span class="s1">result)</span>
  <span class="s2">if </span><span class="s1">keepdims:</span>
    <span class="s1">result = lax.expand_dims(result</span><span class="s2">, </span><span class="s1">pos_dims)</span>
  <span class="s2">return </span><span class="s1">lax.convert_element_type(result</span><span class="s2">, </span><span class="s1">dtype </span><span class="s2">or </span><span class="s1">result_dtype)</span>

<span class="s2">def </span><span class="s1">_canonicalize_axis_allow_named(x</span><span class="s2">, </span><span class="s1">rank):</span>
  <span class="s2">return </span><span class="s1">maybe_named_axis(x</span><span class="s2">, lambda </span><span class="s1">i: _canonicalize_axis(i</span><span class="s2">, </span><span class="s1">rank)</span><span class="s2">, lambda </span><span class="s1">name: name)</span>

<span class="s2">def </span><span class="s1">_reduction_dims(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis):</span>
  <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">(tuple(range(np.ndim(a)))</span><span class="s2">,</span><span class="s1">) * </span><span class="s4">2</span>
  <span class="s2">elif not </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">tuple</span><span class="s2">, </span><span class="s1">list)):</span>
    <span class="s1">axis = (axis</span><span class="s2">,</span><span class="s1">)  </span><span class="s0"># type: ignore[assignment]</span>
  <span class="s1">canon_axis = tuple(_canonicalize_axis_allow_named(x</span><span class="s2">, </span><span class="s1">np.ndim(a))</span>
                     <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">axis)  </span><span class="s0"># type: ignore[union-attr]</span>
  <span class="s2">if </span><span class="s1">len(canon_axis) != len(set(canon_axis)):</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;duplicate value in 'axis': </span><span class="s2">{</span><span class="s1">axis</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>
  <span class="s1">canon_pos_axis = tuple(x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">canon_axis </span><span class="s2">if </span><span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">int))</span>
  <span class="s2">if </span><span class="s1">len(canon_pos_axis) != len(canon_axis):</span>
    <span class="s2">return </span><span class="s1">canon_pos_axis</span><span class="s2">, </span><span class="s1">canon_axis</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">canon_axis</span><span class="s2">, </span><span class="s1">canon_axis</span>

<span class="s2">def </span><span class="s1">_reduction_init_val(a: ArrayLike</span><span class="s2">, </span><span class="s1">init_val: Any) -&gt; np.ndarray:</span>
  <span class="s0"># This function uses np.* functions because lax pattern matches against the</span>
  <span class="s0"># specific concrete values of the reduction inputs.</span>
  <span class="s1">a_dtype = dtypes.canonicalize_dtype(dtypes.dtype(a))</span>
  <span class="s2">if </span><span class="s1">a_dtype == </span><span class="s3">'bool'</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">np.array(init_val &gt; </span><span class="s4">0</span><span class="s2">, </span><span class="s1">dtype=a_dtype)</span>
  <span class="s2">try</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">np.array(init_val</span><span class="s2">, </span><span class="s1">dtype=a_dtype)</span>
  <span class="s2">except </span><span class="s1">OverflowError:</span>
    <span class="s2">assert </span><span class="s1">dtypes.issubdtype(a_dtype</span><span class="s2">, </span><span class="s1">np.integer)</span>
    <span class="s1">sign</span><span class="s2">, </span><span class="s1">info = np.sign(init_val)</span><span class="s2">, </span><span class="s1">dtypes.iinfo(a_dtype)</span>
    <span class="s2">return </span><span class="s1">np.array(info.min </span><span class="s2">if </span><span class="s1">sign &lt; </span><span class="s4">0 </span><span class="s2">else </span><span class="s1">info.max</span><span class="s2">, </span><span class="s1">dtype=a_dtype)</span>

<span class="s2">def </span><span class="s1">_cast_to_bool(operand: ArrayLike) -&gt; Array:</span>
  <span class="s2">with </span><span class="s1">warnings.catch_warnings():</span>
    <span class="s1">warnings.filterwarnings(</span><span class="s3">&quot;ignore&quot;</span><span class="s2">, </span><span class="s1">category=np.ComplexWarning)</span>
    <span class="s2">return </span><span class="s1">lax.convert_element_type(operand</span><span class="s2">, </span><span class="s1">np.bool_)</span>

<span class="s2">def </span><span class="s1">_cast_to_numeric(operand: ArrayLike) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">promote_dtypes_numeric(operand)[</span><span class="s4">0</span><span class="s1">]</span>


<span class="s2">def </span><span class="s1">_ensure_optional_axes(x: Axis) -&gt; Axis:</span>
  <span class="s2">def </span><span class="s1">force(x):</span>
    <span class="s2">if </span><span class="s1">x </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s2">return None</span>
    <span class="s2">try</span><span class="s1">:</span>
      <span class="s2">return </span><span class="s1">operator.index(x)</span>
    <span class="s2">except </span><span class="s1">TypeError:</span>
      <span class="s2">return </span><span class="s1">tuple(i </span><span class="s2">if </span><span class="s1">isinstance(i</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">else </span><span class="s1">operator.index(i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">x)</span>
  <span class="s2">return </span><span class="s1">core.concrete_or_error(</span>
    <span class="s1">force</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s3">&quot;The axis argument must be known statically.&quot;</span><span class="s1">)</span>


<span class="s0"># TODO(jakevdp) change promote_integers default to False</span>
<span class="s1">_PROMOTE_INTEGERS_DOC = </span><span class="s3">&quot;&quot;&quot; 
promote_integers : bool, default=True 
    If True, then integer inputs will be promoted to the widest available integer 
    dtype, following numpy's behavior. If False, the result will have the same dtype 
    as the input. ``promote_integers`` is ignored if ``dtype`` is specified. 
&quot;&quot;&quot;</span>


<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s2">, </span><span class="s3">'promote_integers'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_reduce_sum(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
                <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False,</span>
                <span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None,</span>
                <span class="s1">promote_integers: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduction(a</span><span class="s2">, </span><span class="s3">&quot;sum&quot;</span><span class="s2">, </span><span class="s1">np.sum</span><span class="s2">, </span><span class="s1">lax.add</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">preproc=_cast_to_numeric</span><span class="s2">,</span>
                    <span class="s1">bool_op=lax.bitwise_or</span><span class="s2">, </span><span class="s1">upcast_f16_for_computation=</span><span class="s2">True,</span>
                    <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                    <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where_=where</span><span class="s2">, </span><span class="s1">parallel_reduce=lax.psum</span><span class="s2">,</span>
                    <span class="s1">promote_integers=promote_integers)</span>

<span class="s1">@_wraps(np.sum</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">extra_params=_PROMOTE_INTEGERS_DOC)</span>
<span class="s2">def </span><span class="s1">sum(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
        <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
        <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None, </span><span class="s1">promote_integers: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduce_sum(a</span><span class="s2">, </span><span class="s1">axis=_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">,</span>
                     <span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where</span><span class="s2">,</span>
                     <span class="s1">promote_integers=promote_integers)</span>


<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s2">, </span><span class="s3">'promote_integers'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_reduce_prod(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
                 <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False,</span>
                 <span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None,</span>
                 <span class="s1">promote_integers: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduction(a</span><span class="s2">, </span><span class="s3">&quot;prod&quot;</span><span class="s2">, </span><span class="s1">np.prod</span><span class="s2">, </span><span class="s1">lax.mul</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">preproc=_cast_to_numeric</span><span class="s2">,</span>
                    <span class="s1">bool_op=lax.bitwise_and</span><span class="s2">, </span><span class="s1">upcast_f16_for_computation=</span><span class="s2">True,</span>
                    <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                    <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where_=where</span><span class="s2">, </span><span class="s1">promote_integers=promote_integers)</span>

<span class="s1">@_wraps(np.prod</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">extra_params=_PROMOTE_INTEGERS_DOC)</span>
<span class="s2">def </span><span class="s1">prod(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
         <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False,</span>
         <span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None,</span>
         <span class="s1">promote_integers: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduce_prod(a</span><span class="s2">, </span><span class="s1">axis=_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">,</span>
                      <span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where</span><span class="s2">,</span>
                      <span class="s1">promote_integers=promote_integers)</span>


<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_reduce_max(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
                <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
                <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduction(a</span><span class="s2">, </span><span class="s3">&quot;max&quot;</span><span class="s2">, </span><span class="s1">np.max</span><span class="s2">, </span><span class="s1">lax.max</span><span class="s2">, </span><span class="s1">-np.inf</span><span class="s2">, </span><span class="s1">has_identity=</span><span class="s2">False,</span>
                    <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                    <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where_=where</span><span class="s2">, </span><span class="s1">parallel_reduce=lax.pmax)</span>

<span class="s1">@_wraps(np.max</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">max(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
        <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduce_max(a</span><span class="s2">, </span><span class="s1">axis=_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">,</span>
                     <span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_reduce_min(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
                <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
                <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduction(a</span><span class="s2">, </span><span class="s3">&quot;min&quot;</span><span class="s2">, </span><span class="s1">np.min</span><span class="s2">, </span><span class="s1">lax.min</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">has_identity=</span><span class="s2">False,</span>
                    <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                    <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where_=where</span><span class="s2">, </span><span class="s1">parallel_reduce=lax.pmin)</span>

<span class="s1">@_wraps(np.min</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">min(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
        <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduce_min(a</span><span class="s2">, </span><span class="s1">axis=_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">,</span>
                     <span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_reduce_all(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
                <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduction(a</span><span class="s2">, </span><span class="s3">&quot;all&quot;</span><span class="s2">, </span><span class="s1">np.all</span><span class="s2">, </span><span class="s1">lax.bitwise_and</span><span class="s2">, True, </span><span class="s1">preproc=_cast_to_bool</span><span class="s2">,</span>
                    <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where_=where)</span>

<span class="s1">@_wraps(np.all</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">all(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduce_all(a</span><span class="s2">, </span><span class="s1">axis=_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">,</span>
                     <span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_reduce_any(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
                <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduction(a</span><span class="s2">, </span><span class="s3">&quot;any&quot;</span><span class="s2">, </span><span class="s1">np.any</span><span class="s2">, </span><span class="s1">lax.bitwise_or</span><span class="s2">, False, </span><span class="s1">preproc=_cast_to_bool</span><span class="s2">,</span>
                    <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where_=where)</span>

<span class="s1">@_wraps(np.any</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">any(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_reduce_any(a</span><span class="s2">, </span><span class="s1">axis=_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">,</span>
                     <span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">product = prod</span>
<span class="s1">amin = min</span>
<span class="s1">amax = max</span>
<span class="s1">alltrue = all</span>
<span class="s1">sometrue = any</span>

<span class="s2">def </span><span class="s1">_axis_size(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Union[int</span><span class="s2">, </span><span class="s1">Sequence[int]]):</span>
  <span class="s2">if not </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
    <span class="s1">axis_seq: Sequence[int] = (axis</span><span class="s2">,</span><span class="s1">)  </span><span class="s0"># type: ignore[assignment]</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">axis_seq = axis</span>
  <span class="s1">size = </span><span class="s4">1</span>
  <span class="s1">a_shape = np.shape(a)</span>
  <span class="s2">for </span><span class="s1">a </span><span class="s2">in </span><span class="s1">axis_seq:</span>
    <span class="s1">size *= maybe_named_axis(a</span><span class="s2">, lambda </span><span class="s1">i: a_shape[i]</span><span class="s2">, lambda </span><span class="s1">name: lax.psum(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">name))</span>
  <span class="s2">return </span><span class="s1">size</span>

<span class="s1">@_wraps(np.mean</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">mean(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
         <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">,</span>
         <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_mean(a</span><span class="s2">, </span><span class="s1">_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">out</span><span class="s2">, </span><span class="s1">keepdims</span><span class="s2">,</span>
               <span class="s1">where=where)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_mean(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
          <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">,</span>
          <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;mean&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">dtype = dtypes.to_inexact_dtype(dtypes.dtype(a))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;mean&quot;</span><span class="s1">)</span>
  <span class="s1">dtype = dtypes.canonicalize_dtype(dtype)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.mean is not supported.&quot;</span><span class="s1">)</span>

  <span class="s2">if </span><span class="s1">where </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s1">normalizer = core.dimension_as_value(np.size(a))</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">normalizer = core.dimension_as_value(_axis_size(a</span><span class="s2">, </span><span class="s1">axis))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">normalizer = sum(_broadcast_to(where</span><span class="s2">, </span><span class="s1">np.shape(a))</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>

  <span class="s2">return </span><span class="s1">lax.div(</span>
      <span class="s1">sum(a</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span><span class="s2">,</span>
      <span class="s1">lax.convert_element_type(normalizer</span><span class="s2">, </span><span class="s1">dtype))</span>

<span class="s1">@overload</span>
<span class="s2">def </span><span class="s1">average(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">weights: Optional[ArrayLike] = </span><span class="s2">None,</span>
            <span class="s1">returned: Literal[</span><span class="s2">False</span><span class="s1">] = </span><span class="s2">False, </span><span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array: ...</span>
<span class="s1">@overload</span>
<span class="s2">def </span><span class="s1">average(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">weights: Optional[ArrayLike] = </span><span class="s2">None, </span><span class="s1">*</span><span class="s2">,</span>
            <span class="s1">returned: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array: ...</span>
<span class="s1">@overload</span>
<span class="s2">def </span><span class="s1">average(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">weights: Optional[ArrayLike] = </span><span class="s2">None,</span>
            <span class="s1">returned: bool = </span><span class="s2">False, </span><span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Union[Array</span><span class="s2">, </span><span class="s1">Tuple[Array</span><span class="s2">, </span><span class="s1">Array]]: ...</span>
<span class="s1">@_wraps(np.average)</span>
<span class="s2">def </span><span class="s1">average(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">weights: Optional[ArrayLike] = </span><span class="s2">None,</span>
            <span class="s1">returned: bool = </span><span class="s2">False, </span><span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Union[Array</span><span class="s2">, </span><span class="s1">Tuple[Array</span><span class="s2">, </span><span class="s1">Array]]:</span>
  <span class="s2">return </span><span class="s1">_average(a</span><span class="s2">, </span><span class="s1">_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">weights</span><span class="s2">, </span><span class="s1">returned</span><span class="s2">, </span><span class="s1">keepdims)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'returned'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">)</span><span class="s2">, </span><span class="s1">inline=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_average(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">weights: Optional[ArrayLike] = </span><span class="s2">None,</span>
             <span class="s1">returned: bool = </span><span class="s2">False, </span><span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Union[Array</span><span class="s2">, </span><span class="s1">Tuple[Array</span><span class="s2">, </span><span class="s1">Array]]:</span>
  <span class="s2">if </span><span class="s1">weights </span><span class="s2">is None</span><span class="s1">: </span><span class="s0"># Treat all weights as 1</span>
    <span class="s1">check_arraylike(</span><span class="s3">&quot;average&quot;</span><span class="s2">, </span><span class="s1">a)</span>
    <span class="s1">a</span><span class="s2">, </span><span class="s1">= promote_dtypes_inexact(a)</span>
    <span class="s1">avg = mean(a</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s1">weights_sum = lax.full(()</span><span class="s2">, </span><span class="s1">core.dimension_as_value(a.size)</span><span class="s2">, </span><span class="s1">dtype=avg.dtype)</span>
    <span class="s2">elif </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">tuple):</span>
      <span class="s1">weights_sum = lax.full_like(avg</span><span class="s2">, </span><span class="s1">math.prod(core.dimension_as_value(a.shape[d]) </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">axis))</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">weights_sum = lax.full_like(avg</span><span class="s2">, </span><span class="s1">core.dimension_as_value(a.shape[axis]))  </span><span class="s0"># type: ignore[index]</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">check_arraylike(</span><span class="s3">&quot;average&quot;</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">weights)</span>
    <span class="s1">a</span><span class="s2">, </span><span class="s1">weights = promote_dtypes_inexact(a</span><span class="s2">, </span><span class="s1">weights)</span>

    <span class="s1">a_shape = np.shape(a)</span>
    <span class="s1">a_ndim = len(a_shape)</span>
    <span class="s1">weights_shape = np.shape(weights)</span>

    <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s2">pass</span>
    <span class="s2">elif </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">tuple):</span>
      <span class="s1">axis = tuple(_canonicalize_axis(d</span><span class="s2">, </span><span class="s1">a_ndim) </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">axis)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">axis = _canonicalize_axis(axis</span><span class="s2">, </span><span class="s1">a_ndim)</span>

    <span class="s2">if </span><span class="s1">a_shape != weights_shape:</span>
      <span class="s0"># Make sure the dimensions work out</span>
      <span class="s2">if </span><span class="s1">len(weights_shape) != </span><span class="s4">1</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;1D weights expected when shapes of a and &quot;</span>
                         <span class="s3">&quot;weights differ.&quot;</span><span class="s1">)</span>
      <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Axis must be specified when shapes of a and &quot;</span>
                         <span class="s3">&quot;weights differ.&quot;</span><span class="s1">)</span>
      <span class="s2">elif </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">tuple):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Single axis expected when shapes of a and weights differ&quot;</span><span class="s1">)</span>
      <span class="s2">elif not </span><span class="s1">core.symbolic_equal_dim(weights_shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">a_shape[axis]):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;Length of weights not &quot;</span>
                         <span class="s3">&quot;compatible with specified axis.&quot;</span><span class="s1">)</span>

      <span class="s1">weights = _broadcast_to(weights</span><span class="s2">, </span><span class="s1">(a_ndim - </span><span class="s4">1</span><span class="s1">) * (</span><span class="s4">1</span><span class="s2">,</span><span class="s1">) + weights_shape)</span>
      <span class="s1">weights = _moveaxis(weights</span><span class="s2">, </span><span class="s1">-</span><span class="s4">1</span><span class="s2">, </span><span class="s1">axis)</span>

    <span class="s1">weights_sum = sum(weights</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s1">avg = sum(a * weights</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims) / weights_sum</span>

  <span class="s2">if </span><span class="s1">returned:</span>
    <span class="s2">if </span><span class="s1">avg.shape != weights_sum.shape:</span>
      <span class="s1">weights_sum = _broadcast_to(weights_sum</span><span class="s2">, </span><span class="s1">avg.shape)</span>
    <span class="s2">return </span><span class="s1">avg</span><span class="s2">, </span><span class="s1">weights_sum</span>
  <span class="s2">return </span><span class="s1">avg</span>


<span class="s1">@_wraps(np.var</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">var(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
        <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">ddof: int = </span><span class="s4">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">,</span>
        <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_var(a</span><span class="s2">, </span><span class="s1">_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">out</span><span class="s2">, </span><span class="s1">ddof</span><span class="s2">, </span><span class="s1">keepdims</span><span class="s2">,</span>
              <span class="s1">where=where)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">_var(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
         <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">ddof: int = </span><span class="s4">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">,</span>
         <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;var&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;var&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.var is not supported.&quot;</span><span class="s1">)</span>

  <span class="s1">computation_dtype</span><span class="s2">, </span><span class="s1">dtype = _var_promote_types(dtypes.dtype(a)</span><span class="s2">, </span><span class="s1">dtype)</span>
  <span class="s1">a = _asarray(a).astype(computation_dtype)</span>
  <span class="s1">a_mean = mean(a</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype=computation_dtype</span><span class="s2">, </span><span class="s1">keepdims=</span><span class="s2">True, </span><span class="s1">where=where)</span>
  <span class="s1">centered = lax.sub(a</span><span class="s2">, </span><span class="s1">a_mean)</span>
  <span class="s2">if </span><span class="s1">dtypes.issubdtype(centered.dtype</span><span class="s2">, </span><span class="s1">np.complexfloating):</span>
    <span class="s1">centered = lax.real(lax.mul(centered</span><span class="s2">, </span><span class="s1">lax.conj(centered)))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">centered = lax.square(centered)</span>

  <span class="s2">if </span><span class="s1">where </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s1">normalizer = core.dimension_as_value(np.size(a))</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">normalizer = core.dimension_as_value(_axis_size(a</span><span class="s2">, </span><span class="s1">axis))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">normalizer = sum(_broadcast_to(where</span><span class="s2">, </span><span class="s1">np.shape(a))</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>
  <span class="s1">normalizer = normalizer - ddof</span>

  <span class="s1">result = sum(centered</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>
  <span class="s1">result = lax.div(result</span><span class="s2">, </span><span class="s1">lax.convert_element_type(normalizer</span><span class="s2">, </span><span class="s1">result.dtype))</span>
  <span class="s2">return </span><span class="s1">lax.convert_element_type(result</span><span class="s2">, </span><span class="s1">dtype)</span>


<span class="s2">def </span><span class="s1">_var_promote_types(a_dtype: DTypeLike</span><span class="s2">, </span><span class="s1">dtype: DTypeLike) -&gt; Tuple[DType</span><span class="s2">, </span><span class="s1">DType]:</span>
  <span class="s2">if </span><span class="s1">dtype:</span>
    <span class="s2">if </span><span class="s1">(</span><span class="s2">not </span><span class="s1">dtypes.issubdtype(dtype</span><span class="s2">, </span><span class="s1">np.complexfloating) </span><span class="s2">and</span>
        <span class="s1">dtypes.issubdtype(a_dtype</span><span class="s2">, </span><span class="s1">np.complexfloating)):</span>
      <span class="s1">msg = (</span><span class="s3">&quot;jax.numpy.var does not yet support real dtype parameters when &quot;</span>
             <span class="s3">&quot;computing the variance of an array of complex values. The &quot;</span>
             <span class="s3">&quot;semantics of numpy.var seem unclear in this case. Please comment &quot;</span>
             <span class="s3">&quot;on https://github.com/google/jax/issues/2283 if this behavior is &quot;</span>
             <span class="s3">&quot;important to you.&quot;</span><span class="s1">)</span>
      <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
    <span class="s1">computation_dtype = dtype</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">if not </span><span class="s1">dtypes.issubdtype(a_dtype</span><span class="s2">, </span><span class="s1">np.inexact):</span>
      <span class="s1">dtype = dtypes.to_inexact_dtype(a_dtype)</span>
      <span class="s1">computation_dtype = dtype</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">dtype = _complex_elem_type(a_dtype)</span>
      <span class="s1">computation_dtype = a_dtype</span>
  <span class="s2">return </span><span class="s1">_upcast_f16(computation_dtype)</span><span class="s2">, </span><span class="s1">np.dtype(dtype)</span>


<span class="s1">@_wraps(np.std</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">std(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
        <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">ddof: int = </span><span class="s4">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">,</span>
        <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_std(a</span><span class="s2">, </span><span class="s1">_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">out</span><span class="s2">, </span><span class="s1">ddof</span><span class="s2">, </span><span class="s1">keepdims</span><span class="s2">,</span>
              <span class="s1">where=where)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">_std(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None,</span>
         <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">ddof: int = </span><span class="s4">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">*</span><span class="s2">,</span>
         <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;std&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;std&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.std is not supported.&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">lax.sqrt(var(a</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">ddof=ddof</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where))</span>


<span class="s1">@_wraps(np.ptp</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s2">def </span><span class="s1">ptp(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_ptp(a</span><span class="s2">, </span><span class="s1">_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">out</span><span class="s2">, </span><span class="s1">keepdims)</span>

<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">_ptp(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
         <span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;ptp&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.ptp is not supported.&quot;</span><span class="s1">)</span>
  <span class="s1">x = amax(a</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>
  <span class="s1">y = amin(a</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>
  <span class="s2">return </span><span class="s1">lax.sub(x</span><span class="s2">, </span><span class="s1">y)</span>


<span class="s1">@_wraps(np.count_nonzero)</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">count_nonzero(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None,</span>
                  <span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;count_nonzero&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s2">return </span><span class="s1">sum(lax.ne(a</span><span class="s2">, </span><span class="s1">_lax_const(a</span><span class="s2">, </span><span class="s4">0</span><span class="s1">))</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">,</span>
             <span class="s1">dtype=dtypes.canonicalize_dtype(np.int_)</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>


<span class="s2">def </span><span class="s1">_nan_reduction(a: ArrayLike</span><span class="s2">, </span><span class="s1">name: str</span><span class="s2">, </span><span class="s1">jnp_reduction: Callable[...</span><span class="s2">, </span><span class="s1">Array]</span><span class="s2">,</span>
                   <span class="s1">init_val: ArrayLike</span><span class="s2">, </span><span class="s1">nan_if_all_nan: bool</span><span class="s2">,</span>
                   <span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">**kwargs) -&gt; Array:</span>
  <span class="s1">check_arraylike(name</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s2">if not </span><span class="s1">dtypes.issubdtype(dtypes.dtype(a)</span><span class="s2">, </span><span class="s1">np.inexact):</span>
    <span class="s2">return </span><span class="s1">jnp_reduction(a</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">**kwargs)</span>

  <span class="s1">out = jnp_reduction(_where(lax_internal._isnan(a)</span><span class="s2">, </span><span class="s1">_reduction_init_val(a</span><span class="s2">, </span><span class="s1">init_val)</span><span class="s2">, </span><span class="s1">a)</span><span class="s2">,</span>
                      <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">**kwargs)</span>
  <span class="s2">if </span><span class="s1">nan_if_all_nan:</span>
    <span class="s2">return </span><span class="s1">_where(all(lax_internal._isnan(a)</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span><span class="s2">,</span>
                  <span class="s1">_lax_const(a</span><span class="s2">, </span><span class="s1">np.nan)</span><span class="s2">, </span><span class="s1">out)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">out</span>

<span class="s1">@_wraps(np.nanmin</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanmin(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
           <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
           <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_nan_reduction(a</span><span class="s2">, </span><span class="s3">'nanmin'</span><span class="s2">, </span><span class="s1">min</span><span class="s2">, </span><span class="s1">np.inf</span><span class="s2">, </span><span class="s1">nan_if_all_nan=initial </span><span class="s2">is None,</span>
                        <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                        <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">@_wraps(np.nanmax</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanmax(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
           <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
           <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">return </span><span class="s1">_nan_reduction(a</span><span class="s2">, </span><span class="s3">'nanmax'</span><span class="s2">, </span><span class="s1">max</span><span class="s2">, </span><span class="s1">-np.inf</span><span class="s2">, </span><span class="s1">nan_if_all_nan=initial </span><span class="s2">is None,</span>
                        <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                        <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">@_wraps(np.nansum</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nansum(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
           <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
           <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;nanprod&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">_nan_reduction(a</span><span class="s2">, </span><span class="s3">'nansum'</span><span class="s2">, </span><span class="s1">sum</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">nan_if_all_nan=</span><span class="s2">False,</span>
                        <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                        <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s0"># Work around a sphinx documentation warning in NumPy 1.22.</span>
<span class="s2">if </span><span class="s1">nansum.__doc__ </span><span class="s2">is not None</span><span class="s1">:</span>
  <span class="s1">nansum.__doc__ = nansum.__doc__.replace(</span><span class="s3">&quot;</span><span class="s2">\n\n\n</span><span class="s3">&quot;</span><span class="s2">, </span><span class="s3">&quot;</span><span class="s2">\n\n</span><span class="s3">&quot;</span><span class="s1">)</span>

<span class="s1">@_wraps(np.nanprod</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanprod(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
            <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">initial: Optional[ArrayLike] = </span><span class="s2">None,</span>
            <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;nanprod&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">_nan_reduction(a</span><span class="s2">, </span><span class="s3">'nanprod'</span><span class="s2">, </span><span class="s1">prod</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">nan_if_all_nan=</span><span class="s2">False,</span>
                        <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                        <span class="s1">initial=initial</span><span class="s2">, </span><span class="s1">where=where)</span>

<span class="s1">@_wraps(np.nanmean</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanmean(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
            <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;nanmean&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;nanmean&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.nanmean is not supported.&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">dtypes.issubdtype(dtypes.dtype(a)</span><span class="s2">, </span><span class="s1">np.bool_) </span><span class="s2">or </span><span class="s1">dtypes.issubdtype(dtypes.dtype(a)</span><span class="s2">, </span><span class="s1">np.integer):</span>
    <span class="s2">return </span><span class="s1">mean(a</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">out</span><span class="s2">, </span><span class="s1">keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>
  <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">dtype = dtypes.dtype(a)</span>
  <span class="s1">nan_mask = lax_internal.bitwise_not(lax_internal._isnan(a))</span>
  <span class="s1">normalizer = sum(nan_mask</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=np.int32</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>
  <span class="s1">normalizer = lax.convert_element_type(normalizer</span><span class="s2">, </span><span class="s1">dtype)</span>
  <span class="s1">td = lax.div(nansum(a</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span><span class="s2">, </span><span class="s1">normalizer)</span>
  <span class="s2">return </span><span class="s1">td</span>


<span class="s1">@_wraps(np.nanvar</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanvar(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
           <span class="s1">ddof: int = </span><span class="s4">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False,</span>
           <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;nanvar&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;nanvar&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.nanvar is not supported.&quot;</span><span class="s1">)</span>

  <span class="s1">computation_dtype</span><span class="s2">, </span><span class="s1">dtype = _var_promote_types(dtypes.dtype(a)</span><span class="s2">, </span><span class="s1">dtype)</span>
  <span class="s1">a = _asarray(a).astype(computation_dtype)</span>
  <span class="s1">a_mean = nanmean(a</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">dtype=computation_dtype</span><span class="s2">, </span><span class="s1">keepdims=</span><span class="s2">True, </span><span class="s1">where=where)</span>

  <span class="s1">centered = _where(lax_internal._isnan(a)</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">lax.sub(a</span><span class="s2">, </span><span class="s1">a_mean))  </span><span class="s0"># double-where trick for gradients.</span>
  <span class="s2">if </span><span class="s1">dtypes.issubdtype(centered.dtype</span><span class="s2">, </span><span class="s1">np.complexfloating):</span>
    <span class="s1">centered = lax.real(lax.mul(centered</span><span class="s2">, </span><span class="s1">lax.conj(centered)))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">centered = lax.square(centered)</span>

  <span class="s1">normalizer = sum(lax_internal.bitwise_not(lax_internal._isnan(a))</span><span class="s2">,</span>
                   <span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>
  <span class="s1">normalizer = normalizer - ddof</span>
  <span class="s1">normalizer_mask = lax.le(normalizer</span><span class="s2">, </span><span class="s1">lax_internal._zero(normalizer))</span>
  <span class="s1">result = sum(centered</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where)</span>
  <span class="s1">result = _where(normalizer_mask</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">result)</span>
  <span class="s1">divisor = _where(normalizer_mask</span><span class="s2">, </span><span class="s4">1</span><span class="s2">, </span><span class="s1">normalizer)</span>
  <span class="s1">result = lax.div(result</span><span class="s2">, </span><span class="s1">lax.convert_element_type(divisor</span><span class="s2">, </span><span class="s1">result.dtype))</span>
  <span class="s2">return </span><span class="s1">lax.convert_element_type(result</span><span class="s2">, </span><span class="s1">dtype)</span>


<span class="s1">@_wraps(np.nanstd</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanstd(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None, </span><span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
           <span class="s1">ddof: int = </span><span class="s4">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">False,</span>
           <span class="s1">where: Optional[ArrayLike] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;nanstd&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s3">&quot;nanstd&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">&quot;The 'out' argument to jnp.nanstd is not supported.&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">lax.sqrt(nanvar(a</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">ddof=ddof</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">where=where))</span>


<span class="s0"># TODO(jakevdp): use a protocol here for better typing?</span>
<span class="s2">def </span><span class="s1">_make_cumulative_reduction(np_reduction: Any</span><span class="s2">, </span><span class="s1">reduction: Callable[...</span><span class="s2">, </span><span class="s1">Array]</span><span class="s2">,</span>
                               <span class="s1">fill_nan: bool = </span><span class="s2">False, </span><span class="s1">fill_value: ArrayLike = </span><span class="s4">0</span><span class="s1">) -&gt; Callable[...</span><span class="s2">, </span><span class="s1">Array]:</span>
  <span class="s1">@_wraps(np_reduction</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s1">])</span>
  <span class="s2">def </span><span class="s1">cumulative_reduction(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None,</span>
                           <span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
    <span class="s2">return </span><span class="s1">_cumulative_reduction(a</span><span class="s2">, </span><span class="s1">_ensure_optional_axes(axis)</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">out)</span>

  <span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'dtype'</span><span class="s1">))</span>
  <span class="s2">def </span><span class="s1">_cumulative_reduction(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s2">None,</span>
                            <span class="s1">dtype: DTypeLike = </span><span class="s2">None, </span><span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
    <span class="s1">check_arraylike(np_reduction.__name__</span><span class="s2">, </span><span class="s1">a)</span>
    <span class="s2">if </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
      <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">f&quot;The 'out' argument to jnp.</span><span class="s2">{</span><span class="s1">np_reduction.__name__</span><span class="s2">} </span><span class="s3">&quot;</span>
                                <span class="s3">f&quot;is not supported.&quot;</span><span class="s1">)</span>
    <span class="s1">dtypes.check_user_dtype_supported(dtype</span><span class="s2">, </span><span class="s1">np_reduction.__name__)</span>

    <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None or </span><span class="s1">_isscalar(a):</span>
      <span class="s1">a = lax.reshape(a</span><span class="s2">, </span><span class="s1">(np.size(a)</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s1">axis = </span><span class="s4">0</span>

    <span class="s1">a_shape = list(np.shape(a))</span>
    <span class="s1">num_dims = len(a_shape)</span>
    <span class="s1">axis = _canonicalize_axis(axis</span><span class="s2">, </span><span class="s1">num_dims)</span>

    <span class="s2">if </span><span class="s1">fill_nan:</span>
      <span class="s1">a = _where(lax_internal._isnan(a)</span><span class="s2">, </span><span class="s1">_lax_const(a</span><span class="s2">, </span><span class="s1">fill_value)</span><span class="s2">, </span><span class="s1">a)</span>

    <span class="s2">if not </span><span class="s1">dtype </span><span class="s2">and </span><span class="s1">dtypes.dtype(a) == np.bool_:</span>
      <span class="s1">dtype = dtypes.canonicalize_dtype(dtypes.int_)</span>
    <span class="s2">if </span><span class="s1">dtype:</span>
      <span class="s1">a = lax.convert_element_type(a</span><span class="s2">, </span><span class="s1">dtype)</span>

    <span class="s2">return </span><span class="s1">reduction(a</span><span class="s2">, </span><span class="s1">axis)</span>

  <span class="s2">return </span><span class="s1">cumulative_reduction</span>


<span class="s1">cumsum = _make_cumulative_reduction(np.cumsum</span><span class="s2">, </span><span class="s1">lax.cumsum</span><span class="s2">, </span><span class="s1">fill_nan=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s1">cumprod = _make_cumulative_reduction(np.cumprod</span><span class="s2">, </span><span class="s1">lax.cumprod</span><span class="s2">, </span><span class="s1">fill_nan=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s1">cumproduct = cumprod</span>
<span class="s1">nancumsum = _make_cumulative_reduction(np.nancumsum</span><span class="s2">, </span><span class="s1">lax.cumsum</span><span class="s2">,</span>
                                       <span class="s1">fill_nan=</span><span class="s2">True, </span><span class="s1">fill_value=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">nancumprod = _make_cumulative_reduction(np.nancumprod</span><span class="s2">, </span><span class="s1">lax.cumprod</span><span class="s2">,</span>
                                        <span class="s1">fill_nan=</span><span class="s2">True, </span><span class="s1">fill_value=</span><span class="s4">1</span><span class="s1">)</span>

<span class="s0"># Quantiles</span>
<span class="s1">@_wraps(np.quantile</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s2">, </span><span class="s3">'interpolation'</span><span class="s2">,</span>
                               <span class="s3">'keepdims'</span><span class="s2">, </span><span class="s3">'method'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">quantile(a: ArrayLike</span><span class="s2">, </span><span class="s1">q: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]] = </span><span class="s2">None,</span>
             <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">overwrite_input: bool = </span><span class="s2">False, </span><span class="s1">method: str = </span><span class="s3">&quot;linear&quot;</span><span class="s2">,</span>
             <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">interpolation: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;quantile&quot;</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">q)</span>
  <span class="s2">if </span><span class="s1">overwrite_input </span><span class="s2">or </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">msg = (</span><span class="s3">&quot;jax.numpy.quantile does not support overwrite_input=True or &quot;</span>
           <span class="s3">&quot;out != None&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
  <span class="s2">if </span><span class="s1">interpolation </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">warnings.warn(</span><span class="s3">&quot;The interpolation= argument to 'quantile' is deprecated. &quot;</span>
                  <span class="s3">&quot;Use 'method=' instead.&quot;</span><span class="s2">, </span><span class="s1">DeprecationWarning)</span>
  <span class="s2">return </span><span class="s1">_quantile(_asarray(a)</span><span class="s2">, </span><span class="s1">_asarray(q)</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">interpolation </span><span class="s2">or </span><span class="s1">method</span><span class="s2">, </span><span class="s1">keepdims</span><span class="s2">, False</span><span class="s1">)</span>

<span class="s1">@_wraps(np.nanquantile</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s2">, </span><span class="s3">'interpolation'</span><span class="s2">,</span>
                               <span class="s3">'keepdims'</span><span class="s2">, </span><span class="s3">'method'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanquantile(a: ArrayLike</span><span class="s2">, </span><span class="s1">q: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]] = </span><span class="s2">None,</span>
                <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">overwrite_input: bool = </span><span class="s2">False, </span><span class="s1">method: str = </span><span class="s3">&quot;linear&quot;</span><span class="s2">,</span>
                <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">interpolation: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;nanquantile&quot;</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">q)</span>
  <span class="s2">if </span><span class="s1">overwrite_input </span><span class="s2">or </span><span class="s1">out </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">msg = (</span><span class="s3">&quot;jax.numpy.nanquantile does not support overwrite_input=True or &quot;</span>
           <span class="s3">&quot;out != None&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
  <span class="s2">if </span><span class="s1">interpolation </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">warnings.warn(</span><span class="s3">&quot;The interpolation= argument to 'nanquantile' is deprecated. &quot;</span>
                  <span class="s3">&quot;Use 'method=' instead.&quot;</span><span class="s2">, </span><span class="s1">DeprecationWarning)</span>
  <span class="s2">return </span><span class="s1">_quantile(_asarray(a)</span><span class="s2">, </span><span class="s1">_asarray(q)</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">interpolation </span><span class="s2">or </span><span class="s1">method</span><span class="s2">, </span><span class="s1">keepdims</span><span class="s2">, True</span><span class="s1">)</span>

<span class="s2">def </span><span class="s1">_quantile(a: Array</span><span class="s2">, </span><span class="s1">q: Array</span><span class="s2">, </span><span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]]</span><span class="s2">,</span>
              <span class="s1">interpolation: str</span><span class="s2">, </span><span class="s1">keepdims: bool</span><span class="s2">, </span><span class="s1">squash_nans: bool) -&gt; Array:</span>
  <span class="s2">if </span><span class="s1">interpolation </span><span class="s2">not in </span><span class="s1">[</span><span class="s3">&quot;linear&quot;</span><span class="s2">, </span><span class="s3">&quot;lower&quot;</span><span class="s2">, </span><span class="s3">&quot;higher&quot;</span><span class="s2">, </span><span class="s3">&quot;midpoint&quot;</span><span class="s2">, </span><span class="s3">&quot;nearest&quot;</span><span class="s1">]:</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;interpolation can only be 'linear', 'lower', 'higher', &quot;</span>
                     <span class="s3">&quot;'midpoint', or 'nearest'&quot;</span><span class="s1">)</span>
  <span class="s1">a</span><span class="s2">, </span><span class="s1">= promote_dtypes_inexact(a)</span>
  <span class="s1">keepdim = []</span>
  <span class="s2">if </span><span class="s1">dtypes.issubdtype(a.dtype</span><span class="s2">, </span><span class="s1">np.complexfloating):</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;quantile does not support complex input, as the operation is poorly defined.&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">axis </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">a = a.ravel()</span>
    <span class="s1">axis = </span><span class="s4">0</span>
  <span class="s2">elif </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">tuple):</span>
    <span class="s1">keepdim = list(a.shape)</span>
    <span class="s1">nd = a.ndim</span>
    <span class="s1">axis = tuple(_canonicalize_axis(ax</span><span class="s2">, </span><span class="s1">nd) </span><span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">axis)</span>
    <span class="s2">if </span><span class="s1">len(set(axis)) != len(axis):</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">'repeated axis'</span><span class="s1">)</span>
    <span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">axis:</span>
      <span class="s1">keepdim[ax] = </span><span class="s4">1</span>

    <span class="s1">keep = set(range(nd)) - set(axis)</span>
    <span class="s0"># prepare permutation</span>
    <span class="s1">dimensions = list(range(nd))</span>
    <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">s </span><span class="s2">in </span><span class="s1">enumerate(sorted(keep)):</span>
      <span class="s1">dimensions[i]</span><span class="s2">, </span><span class="s1">dimensions[s] = dimensions[s]</span><span class="s2">, </span><span class="s1">dimensions[i]</span>
    <span class="s1">do_not_touch_shape = tuple(x </span><span class="s2">for </span><span class="s1">idx</span><span class="s2">,</span><span class="s1">x </span><span class="s2">in </span><span class="s1">enumerate(a.shape) </span><span class="s2">if </span><span class="s1">idx </span><span class="s2">not in </span><span class="s1">axis)</span>
    <span class="s1">touch_shape = tuple(x </span><span class="s2">for </span><span class="s1">idx</span><span class="s2">,</span><span class="s1">x </span><span class="s2">in </span><span class="s1">enumerate(a.shape) </span><span class="s2">if </span><span class="s1">idx </span><span class="s2">in </span><span class="s1">axis)</span>
    <span class="s1">a = lax.reshape(a</span><span class="s2">, </span><span class="s1">do_not_touch_shape + (int(np.prod(touch_shape))</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dimensions)</span>
    <span class="s1">axis = _canonicalize_axis(-</span><span class="s4">1</span><span class="s2">, </span><span class="s1">a.ndim)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">axis = _canonicalize_axis(axis</span><span class="s2">, </span><span class="s1">a.ndim)</span>

  <span class="s1">q_shape = q.shape</span>
  <span class="s1">q_ndim = q.ndim</span>
  <span class="s2">if </span><span class="s1">q_ndim &gt; </span><span class="s4">1</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;q must be have rank &lt;= 1, got shape </span><span class="s2">{</span><span class="s1">q.shape</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>

  <span class="s1">a_shape = a.shape</span>

  <span class="s2">if </span><span class="s1">squash_nans:</span>
    <span class="s1">a = _where(ufuncs.isnan(a)</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">a) </span><span class="s0"># Ensure nans are positive so they sort to the end.</span>
    <span class="s1">a = lax.sort(a</span><span class="s2">, </span><span class="s1">dimension=axis)</span>
    <span class="s1">counts = sum(ufuncs.logical_not(ufuncs.isnan(a))</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dtype=q.dtype</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>
    <span class="s1">shape_after_reduction = counts.shape</span>
    <span class="s1">q = lax.expand_dims(</span>
      <span class="s1">q</span><span class="s2">, </span><span class="s1">tuple(range(q_ndim</span><span class="s2">, </span><span class="s1">len(shape_after_reduction) + q_ndim)))</span>
    <span class="s1">counts = lax.expand_dims(counts</span><span class="s2">, </span><span class="s1">tuple(range(q_ndim)))</span>
    <span class="s1">q = lax.mul(q</span><span class="s2">, </span><span class="s1">lax.sub(counts</span><span class="s2">, </span><span class="s1">_lax_const(q</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)))</span>
    <span class="s1">low = lax.floor(q)</span>
    <span class="s1">high = lax.ceil(q)</span>
    <span class="s1">high_weight = lax.sub(q</span><span class="s2">, </span><span class="s1">low)</span>
    <span class="s1">low_weight = lax.sub(_lax_const(high_weight</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">high_weight)</span>

    <span class="s1">low = lax.max(_lax_const(low</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">lax.min(low</span><span class="s2">, </span><span class="s1">counts - </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">high = lax.max(_lax_const(high</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">lax.min(high</span><span class="s2">, </span><span class="s1">counts - </span><span class="s4">1</span><span class="s1">))</span>
    <span class="s1">low = lax.convert_element_type(low</span><span class="s2">, </span><span class="s1">int)</span>
    <span class="s1">high = lax.convert_element_type(high</span><span class="s2">, </span><span class="s1">int)</span>
    <span class="s1">out_shape = q_shape + shape_after_reduction</span>
    <span class="s1">index = [lax.broadcasted_iota(int</span><span class="s2">, </span><span class="s1">out_shape</span><span class="s2">, </span><span class="s1">dim + q_ndim)</span>
             <span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">range(len(shape_after_reduction))]</span>
    <span class="s2">if </span><span class="s1">keepdims:</span>
      <span class="s1">index[axis] = low</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">index.insert(axis</span><span class="s2">, </span><span class="s1">low)</span>
    <span class="s1">low_value = a[tuple(index)]</span>
    <span class="s1">index[axis] = high</span>
    <span class="s1">high_value = a[tuple(index)]</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">a = _where(any(ufuncs.isnan(a)</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">keepdims=</span><span class="s2">True</span><span class="s1">)</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s1">a)</span>
    <span class="s1">a = lax.sort(a</span><span class="s2">, </span><span class="s1">dimension=axis)</span>
    <span class="s1">n = lax.convert_element_type(a_shape[axis]</span><span class="s2">, </span><span class="s1">lax_internal._dtype(q))</span>
    <span class="s1">q = lax.mul(q</span><span class="s2">, </span><span class="s1">n - </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">low = lax.floor(q)</span>
    <span class="s1">high = lax.ceil(q)</span>
    <span class="s1">high_weight = lax.sub(q</span><span class="s2">, </span><span class="s1">low)</span>
    <span class="s1">low_weight = lax.sub(_lax_const(high_weight</span><span class="s2">, </span><span class="s4">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">high_weight)</span>

    <span class="s1">low = lax.clamp(_lax_const(low</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">n - </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">high = lax.clamp(_lax_const(high</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">high</span><span class="s2">, </span><span class="s1">n - </span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">low = lax.convert_element_type(low</span><span class="s2">, </span><span class="s1">int)</span>
    <span class="s1">high = lax.convert_element_type(high</span><span class="s2">, </span><span class="s1">int)</span>

    <span class="s1">slice_sizes = list(a_shape)</span>
    <span class="s1">slice_sizes[axis] = </span><span class="s4">1</span>
    <span class="s1">dnums = lax.GatherDimensionNumbers(</span>
      <span class="s1">offset_dims=tuple(range(</span>
        <span class="s1">q_ndim</span><span class="s2">,</span>
        <span class="s1">len(a_shape) + q_ndim </span><span class="s2">if </span><span class="s1">keepdims </span><span class="s2">else </span><span class="s1">len(a_shape) + q_ndim - </span><span class="s4">1</span><span class="s1">))</span><span class="s2">,</span>
      <span class="s1">collapsed_slice_dims=() </span><span class="s2">if </span><span class="s1">keepdims </span><span class="s2">else </span><span class="s1">(axis</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
      <span class="s1">start_index_map=(axis</span><span class="s2">,</span><span class="s1">))</span>
    <span class="s1">low_value = lax.gather(a</span><span class="s2">, </span><span class="s1">low[...</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                           <span class="s1">slice_sizes=slice_sizes)</span>
    <span class="s1">high_value = lax.gather(a</span><span class="s2">, </span><span class="s1">high[...</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                            <span class="s1">slice_sizes=slice_sizes)</span>
    <span class="s2">if </span><span class="s1">q_ndim == </span><span class="s4">1</span><span class="s1">:</span>
      <span class="s1">low_weight = lax.broadcast_in_dim(low_weight</span><span class="s2">, </span><span class="s1">low_value.shape</span><span class="s2">,</span>
                                        <span class="s1">broadcast_dimensions=(</span><span class="s4">0</span><span class="s2">,</span><span class="s1">))</span>
      <span class="s1">high_weight = lax.broadcast_in_dim(high_weight</span><span class="s2">, </span><span class="s1">high_value.shape</span><span class="s2">,</span>
                                        <span class="s1">broadcast_dimensions=(</span><span class="s4">0</span><span class="s2">,</span><span class="s1">))</span>

  <span class="s2">if </span><span class="s1">interpolation == </span><span class="s3">&quot;linear&quot;</span><span class="s1">:</span>
    <span class="s1">result = lax.add(lax.mul(low_value.astype(q.dtype)</span><span class="s2">, </span><span class="s1">low_weight)</span><span class="s2">,</span>
                     <span class="s1">lax.mul(high_value.astype(q.dtype)</span><span class="s2">, </span><span class="s1">high_weight))</span>
  <span class="s2">elif </span><span class="s1">interpolation == </span><span class="s3">&quot;lower&quot;</span><span class="s1">:</span>
    <span class="s1">result = low_value</span>
  <span class="s2">elif </span><span class="s1">interpolation == </span><span class="s3">&quot;higher&quot;</span><span class="s1">:</span>
    <span class="s1">result = high_value</span>
  <span class="s2">elif </span><span class="s1">interpolation == </span><span class="s3">&quot;nearest&quot;</span><span class="s1">:</span>
    <span class="s1">pred = lax.le(high_weight</span><span class="s2">, </span><span class="s1">_lax_const(high_weight</span><span class="s2">, </span><span class="s4">0.5</span><span class="s1">))</span>
    <span class="s1">result = lax.select(pred</span><span class="s2">, </span><span class="s1">low_value</span><span class="s2">, </span><span class="s1">high_value)</span>
  <span class="s2">elif </span><span class="s1">interpolation == </span><span class="s3">&quot;midpoint&quot;</span><span class="s1">:</span>
    <span class="s1">result = lax.mul(lax.add(low_value</span><span class="s2">, </span><span class="s1">high_value)</span><span class="s2">, </span><span class="s1">_lax_const(low_value</span><span class="s2">, </span><span class="s4">0.5</span><span class="s1">))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;interpolation=</span><span class="s2">{</span><span class="s1">interpolation</span><span class="s2">!r} </span><span class="s3">not recognized&quot;</span><span class="s1">)</span>
  <span class="s2">if </span><span class="s1">keepdims </span><span class="s2">and </span><span class="s1">keepdim:</span>
    <span class="s2">if </span><span class="s1">q_ndim &gt; </span><span class="s4">0</span><span class="s1">:</span>
      <span class="s1">keepdim = [np.shape(q)[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">*keepdim]</span>
    <span class="s1">result = result.reshape(keepdim)</span>
  <span class="s2">return </span><span class="s1">lax.convert_element_type(result</span><span class="s2">, </span><span class="s1">a.dtype)</span>

<span class="s1">@_wraps(np.percentile</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s2">, </span><span class="s3">'interpolation'</span><span class="s2">,</span>
                                   <span class="s3">'keepdims'</span><span class="s2">, </span><span class="s3">'method'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">percentile(a: ArrayLike</span><span class="s2">, </span><span class="s1">q: ArrayLike</span><span class="s2">,</span>
               <span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]] = </span><span class="s2">None,</span>
               <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">overwrite_input: bool = </span><span class="s2">False, </span><span class="s1">method: str = </span><span class="s3">&quot;linear&quot;</span><span class="s2">,</span>
               <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">interpolation: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;percentile&quot;</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">q)</span>
  <span class="s1">q</span><span class="s2">, </span><span class="s1">= promote_dtypes_inexact(q)</span>
  <span class="s2">return </span><span class="s1">quantile(a</span><span class="s2">, </span><span class="s1">q / </span><span class="s4">100</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">overwrite_input=overwrite_input</span><span class="s2">,</span>
                  <span class="s1">interpolation=interpolation</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">keepdims=keepdims)</span>

<span class="s1">@_wraps(np.nanpercentile</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s2">, </span><span class="s3">'interpolation'</span><span class="s2">,</span>
                               <span class="s3">'keepdims'</span><span class="s2">, </span><span class="s3">'method'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanpercentile(a: ArrayLike</span><span class="s2">, </span><span class="s1">q: ArrayLike</span><span class="s2">,</span>
                  <span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]] = </span><span class="s2">None,</span>
                  <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">overwrite_input: bool = </span><span class="s2">False, </span><span class="s1">method: str = </span><span class="s3">&quot;linear&quot;</span><span class="s2">,</span>
                  <span class="s1">keepdims: bool = </span><span class="s2">False, </span><span class="s1">interpolation: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;nanpercentile&quot;</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">q)</span>
  <span class="s1">q = ufuncs.true_divide(q</span><span class="s2">, </span><span class="s4">100.0</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">nanquantile(a</span><span class="s2">, </span><span class="s1">q</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">overwrite_input=overwrite_input</span><span class="s2">,</span>
                     <span class="s1">interpolation=interpolation</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">,</span>
                     <span class="s1">keepdims=keepdims)</span>

<span class="s1">@_wraps(np.median</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">median(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]] = </span><span class="s2">None,</span>
           <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">overwrite_input: bool = </span><span class="s2">False,</span>
           <span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;median&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s2">return </span><span class="s1">quantile(a</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">, </span><span class="s1">overwrite_input=overwrite_input</span><span class="s2">,</span>
                  <span class="s1">keepdims=keepdims</span><span class="s2">, </span><span class="s1">method=</span><span class="s3">'midpoint'</span><span class="s1">)</span>

<span class="s1">@_wraps(np.nanmedian</span><span class="s2">, </span><span class="s1">skip_params=[</span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s1">])</span>
<span class="s1">@partial(api.jit</span><span class="s2">, </span><span class="s1">static_argnames=(</span><span class="s3">'axis'</span><span class="s2">, </span><span class="s3">'overwrite_input'</span><span class="s2">, </span><span class="s3">'keepdims'</span><span class="s1">))</span>
<span class="s2">def </span><span class="s1">nanmedian(a: ArrayLike</span><span class="s2">, </span><span class="s1">axis: Optional[Union[int</span><span class="s2">, </span><span class="s1">Tuple[int</span><span class="s2">, </span><span class="s1">...]]] = </span><span class="s2">None,</span>
              <span class="s1">out: </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">overwrite_input: bool = </span><span class="s2">False,</span>
              <span class="s1">keepdims: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s1">check_arraylike(</span><span class="s3">&quot;nanmedian&quot;</span><span class="s2">, </span><span class="s1">a)</span>
  <span class="s2">return </span><span class="s1">nanquantile(a</span><span class="s2">, </span><span class="s4">0.5</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">out=out</span><span class="s2">,</span>
                     <span class="s1">overwrite_input=overwrite_input</span><span class="s2">, </span><span class="s1">keepdims=keepdims</span><span class="s2">,</span>
                     <span class="s1">method=</span><span class="s3">'midpoint'</span><span class="s1">)</span>
</pre>
</body>
</html>