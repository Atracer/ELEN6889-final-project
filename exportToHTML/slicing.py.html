<html>
<head>
<title>slicing.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
slicing.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2018 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">import </span><span class="s1">enum</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">Callable</span><span class="s2">, </span><span class="s1">List</span><span class="s2">, </span><span class="s1">NamedTuple</span><span class="s2">, </span><span class="s1">Optional</span><span class="s2">, </span><span class="s1">Sequence</span><span class="s2">, </span><span class="s1">Tuple</span><span class="s2">, </span><span class="s1">Union</span>
<span class="s2">import </span><span class="s1">weakref</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">import </span><span class="s1">jax</span>

<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">ad_util</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">core</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">dtypes</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">source_info_util</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">util</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">ad</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">batching</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">mlir</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">partial_eval </span><span class="s2">as </span><span class="s1">pe</span>
<span class="s2">from </span><span class="s1">jax._src.lax </span><span class="s2">import </span><span class="s1">lax</span>
<span class="s2">from </span><span class="s1">jax._src.lax.utils </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">_argnum_weak_type</span><span class="s2">,</span>
    <span class="s1">_input_dtype</span><span class="s2">,</span>
    <span class="s1">standard_primitive</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">jax._src.lib.mlir </span><span class="s2">import </span><span class="s1">ir</span>
<span class="s2">from </span><span class="s1">jax._src.lib.mlir.dialects </span><span class="s2">import </span><span class="s1">hlo</span>
<span class="s2">from </span><span class="s1">jax._src.typing </span><span class="s2">import </span><span class="s1">Array</span><span class="s2">, </span><span class="s1">ArrayLike</span><span class="s2">, </span><span class="s1">Shape</span>
<span class="s2">from </span><span class="s1">jax._src.util </span><span class="s2">import </span><span class="s1">safe_map</span><span class="s2">, </span><span class="s1">safe_zip</span>

<span class="s1">map</span><span class="s2">, </span><span class="s1">unsafe_map = safe_map</span><span class="s2">, </span><span class="s1">map</span>
<span class="s1">zip</span><span class="s2">, </span><span class="s1">unsafe_zip = safe_zip</span><span class="s2">, </span><span class="s1">zip</span>

<span class="s1">_dtype = partial(dtypes.dtype</span><span class="s2">, </span><span class="s1">canonicalize=</span><span class="s2">True</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">slice(operand: ArrayLike</span><span class="s2">, </span><span class="s1">start_indices: Sequence[int]</span><span class="s2">,</span>
          <span class="s1">limit_indices: Sequence[int]</span><span class="s2">,</span>
          <span class="s1">strides: Optional[Sequence[int]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Wraps XLA's `Slice 
  &lt;https://www.tensorflow.org/xla/operation_semantics#slice&gt;`_ 
  operator. 
  &quot;&quot;&quot;</span>
  <span class="s2">return </span><span class="s1">slice_p.bind(operand</span><span class="s2">, </span><span class="s1">start_indices=tuple(start_indices)</span><span class="s2">,</span>
                      <span class="s1">limit_indices=tuple(limit_indices)</span><span class="s2">,</span>
                      <span class="s1">strides=</span><span class="s2">None if </span><span class="s1">strides </span><span class="s2">is None else </span><span class="s1">tuple(strides))</span>


<span class="s2">def </span><span class="s1">dynamic_slice(</span>
    <span class="s1">operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">,</span>
    <span class="s1">start_indices: Union[Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">Sequence[ArrayLike]]</span><span class="s2">,</span>
    <span class="s1">slice_sizes: Shape</span><span class="s2">,</span>
<span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Wraps XLA's `DynamicSlice 
  &lt;https://www.tensorflow.org/xla/operation_semantics#dynamicslice&gt;`_ 
  operator. 
 
  Args: 
    operand: an array to slice. 
    start_indices: a list of scalar indices, one per dimension. These values 
      may be dynamic. 
    slice_sizes: the size of the slice. Must be a sequence of non-negative 
      integers with length equal to `ndim(operand)`. Inside a JIT compiled 
      function, only static values are supported (all JAX arrays inside JIT 
      must have statically known size). 
 
  Returns: 
    An array containing the slice. 
 
  Examples: 
    Here is a simple two-dimensional dynamic slice: 
 
    &gt;&gt;&gt; x = jnp.arange(12).reshape(3, 4) 
    &gt;&gt;&gt; x 
    Array([[ 0,  1,  2,  3], 
           [ 4,  5,  6,  7], 
           [ 8,  9, 10, 11]], dtype=int32) 
 
    &gt;&gt;&gt; dynamic_slice(x, (1, 1), (2, 3)) 
    Array([[ 5,  6,  7], 
           [ 9, 10, 11]], dtype=int32) 
 
    Note the potentially surprising behavior for the case where the requested slice 
    overruns the bounds of the array; in this case the start index is adjusted to 
    return a slice of the requested size: 
 
    &gt;&gt;&gt; dynamic_slice(x, (1, 1), (2, 4)) 
    Array([[ 4,  5,  6,  7], 
           [ 8,  9, 10, 11]], dtype=int32) 
  &quot;&quot;&quot;</span>
  <span class="s1">start_indices = _dynamic_slice_indices(operand</span><span class="s2">, </span><span class="s1">start_indices)</span>
  <span class="s2">if </span><span class="s1">jax.config.jax_dynamic_shapes:</span>
    <span class="s1">dynamic_sizes</span><span class="s2">, </span><span class="s1">static_sizes = lax._extract_tracers_dyn_shape(slice_sizes)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">dynamic_sizes = []</span>
    <span class="s1">static_sizes = core.canonicalize_shape(slice_sizes)  </span><span class="s0"># type: ignore</span>
  <span class="s2">return </span><span class="s1">dynamic_slice_p.bind(operand</span><span class="s2">, </span><span class="s1">*start_indices</span><span class="s2">, </span><span class="s1">*dynamic_sizes</span><span class="s2">,</span>
                              <span class="s1">slice_sizes=tuple(static_sizes))</span>


<span class="s2">def </span><span class="s1">dynamic_update_slice(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">update: ArrayLike</span><span class="s2">,</span>
                         <span class="s1">start_indices: Union[Array</span><span class="s2">, </span><span class="s1">Sequence[ArrayLike]]) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Wraps XLA's `DynamicUpdateSlice 
  &lt;https://www.tensorflow.org/xla/operation_semantics#dynamicupdateslice&gt;`_ 
  operator. 
 
  Args: 
    operand: an array to slice. 
    update: an array containing the new values to write onto `operand`. 
    start_indices: a list of scalar indices, one per dimension. 
 
  Returns: 
    An array containing the slice. 
 
  Examples: 
    Here is an example of updating a one-dimensional slice update: 
 
    &gt;&gt;&gt; x = jnp.zeros(6) 
    &gt;&gt;&gt; y = jnp.ones(3) 
    &gt;&gt;&gt; dynamic_update_slice(x, y, (2,)) 
    Array([0., 0., 1., 1., 1., 0.], dtype=float32) 
 
    If the update slice is too large to fit in the array, the start 
    index will be adjusted to make it fit 
 
    &gt;&gt;&gt; dynamic_update_slice(x, y, (3,)) 
    Array([0., 0., 0., 1., 1., 1.], dtype=float32) 
    &gt;&gt;&gt; dynamic_update_slice(x, y, (5,)) 
    Array([0., 0., 0., 1., 1., 1.], dtype=float32) 
 
    Here is an example of a two-dimensional slice update: 
 
    &gt;&gt;&gt; x = jnp.zeros((4, 4)) 
    &gt;&gt;&gt; y = jnp.ones((2, 2)) 
    &gt;&gt;&gt; dynamic_update_slice(x, y, (1, 2)) 
    Array([[0., 0., 0., 0.], 
           [0., 0., 1., 1.], 
           [0., 0., 1., 1.], 
           [0., 0., 0., 0.]], dtype=float32) 
  &quot;&quot;&quot;</span>
  <span class="s1">start_indices = _dynamic_slice_indices(operand</span><span class="s2">, </span><span class="s1">start_indices)</span>
  <span class="s2">return </span><span class="s1">dynamic_update_slice_p.bind(operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_indices)</span>


<span class="s2">class </span><span class="s1">GatherDimensionNumbers(NamedTuple):</span>
  <span class="s3">&quot;&quot;&quot; 
  Describes the dimension number arguments to an `XLA's Gather operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#gather&gt;`_. See the XLA 
  documentation for more details of what the dimension numbers mean. 
 
  Args: 
    offset_dims: the set of dimensions in the `gather` output that offset into 
      an array sliced from `operand`. Must be a tuple of integers in ascending 
      order, each representing a dimension number of the output. 
    collapsed_slice_dims: the set of dimensions `i` in `operand` that have 
      `slice_sizes[i] == 1` and that should not have a corresponding dimension 
      in the output of the gather. Must be a tuple of integers in ascending 
      order. 
    start_index_map: for each dimension in `start_indices`, gives the 
      corresponding dimension in `operand` that is to be sliced. Must be a 
      tuple of integers with size equal to `start_indices.shape[-1]`. 
 
  Unlike XLA's `GatherDimensionNumbers` structure, `index_vector_dim` is 
  implicit; there is always an index vector dimension and it must always be the 
  last dimension. To gather scalar indices, add a trailing dimension of size 1. 
  &quot;&quot;&quot;</span>
  <span class="s1">offset_dims: Tuple[int</span><span class="s2">, </span><span class="s1">...]</span>
  <span class="s1">collapsed_slice_dims: Tuple[int</span><span class="s2">, </span><span class="s1">...]</span>
  <span class="s1">start_index_map: Tuple[int</span><span class="s2">, </span><span class="s1">...]</span>


<span class="s2">class </span><span class="s1">GatherScatterMode(enum.Enum):</span>
  <span class="s3">&quot;&quot;&quot; 
  Describes how to handle out-of-bounds indices in a gather or scatter. 
 
  Possible values are: 
 
  CLIP: 
    Indices will be clamped to the nearest in-range value, i.e., such that the 
    entire window to be gathered is in-range. 
  FILL_OR_DROP: 
    If any part of a gathered window is out of bounds, the entire window 
    that is returned, even those elements that were otherwise in-bounds, will be 
    filled with a constant. 
    If any part of a scattered window is out of bounds, the entire window 
    will be discarded. 
  PROMISE_IN_BOUNDS: 
    The user promises that indices are in bounds. No additional checking will be 
    performed. In practice, with the current XLA  implementation this means 
    that, out-of-bounds gathers will be clamped but out-of-bounds scatters will 
    be discarded. Gradients will not be correct if indices are out-of-bounds. 
  &quot;&quot;&quot;</span>
  <span class="s1">CLIP = enum.auto()</span>
  <span class="s1">FILL_OR_DROP = enum.auto()</span>
  <span class="s1">PROMISE_IN_BOUNDS = enum.auto()</span>

  <span class="s1">@staticmethod</span>
  <span class="s2">def </span><span class="s1">from_any(s: Optional[Union[str</span><span class="s2">, </span><span class="s4">'GatherScatterMode'</span><span class="s1">]]):</span>
    <span class="s2">if </span><span class="s1">isinstance(s</span><span class="s2">, </span><span class="s1">GatherScatterMode):</span>
      <span class="s2">return </span><span class="s1">s</span>
    <span class="s2">if </span><span class="s1">s == </span><span class="s4">&quot;clip&quot;</span><span class="s1">:</span>
      <span class="s2">return </span><span class="s1">GatherScatterMode.CLIP</span>
    <span class="s2">if </span><span class="s1">s </span><span class="s2">is None or </span><span class="s1">s == </span><span class="s4">&quot;fill&quot; </span><span class="s2">or </span><span class="s1">s == </span><span class="s4">&quot;drop&quot;</span><span class="s1">:</span>
      <span class="s2">return </span><span class="s1">GatherScatterMode.FILL_OR_DROP</span>
    <span class="s2">if </span><span class="s1">s == </span><span class="s4">&quot;promise_in_bounds&quot;</span><span class="s1">:</span>
      <span class="s2">return </span><span class="s1">GatherScatterMode.PROMISE_IN_BOUNDS</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f'Unknown gather mode &quot;</span><span class="s2">{</span><span class="s1">s</span><span class="s2">}</span><span class="s4">&quot;'</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">gather(operand: ArrayLike</span><span class="s2">, </span><span class="s1">start_indices: ArrayLike</span><span class="s2">,</span>
           <span class="s1">dimension_numbers: GatherDimensionNumbers</span><span class="s2">,</span>
           <span class="s1">slice_sizes: Shape</span><span class="s2">,</span>
           <span class="s1">*</span><span class="s2">,</span>
           <span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
           <span class="s1">indices_are_sorted: bool = </span><span class="s2">False,</span>
           <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None,</span>
           <span class="s1">fill_value = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Gather operator. 
 
  Wraps `XLA's Gather operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#gather&gt;`_. 
 
  The semantics of gather are complicated, and its API might change in the 
  future. For most use cases, you should prefer `Numpy-style indexing 
  &lt;https://numpy.org/doc/stable/reference/arrays.indexing.html&gt;`_ 
  (e.g., `x[:, (1,4,7), ...]`), rather than using `gather` directly. 
 
  Args: 
    operand: an array from which slices should be taken 
    start_indices: the indices at which slices should be taken 
    dimension_numbers: a `lax.GatherDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices` and the output relate. 
    slice_sizes: the size of each slice. Must be a sequence of non-negative 
      integers with length equal to `ndim(operand)`. 
    indices_are_sorted: whether `indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements gathered from ``operand`` are 
      guaranteed not to overlap with each other. If ``True``, this may improve 
      performance on some backends. JAX does not check this promise: if 
      the elements overlap the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to ``'clip'``, 
      indices are clamped so that the slice is within bounds, and when 
      set to ``'fill'`` or ``'drop'`` gather returns a slice full of 
      ``fill_value`` for the affected slice. The behavior for out-of-bounds 
      indices when set to ``'promise_in_bounds'`` is implementation-defined. 
    fill_value: the fill value to return for out-of-bounds slices when `mode` 
      is ``'fill'``. Ignored otherwise. Defaults to ``NaN`` for inexact types, 
      the largest negative value for signed types, the largest positive value 
      for unsigned types, and ``True`` for booleans. 
 
  Returns: 
    An array containing the gather output. 
  &quot;&quot;&quot;</span>
  <span class="s2">if </span><span class="s1">mode </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">mode = GatherScatterMode.PROMISE_IN_BOUNDS</span>
  <span class="s1">parsed_mode = GatherScatterMode.from_any(mode)</span>
  <span class="s2">if </span><span class="s1">parsed_mode == GatherScatterMode.FILL_OR_DROP:</span>
    <span class="s2">if </span><span class="s1">fill_value </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s1">dtype = _dtype(operand)</span>
      <span class="s2">if </span><span class="s1">dtypes.issubdtype(dtype</span><span class="s2">, </span><span class="s1">np.inexact):</span>
        <span class="s1">fill_value = np.nan</span>
      <span class="s2">elif </span><span class="s1">dtypes.issubdtype(dtype</span><span class="s2">, </span><span class="s1">np.signedinteger):</span>
        <span class="s1">fill_value = dtypes.iinfo(dtype).min</span>
      <span class="s2">elif </span><span class="s1">dtypes.issubdtype(dtype</span><span class="s2">, </span><span class="s1">np.unsignedinteger):</span>
        <span class="s1">fill_value = dtypes.iinfo(dtype).max</span>
      <span class="s2">elif </span><span class="s1">dtype == dtypes.bool_:</span>
        <span class="s1">fill_value = </span><span class="s2">True</span>
      <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;Unsupported dtype for gather fill_value </span><span class="s2">{</span><span class="s1">dtype</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">fill_value = </span><span class="s2">None</span>
  <span class="s2">return </span><span class="s1">gather_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">slice_sizes=core.canonicalize_shape(slice_sizes)</span><span class="s2">,</span>
      <span class="s1">unique_indices=bool(unique_indices)</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=bool(indices_are_sorted)</span><span class="s2">,</span>
      <span class="s1">mode=parsed_mode</span><span class="s2">,</span>
      <span class="s1">fill_value=fill_value)</span>


<span class="s2">class </span><span class="s1">ScatterDimensionNumbers(NamedTuple):</span>
  <span class="s3">&quot;&quot;&quot; 
  Describes the dimension number arguments to an `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_. See the XLA 
  documentation for more details of what the dimension numbers mean. 
 
  Args: 
    update_window_dims: the set of dimensions in the `updates` that are window 
      dimensions. Must be a tuple of integers in ascending 
      order, each representing a dimension number. 
    inserted_window_dims: the set of size 1 window dimensions that must be 
      inserted into the shape of `updates`. Must be a tuple of integers in 
      ascending order, each representing a dimension number of the output. These 
      are the mirror image of `collapsed_slice_dims` in the case of `gather`. 
    scatter_dims_to_operand_dims: for each dimension in `scatter_indices`, gives 
      the corresponding dimension in `operand`. Must be a sequence of integers 
      with size equal to indices.shape[-1]. 
 
  Unlike XLA's `ScatterDimensionNumbers` structure, `index_vector_dim` is 
  implicit; there is always an index vector dimension and it must always be the 
  last dimension. To scatter scalar indices, add a trailing dimension of size 1. 
  &quot;&quot;&quot;</span>
  <span class="s1">update_window_dims: Sequence[int]</span>
  <span class="s1">inserted_window_dims: Sequence[int]</span>
  <span class="s1">scatter_dims_to_operand_dims: Sequence[int]</span>

<span class="s2">def </span><span class="s1">scatter_add(</span>
  <span class="s1">operand: ArrayLike</span><span class="s2">, </span><span class="s1">scatter_indices: ArrayLike</span><span class="s2">, </span><span class="s1">updates: ArrayLike</span><span class="s2">,</span>
  <span class="s1">dimension_numbers: ScatterDimensionNumbers</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
  <span class="s1">indices_are_sorted: bool = </span><span class="s2">False, </span><span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
  <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Scatter-add operator. 
 
  Wraps `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_, where 
  addition is used to combine updates and values from `operand`. 
 
  The semantics of scatter are complicated, and its API might change in the 
  future. For most use cases, you should prefer the 
  :attr:`jax.numpy.ndarray.at` property on JAX arrays which uses 
  the familiar NumPy indexing syntax. 
 
  Args: 
    operand: an array to which the scatter should be applied 
    scatter_indices: an array that gives the indices in `operand` to which each 
      update in `updates` should be applied. 
    updates: the updates that should be scattered onto `operand`. 
    dimension_numbers: a `lax.ScatterDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices`, `updates` and the output 
      relate. 
    indices_are_sorted: whether `scatter_indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements to be updated in ``operand`` are 
      guaranteed to not overlap with each other. If true, may improve performance on 
      some backends. JAX does not check this promise: if the updated elements 
      overlap when ``unique_indices`` is ``True`` the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to 'clip', 
      indices are clamped so that the slice is within bounds, and when 
      set to 'fill' or 'drop' out-of-bounds updates are dropped. The behavior 
      for out-of-bounds indices when set to 'promise_in_bounds' is 
      implementation-defined. 
 
  Returns: 
    An array containing the sum of `operand` and the scattered updates. 
  &quot;&quot;&quot;</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">consts = lax._reduction_jaxpr(lax.add</span><span class="s2">,</span>
                                       <span class="s1">lax._abstractify(lax._const(operand</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)))</span>
  <span class="s2">return </span><span class="s1">scatter_add_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">scatter_indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=GatherScatterMode.from_any(mode))</span>

<span class="s2">def </span><span class="s1">scatter_mul(</span>
  <span class="s1">operand: ArrayLike</span><span class="s2">, </span><span class="s1">scatter_indices: ArrayLike</span><span class="s2">, </span><span class="s1">updates: ArrayLike</span><span class="s2">,</span>
  <span class="s1">dimension_numbers: ScatterDimensionNumbers</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
  <span class="s1">indices_are_sorted: bool = </span><span class="s2">False, </span><span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
  <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Scatter-multiply operator. 
 
  Wraps `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_, where 
  multiplication is used to combine updates and values from `operand`. 
 
  The semantics of scatter are complicated, and its API might change in the 
  future. For most use cases, you should prefer the 
  :attr:`jax.numpy.ndarray.at` property on JAX arrays which uses 
  the familiar NumPy indexing syntax. 
 
  Args: 
    operand: an array to which the scatter should be applied 
    scatter_indices: an array that gives the indices in `operand` to which each 
      update in `updates` should be applied. 
    updates: the updates that should be scattered onto `operand`. 
    dimension_numbers: a `lax.ScatterDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices`, `updates` and the output 
      relate. 
    indices_are_sorted: whether `scatter_indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements to be updated in ``operand`` are 
      guaranteed to not overlap with each other. If true, may improve performance on 
      some backends. JAX does not check this promise: if the updated elements 
      overlap when ``unique_indices`` is ``True`` the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to 'clip', 
      indices are clamped so that the slice is within bounds, and when 
      set to 'fill' or 'drop' out-of-bounds updates are dropped. The behavior 
      for out-of-bounds indices when set to 'promise_in_bounds' is 
      implementation-defined. 
 
  Returns: 
    An array containing the sum of `operand` and the scattered updates. 
  &quot;&quot;&quot;</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">consts = lax._reduction_jaxpr(lax.mul</span><span class="s2">,</span>
                                       <span class="s1">lax._abstractify(lax._const(operand</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)))</span>
  <span class="s2">return </span><span class="s1">scatter_mul_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">scatter_indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=GatherScatterMode.from_any(mode))</span>

<span class="s2">def </span><span class="s1">scatter_min(</span>
  <span class="s1">operand: ArrayLike</span><span class="s2">, </span><span class="s1">scatter_indices: ArrayLike</span><span class="s2">, </span><span class="s1">updates: ArrayLike</span><span class="s2">,</span>
  <span class="s1">dimension_numbers: ScatterDimensionNumbers</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
  <span class="s1">indices_are_sorted: bool = </span><span class="s2">False, </span><span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
  <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Scatter-min operator. 
 
  Wraps `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_, where 
  the `min` function is used to combine updates and values from `operand`. 
 
  The semantics of scatter are complicated, and its API might change in the 
  future. For most use cases, you should prefer the 
  :attr:`jax.numpy.ndarray.at` property on JAX arrays which uses 
  the familiar NumPy indexing syntax. 
 
  Args: 
    operand: an array to which the scatter should be applied 
    scatter_indices: an array that gives the indices in `operand` to which each 
      update in `updates` should be applied. 
    updates: the updates that should be scattered onto `operand`. 
    dimension_numbers: a `lax.ScatterDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices`, `updates` and the output 
      relate. 
    indices_are_sorted: whether `scatter_indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements to be updated in ``operand`` are 
      guaranteed to not overlap with each other. If true, may improve performance on 
      some backends. JAX does not check this promise: if the updated elements 
      overlap when ``unique_indices`` is ``True`` the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to 'clip', 
      indices are clamped so that the slice is within bounds, and when 
      set to 'fill' or 'drop' out-of-bounds updates are dropped. The behavior 
      for out-of-bounds indices when set to 'promise_in_bounds' is 
      implementation-defined. 
 
  Returns: 
    An array containing the sum of `operand` and the scattered updates. 
  &quot;&quot;&quot;</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">consts = lax._reduction_jaxpr(lax.min</span><span class="s2">,</span>
                                       <span class="s1">lax._abstractify(lax._const(operand</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)))</span>
  <span class="s2">return </span><span class="s1">scatter_min_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">scatter_indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=GatherScatterMode.from_any(mode))</span>

<span class="s2">def </span><span class="s1">scatter_max(</span>
  <span class="s1">operand: ArrayLike</span><span class="s2">, </span><span class="s1">scatter_indices: ArrayLike</span><span class="s2">, </span><span class="s1">updates: ArrayLike</span><span class="s2">,</span>
  <span class="s1">dimension_numbers: ScatterDimensionNumbers</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
  <span class="s1">indices_are_sorted: bool = </span><span class="s2">False, </span><span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
  <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Scatter-max operator. 
 
  Wraps `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_, where 
  the `max` function is used to combine updates and values from `operand`. 
 
  The semantics of scatter are complicated, and its API might change in the 
  future. For most use cases, you should prefer the 
  :attr:`jax.numpy.ndarray.at` property on JAX arrays which uses 
  the familiar NumPy indexing syntax. 
 
  Args: 
    operand: an array to which the scatter should be applied 
    scatter_indices: an array that gives the indices in `operand` to which each 
      update in `updates` should be applied. 
    updates: the updates that should be scattered onto `operand`. 
    dimension_numbers: a `lax.ScatterDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices`, `updates` and the output 
      relate. 
    indices_are_sorted: whether `scatter_indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements to be updated in ``operand`` are 
      guaranteed to not overlap with each other. If true, may improve performance on 
      some backends. JAX does not check this promise: if the updated elements 
      overlap when ``unique_indices`` is ``True`` the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to 'clip', 
      indices are clamped so that the slice is within bounds, and when 
      set to 'fill' or 'drop' out-of-bounds updates are dropped. The behavior 
      for out-of-bounds indices when set to 'promise_in_bounds' is 
      implementation-defined. 
 
  Returns: 
    An array containing the sum of `operand` and the scattered updates. 
  &quot;&quot;&quot;</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">consts = lax._reduction_jaxpr(lax.max</span><span class="s2">,</span>
                                       <span class="s1">lax._abstractify(lax._const(operand</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)))</span>
  <span class="s2">return </span><span class="s1">scatter_max_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">scatter_indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=GatherScatterMode.from_any(mode))</span>

<span class="s0"># To avoid recompilation, we store a dict of weak references to funcs.</span>
<span class="s1">_scatter_apply_cache: weakref.WeakKeyDictionary = weakref.WeakKeyDictionary()</span>

<span class="s2">def </span><span class="s1">scatter_apply(</span>
  <span class="s1">operand: Array</span><span class="s2">, </span><span class="s1">scatter_indices: Array</span><span class="s2">,</span>
  <span class="s1">func: Callable[[Array]</span><span class="s2">, </span><span class="s1">Array]</span><span class="s2">,</span>
  <span class="s1">dimension_numbers: ScatterDimensionNumbers</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
  <span class="s1">indices_are_sorted: bool = </span><span class="s2">False, </span><span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
  <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Scatter-apply operator. 
 
  Wraps `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_, where values 
  from ``operand`` are replaced with ``func(operand)``, with duplicate indices 
  resulting in multiple applications of ``func``. 
 
  The semantics of scatter are complicated, and its API might change in the 
  future. For most use cases, you should prefer the 
  :attr:`jax.numpy.ndarray.at` property on JAX arrays which uses 
  the familiar NumPy indexing syntax. 
 
  Note that in the current implementation, ``scatter_apply`` is not compatible 
  with automatic differentiation. 
 
  Args: 
    operand: an array to which the scatter should be applied 
    scatter_indices: an array that gives the indices in `operand` to which each 
      update in `updates` should be applied. 
    func: unary function that will be applied at each index. 
    dimension_numbers: a `lax.ScatterDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices`, `updates` and the output 
      relate. 
    indices_are_sorted: whether `scatter_indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements to be updated in ``operand`` are 
      guaranteed to not overlap with each other. If true, may improve performance on 
      some backends. JAX does not check this promise: if the updated elements 
      overlap when ``unique_indices`` is ``True`` the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to 'clip', 
      indices are clamped so that the slice is within bounds, and when 
      set to 'fill' or 'drop' out-of-bounds updates are dropped. The behavior 
      for out-of-bounds indices when set to 'promise_in_bounds' is 
      implementation-defined. 
 
  Returns: 
    An array containing the result of applying `func` to `operand` at the given indices. 
  &quot;&quot;&quot;</span>
  <span class="s0"># TODO: can we implement this without a placeholder?</span>
  <span class="s1">unused = lax.full(scatter_indices.shape[:</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">operand.dtype)</span>
  <span class="s1">_apply = </span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">_: func(x)</span>
  <span class="s2">try</span><span class="s1">:</span>
    <span class="s1">_apply = _scatter_apply_cache.setdefault(func</span><span class="s2">, </span><span class="s1">_apply)</span>
  <span class="s2">except </span><span class="s1">TypeError:  </span><span class="s0"># func is not weak referenceable</span>
    <span class="s2">pass</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">consts = lax._reduction_jaxpr(_apply</span><span class="s2">, </span><span class="s1">lax._abstractify(lax._zero(operand)))</span>
  <span class="s0"># TODO: implement this via its own primitive so we can define appropriate autodiff rules.</span>
  <span class="s2">return </span><span class="s1">scatter_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">scatter_indices</span><span class="s2">, </span><span class="s1">unused</span><span class="s2">, </span><span class="s1">update_jaxpr=jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=GatherScatterMode.from_any(mode))</span>

<span class="s0"># Define this outside of scatter to ensure cache hits.</span>
<span class="s1">_scatter_reduction_computation = </span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: y</span>

<span class="s2">def </span><span class="s1">scatter(</span>
  <span class="s1">operand: ArrayLike</span><span class="s2">, </span><span class="s1">scatter_indices: ArrayLike</span><span class="s2">, </span><span class="s1">updates: ArrayLike</span><span class="s2">,</span>
  <span class="s1">dimension_numbers: ScatterDimensionNumbers</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
  <span class="s1">indices_are_sorted: bool = </span><span class="s2">False, </span><span class="s1">unique_indices: bool = </span><span class="s2">False,</span>
  <span class="s1">mode: Optional[Union[str</span><span class="s2">, </span><span class="s1">GatherScatterMode]] = </span><span class="s2">None</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Scatter-update operator. 
 
  Wraps `XLA's Scatter operator 
  &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_, where updates 
  replace values from `operand`. 
 
  If multiple updates are performed to the same index of operand, they may be 
  applied in any order. 
 
  The semantics of scatter are complicated, and its API might change in the 
  future. For most use cases, you should prefer the 
  :attr:`jax.numpy.ndarray.at` property on JAX arrays which uses 
  the familiar NumPy indexing syntax. 
 
  Args: 
    operand: an array to which the scatter should be applied 
    scatter_indices: an array that gives the indices in `operand` to which each 
      update in `updates` should be applied. 
    updates: the updates that should be scattered onto `operand`. 
    dimension_numbers: a `lax.ScatterDimensionNumbers` object that describes 
      how dimensions of `operand`, `start_indices`, `updates` and the output 
      relate. 
    indices_are_sorted: whether `scatter_indices` is known to be sorted. If 
      true, may improve performance on some backends. 
    unique_indices: whether the elements to be updated in ``operand`` are 
      guaranteed to not overlap with each other. If true, may improve performance on 
      some backends. JAX does not check this promise: if the updated elements 
      overlap when ``unique_indices`` is ``True`` the behavior is undefined. 
    mode: how to handle indices that are out of bounds: when set to 'clip', 
      indices are clamped so that the slice is within bounds, and when 
      set to 'fill' or 'drop' out-of-bounds updates are dropped. The behavior 
      for out-of-bounds indices when set to 'promise_in_bounds' is 
      implementation-defined. 
 
  Returns: 
    An array containing the sum of `operand` and the scattered updates. 
  &quot;&quot;&quot;</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">consts = lax._reduction_jaxpr(_scatter_reduction_computation</span><span class="s2">,</span>
                                       <span class="s1">lax._abstractify(lax._const(operand</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)))</span>
  <span class="s2">return </span><span class="s1">scatter_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">scatter_indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=GatherScatterMode.from_any(mode))</span>

<span class="s2">def </span><span class="s1">index_take(src: Array</span><span class="s2">, </span><span class="s1">idxs: Array</span><span class="s2">, </span><span class="s1">axes: Sequence[int]) -&gt; Array:</span>
  <span class="s1">indices = lax.concatenate([lax.expand_dims(i</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">,</span><span class="s1">)) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">idxs]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
  <span class="s1">max_idx = lax.expand_dims(np.array([src.shape[ax] </span><span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">axes])</span><span class="s2">,</span>
                            <span class="s1">tuple(range(indices.ndim - </span><span class="s5">1</span><span class="s1">)))</span>
  <span class="s1">indices = indices % max_idx</span>
  <span class="s1">slice_sizes = list(src.shape)</span>
  <span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">axes:</span>
    <span class="s1">slice_sizes[ax] = </span><span class="s5">1</span>
  <span class="s1">offset_dims = tuple(range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">src.ndim - indices.shape[</span><span class="s5">1</span><span class="s1">] + </span><span class="s5">1</span><span class="s1">))</span>
  <span class="s1">dnums = GatherDimensionNumbers(</span>
      <span class="s1">offset_dims=offset_dims</span><span class="s2">,</span>
      <span class="s1">collapsed_slice_dims=tuple(axes)</span><span class="s2">,</span>
      <span class="s1">start_index_map=tuple(axes))</span>
  <span class="s2">return </span><span class="s1">gather(src</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                <span class="s1">slice_sizes=tuple(slice_sizes))</span>


<span class="s0">### convenience wrappers around traceables</span>

<span class="s2">def </span><span class="s1">slice_in_dim(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">start_index: Optional[int]</span><span class="s2">,</span>
                 <span class="s1">limit_index: Optional[int]</span><span class="s2">,</span>
                 <span class="s1">stride: int = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Convenience wrapper around slice applying to only one dimension.&quot;&quot;&quot;</span>
  <span class="s1">start_indices = [</span><span class="s5">0</span><span class="s1">] * operand.ndim</span>
  <span class="s1">limit_indices = list(operand.shape)</span>
  <span class="s1">strides = [</span><span class="s5">1</span><span class="s1">] * operand.ndim</span>

  <span class="s0"># translate `None`</span>
  <span class="s1">len_axis = operand.shape[axis]</span>
  <span class="s1">start_index_int = (core._canonicalize_dimension(start_index)</span>
                     <span class="s2">if </span><span class="s1">start_index </span><span class="s2">is not None else </span><span class="s5">0</span><span class="s1">)</span>
  <span class="s1">limit_index_int = (core._canonicalize_dimension(limit_index)</span>
                     <span class="s2">if </span><span class="s1">limit_index </span><span class="s2">is not None else </span><span class="s1">len_axis)</span>

  <span class="s0"># translate negative indices</span>
  <span class="s2">if </span><span class="s1">start_index_int &lt; </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s1">start_index_int = start_index_int + len_axis</span>
  <span class="s2">if </span><span class="s1">limit_index_int &lt; </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s1">limit_index_int = limit_index_int + len_axis</span>

  <span class="s1">axis = int(axis)</span>
  <span class="s1">start_indices[axis] = start_index_int</span>
  <span class="s1">limit_indices[axis] = limit_index_int</span>
  <span class="s1">strides[axis] = int(stride)</span>

  <span class="s2">return </span><span class="s1">slice(operand</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">, </span><span class="s1">limit_indices</span><span class="s2">, </span><span class="s1">strides)</span>


<span class="s2">def </span><span class="s1">index_in_dim(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">index: int</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">,</span>
                 <span class="s1">keepdims: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Convenience wrapper around slice to perform int indexing.&quot;&quot;&quot;</span>
  <span class="s1">index</span><span class="s2">, </span><span class="s1">axis = core._canonicalize_dimension(index)</span><span class="s2">, </span><span class="s1">int(axis)</span>
  <span class="s1">axis_size = operand.shape[axis]</span>
  <span class="s1">wrapped_index = index + axis_size </span><span class="s2">if </span><span class="s1">index &lt; </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">index</span>
  <span class="s2">if not </span><span class="s5">0 </span><span class="s1">&lt;= wrapped_index &lt; axis_size:</span>
    <span class="s1">msg = </span><span class="s4">'index {} is out of bounds for axis {} with size {}'</span>
    <span class="s2">raise </span><span class="s1">IndexError(msg.format(index</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">axis_size))</span>
  <span class="s1">result = slice_in_dim(operand</span><span class="s2">, </span><span class="s1">wrapped_index</span><span class="s2">, </span><span class="s1">wrapped_index + </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">axis)</span>
  <span class="s2">if </span><span class="s1">keepdims:</span>
    <span class="s2">return </span><span class="s1">result</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">lax.squeeze(result</span><span class="s2">, </span><span class="s1">(axis</span><span class="s2">,</span><span class="s1">))</span>


<span class="s2">def </span><span class="s1">dynamic_slice_in_dim(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">,</span>
                         <span class="s1">start_index: ArrayLike</span><span class="s2">,</span>
                         <span class="s1">slice_size: int</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Convenience wrapper around dynamic_slice applying to one dimension.&quot;&quot;&quot;</span>
  <span class="s1">start_indices: List[ArrayLike] = [lax._const(start_index</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)] * operand.ndim</span>
  <span class="s1">slice_sizes = list(operand.shape)</span>

  <span class="s1">axis = int(axis)</span>
  <span class="s1">start_indices[axis] = start_index</span>
  <span class="s1">slice_sizes[axis] = core._canonicalize_dimension(slice_size)</span>
  <span class="s2">return </span><span class="s1">dynamic_slice(operand</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">, </span><span class="s1">slice_sizes)</span>


<span class="s2">def </span><span class="s1">dynamic_index_in_dim(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">,</span>
                         <span class="s1">index: Union[int</span><span class="s2">, </span><span class="s1">Array]</span><span class="s2">,</span>
                         <span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">keepdims: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Convenience wrapper around dynamic_slice to perform int indexing.&quot;&quot;&quot;</span>
  <span class="s1">result = dynamic_slice_in_dim(operand</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">axis)</span>
  <span class="s2">if </span><span class="s1">keepdims:</span>
    <span class="s2">return </span><span class="s1">result</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">lax.squeeze(result</span><span class="s2">, </span><span class="s1">(axis</span><span class="s2">,</span><span class="s1">))</span>


<span class="s2">def </span><span class="s1">dynamic_update_slice_in_dim(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">,</span>
                                <span class="s1">update: ArrayLike</span><span class="s2">,</span>
                                <span class="s1">start_index: ArrayLike</span><span class="s2">, </span><span class="s1">axis: int) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Convenience wrapper around :func:`dynamic_update_slice` to update a slice 
     in a single ``axis``. 
  &quot;&quot;&quot;</span>
  <span class="s1">axis = int(axis)</span>
  <span class="s1">start_indices: List[ArrayLike] = [lax._const(start_index</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)] * lax._ndim(operand)</span>
  <span class="s1">start_indices[axis] = start_index</span>
  <span class="s2">return </span><span class="s1">dynamic_update_slice(operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">start_indices)</span>


<span class="s2">def </span><span class="s1">dynamic_update_index_in_dim(operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">,</span>
                                <span class="s1">update: ArrayLike</span><span class="s2">, </span><span class="s1">index: ArrayLike</span><span class="s2">,</span>
                                <span class="s1">axis: int) -&gt; Array:</span>
  <span class="s3">&quot;&quot;&quot;Convenience wrapper around :func:`dynamic_update_slice` to update a slice 
     of size 1 in a single ``axis``. 
  &quot;&quot;&quot;</span>
  <span class="s1">axis = int(axis)</span>
  <span class="s2">if </span><span class="s1">lax._ndim(update) != lax._ndim(operand):</span>
    <span class="s2">assert </span><span class="s1">lax._ndim(update) + </span><span class="s5">1 </span><span class="s1">== lax._ndim(operand)</span>
    <span class="s1">update = lax.expand_dims(update</span><span class="s2">, </span><span class="s1">(axis</span><span class="s2">,</span><span class="s1">))</span>
  <span class="s2">return </span><span class="s1">dynamic_update_slice_in_dim(operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">axis)</span>


<span class="s2">def </span><span class="s1">_slice_shape_rule(operand</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">, </span><span class="s1">limit_indices</span><span class="s2">, </span><span class="s1">strides):</span>
  <span class="s1">lax._check_shapelike(</span><span class="s4">&quot;slice&quot;</span><span class="s2">, </span><span class="s4">&quot;start_indices&quot;</span><span class="s2">, </span><span class="s1">start_indices)</span>
  <span class="s1">lax._check_shapelike(</span><span class="s4">&quot;slice&quot;</span><span class="s2">, </span><span class="s4">&quot;limit_indices&quot;</span><span class="s2">, </span><span class="s1">limit_indices)</span>
  <span class="s2">if </span><span class="s1">operand.ndim != len(start_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice start_indices must have length equal to the number of &quot;</span>
           <span class="s4">&quot;dimensions of the operand, got indices {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(start_indices</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if </span><span class="s1">len(start_indices) != len(limit_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice limit_indices must have the same length as start_indices, &quot;</span>
           <span class="s4">&quot;got start_indices {} and limit_indices {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(start_indices</span><span class="s2">, </span><span class="s1">limit_indices))</span>
  <span class="s2">if not </span><span class="s1">core.greater_equal_shape(operand.shape</span><span class="s2">, </span><span class="s1">limit_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice limit_indices must be less than or equal to operand shape, &quot;</span>
           <span class="s4">&quot;got limit_indices {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(limit_indices</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if not </span><span class="s1">all(core.greater_equal_dim(si</span><span class="s2">, </span><span class="s5">0</span><span class="s1">) </span><span class="s2">for </span><span class="s1">si </span><span class="s2">in </span><span class="s1">start_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice start_indices must be greater than or equal to zero, &quot;</span>
           <span class="s4">&quot;got start_indices of {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(start_indices))</span>
  <span class="s2">if not </span><span class="s1">jax.config.jax_dynamic_shapes:</span>
    <span class="s2">if not </span><span class="s1">core.greater_equal_shape(limit_indices</span><span class="s2">, </span><span class="s1">start_indices):</span>
      <span class="s1">msg = (</span><span class="s4">&quot;slice limit_indices must be greater than or equal to start_indices,&quot;</span>
            <span class="s4">&quot; got start_indices {} and limit_indices {}.&quot;</span><span class="s1">)</span>
      <span class="s2">raise </span><span class="s1">TypeError(msg.format(start_indices</span><span class="s2">, </span><span class="s1">limit_indices))</span>
  <span class="s2">if </span><span class="s1">strides </span><span class="s2">is None or </span><span class="s1">tuple(strides) == (</span><span class="s5">1</span><span class="s2">,</span><span class="s1">) * len(operand.shape):</span>
    <span class="s1">shape = [limit </span><span class="s2">if </span><span class="s1">type(start) </span><span class="s2">is </span><span class="s1">int </span><span class="s2">and </span><span class="s1">start == </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">limit - start</span>
             <span class="s2">for </span><span class="s1">start</span><span class="s2">, </span><span class="s1">limit </span><span class="s2">in </span><span class="s1">zip(start_indices</span><span class="s2">, </span><span class="s1">limit_indices)]</span>
    <span class="s2">return </span><span class="s1">tuple(shape)</span>

  <span class="s1">lax._check_shapelike(</span><span class="s4">&quot;slice&quot;</span><span class="s2">, </span><span class="s4">&quot;strides&quot;</span><span class="s2">, </span><span class="s1">strides)</span>
  <span class="s2">if </span><span class="s1">len(strides) != operand.ndim:</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice strides must have length equal to the number of dimensions &quot;</span>
            <span class="s4">&quot;of the operand, got strides {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(strides</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if not </span><span class="s1">core.greater_equal_shape(strides</span><span class="s2">, </span><span class="s1">(</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) * len(strides)):</span>
    <span class="s1">msg = </span><span class="s4">&quot;slice strides must be positive, got {}&quot;</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(strides))</span>
  <span class="s1">diff = core.diff_shape(limit_indices</span><span class="s2">, </span><span class="s1">start_indices)</span>
  <span class="s2">return </span><span class="s1">core.stride_shape(diff</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">,</span><span class="s1">) * len(diff)</span><span class="s2">, </span><span class="s1">strides)</span>

<span class="s2">def </span><span class="s1">_slice_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">, </span><span class="s1">limit_indices</span><span class="s2">, </span><span class="s1">strides):</span>
  <span class="s2">assert </span><span class="s1">ad.is_undefined_primal(operand)</span>
  <span class="s1">operand_shape = operand.aval.shape</span>
  <span class="s2">if </span><span class="s1">strides </span><span class="s2">is None or </span><span class="s1">np.all(np.equal(strides</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)):</span>
    <span class="s1">pads = zip(start_indices</span><span class="s2">, </span><span class="s1">np.subtract(operand_shape</span><span class="s2">, </span><span class="s1">limit_indices)</span><span class="s2">,</span>
               <span class="s1">(</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) * len(start_indices))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">real_limits = np.add(</span>
      <span class="s1">start_indices</span><span class="s2">,</span>
      <span class="s1">np.where(np.array(t.shape) == </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s2">,</span>
               <span class="s1">np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">np.multiply(np.subtract(t.shape</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">strides))))</span>
    <span class="s1">pads = zip(start_indices</span><span class="s2">, </span><span class="s1">np.subtract(operand_shape</span><span class="s2">, </span><span class="s1">real_limits)</span><span class="s2">,</span>
               <span class="s1">np.subtract(strides</span><span class="s2">, </span><span class="s5">1</span><span class="s1">))</span>
  <span class="s1">result = lax.pad(t</span><span class="s2">, </span><span class="s1">lax._const(t</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">pads)</span>
  <span class="s2">assert </span><span class="s1">result.shape == operand_shape</span><span class="s2">, </span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">result.shape=</span><span class="s2">} {</span><span class="s1">operand_shape=</span><span class="s2">}</span><span class="s4">&quot;</span>
  <span class="s2">return </span><span class="s1">[result]</span>


<span class="s2">def </span><span class="s1">_slice_batching_rule(batched_args</span><span class="s2">, </span><span class="s1">batch_dims</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">,</span>
                         <span class="s1">limit_indices</span><span class="s2">, </span><span class="s1">strides):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">= batched_args</span>
  <span class="s1">bdim</span><span class="s2">, </span><span class="s1">= batch_dims</span>

  <span class="s1">new_start_indices = list(start_indices)</span>
  <span class="s1">new_start_indices.insert(bdim</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>

  <span class="s1">new_limit_indices = list(limit_indices)</span>
  <span class="s1">new_limit_indices.insert(bdim</span><span class="s2">, </span><span class="s1">operand.shape[bdim])</span>

  <span class="s2">if </span><span class="s1">strides </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">new_strides = </span><span class="s2">None</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">new_strides = list(strides)</span>
    <span class="s1">new_strides.insert(bdim</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

  <span class="s1">out = slice(operand</span><span class="s2">, </span><span class="s1">new_start_indices</span><span class="s2">, </span><span class="s1">new_limit_indices</span><span class="s2">, </span><span class="s1">new_strides)</span>
  <span class="s2">return </span><span class="s1">out</span><span class="s2">, </span><span class="s1">bdim</span>

<span class="s1">slice_p = standard_primitive(_slice_shape_rule</span><span class="s2">, </span><span class="s1">_input_dtype</span><span class="s2">, </span><span class="s4">'slice'</span><span class="s1">)</span>
<span class="s1">ad.deflinear2(slice_p</span><span class="s2">, </span><span class="s1">_slice_transpose_rule)</span>
<span class="s1">batching.primitive_batchers[slice_p] = _slice_batching_rule</span>

<span class="s2">def </span><span class="s1">_slice_lower(ctx</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">start_indices</span><span class="s2">, </span><span class="s1">limit_indices</span><span class="s2">, </span><span class="s1">strides):</span>
  <span class="s1">strides = strides </span><span class="s2">or </span><span class="s1">[</span><span class="s5">1</span><span class="s1">] * len(start_indices)</span>
  <span class="s1">aval_out</span><span class="s2">, </span><span class="s1">= ctx.avals_out</span>
  <span class="s2">return </span><span class="s1">[mlir.slice_op(ctx</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">aval_out</span><span class="s2">,</span>
                        <span class="s1">start_indices=start_indices</span><span class="s2">, </span><span class="s1">limit_indices=limit_indices</span><span class="s2">, </span><span class="s1">strides=strides)]</span>

<span class="s1">mlir.register_lowering(slice_p</span><span class="s2">, </span><span class="s1">_slice_lower)</span>


<span class="s2">def </span><span class="s1">_dynamic_slice_shape_rule(operand</span><span class="s2">, </span><span class="s1">*start_indices</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s2">if </span><span class="s1">operand.ndim != len(start_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;dynamic_slice start_indices must have length equal to the number &quot;</span>
           <span class="s4">&quot;of dimensions of the operand, got indices {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(start_indices</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if </span><span class="s1">len(start_indices) != len(slice_sizes):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;dynamic_slice slice_sizes must have the same length as &quot;</span>
           <span class="s4">&quot;start_indices, got start_indices length {} and slice_sizes {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(len(start_indices)</span><span class="s2">, </span><span class="s1">slice_sizes))</span>
  <span class="s2">if not </span><span class="s1">core.greater_equal_shape(operand.shape</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice slice_sizes must be less than or equal to operand shape, &quot;</span>
           <span class="s4">&quot;got slice_sizes {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(slice_sizes</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if not </span><span class="s1">all(core.greater_equal_dim(ssz</span><span class="s2">, </span><span class="s5">0</span><span class="s1">) </span><span class="s2">for </span><span class="s1">ssz </span><span class="s2">in </span><span class="s1">slice_sizes):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;slice slice_sizes must be greater than or equal to zero, &quot;</span>
           <span class="s4">&quot;got slice_sizes of {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(slice_sizes))</span>
  <span class="s2">if </span><span class="s1">any(idx.ndim != </span><span class="s5">0 </span><span class="s2">for </span><span class="s1">idx </span><span class="s2">in </span><span class="s1">start_indices):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;start_indices arguments to dynamic_slice must be scalars, &quot;</span>
                    <span class="s4">f&quot; got indices </span><span class="s2">{</span><span class="s1">start_indices</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">tuple(slice_sizes)</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_dtype_rule(operand</span><span class="s2">, </span><span class="s1">*start_indices</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s2">if </span><span class="s1">any(i.dtype != start_indices[</span><span class="s5">0</span><span class="s1">].dtype </span><span class="s2">or</span>
         <span class="s2">not </span><span class="s1">dtypes.issubdtype(i.dtype</span><span class="s2">, </span><span class="s1">np.integer) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">start_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;index arguments to dynamic_slice must be integers of the same &quot;</span>
           <span class="s4">&quot;type, got: {}&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(</span><span class="s4">&quot;, &quot;</span><span class="s1">.join(i.dtype.name </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">start_indices)))</span>
  <span class="s2">return </span><span class="s1">operand.dtype</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_jvp(primals</span><span class="s2">, </span><span class="s1">tangents</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s1">tangent_out = tangents[</span><span class="s5">0</span><span class="s1">]</span>
  <span class="s2">if </span><span class="s1">type(tangent_out) </span><span class="s2">is not </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">tangent_out = dynamic_slice_p.bind(tangent_out</span><span class="s2">, </span><span class="s1">*primals[</span><span class="s5">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">slice_sizes=slice_sizes)</span>
  <span class="s2">return </span><span class="s1">dynamic_slice_p.bind(primals[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">*primals[</span><span class="s5">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">slice_sizes=slice_sizes)</span><span class="s2">, </span><span class="s1">tangent_out</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">*start_indices</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s2">assert </span><span class="s1">ad.is_undefined_primal(operand)</span>
  <span class="s2">assert </span><span class="s1">all(</span><span class="s2">not </span><span class="s1">ad.is_undefined_primal(s) </span><span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">start_indices)</span>
  <span class="s1">operand_shape</span><span class="s2">, </span><span class="s1">operand_dtype = operand.aval.shape</span><span class="s2">, </span><span class="s1">operand.aval.dtype</span>
  <span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s2">return </span><span class="s1">[ad_util.Zero(operand.aval)] + [</span><span class="s2">None</span><span class="s1">] * len(start_indices)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">zeros = lax.full(operand_shape</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">operand_dtype)</span>
    <span class="s2">return </span><span class="s1">([dynamic_update_slice_p.bind(zeros</span><span class="s2">, </span><span class="s1">t</span><span class="s2">, </span><span class="s1">*start_indices)] +</span>
            <span class="s1">[</span><span class="s2">None</span><span class="s1">] * len(start_indices))</span>

<span class="s2">def </span><span class="s1">_batch_dynamic_slice_indices(indices</span><span class="s2">, </span><span class="s1">bdims):</span>
  <span class="s2">if </span><span class="s1">len(indices) == </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">np.array([]</span><span class="s2">, </span><span class="s4">'int32'</span><span class="s1">)</span><span class="s2">, None</span>
  <span class="s1">empty_marker = object()</span>
  <span class="s1">size = next((x.shape[i] </span><span class="s2">for </span><span class="s1">x</span><span class="s2">, </span><span class="s1">i </span><span class="s2">in </span><span class="s1">zip(indices</span><span class="s2">, </span><span class="s1">bdims) </span><span class="s2">if </span><span class="s1">i </span><span class="s2">is not None</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">empty_marker)</span>
  <span class="s2">if </span><span class="s1">size </span><span class="s2">is </span><span class="s1">empty_marker:</span>
    <span class="s2">return </span><span class="s1">lax.concatenate([lax.broadcast(i</span><span class="s2">, </span><span class="s1">(</span><span class="s5">1</span><span class="s2">,</span><span class="s1">)) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">indices]</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">, None</span>
  <span class="s1">indices = lax.concatenate(</span>
    <span class="s1">[lax.broadcast_in_dim(x</span><span class="s2">, </span><span class="s1">(size</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                          <span class="s1">broadcast_dimensions=((</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if </span><span class="s1">i </span><span class="s2">is not None else </span><span class="s1">()))</span>
     <span class="s2">for </span><span class="s1">x</span><span class="s2">, </span><span class="s1">i </span><span class="s2">in </span><span class="s1">zip(indices</span><span class="s2">, </span><span class="s1">bdims)]</span><span class="s2">,</span>
    <span class="s1">dimension=</span><span class="s5">1</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">indices</span><span class="s2">, </span><span class="s5">0</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_batching_rule(batched_args</span><span class="s2">, </span><span class="s1">batch_dims</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s0"># A dynamic slice is a special case of gather; we can delegate to the gather</span>
  <span class="s0"># batching rule.</span>
  <span class="s0"># TODO(phawkins): consider removing dynamic_slice entirely and using gather</span>
  <span class="s0"># always.</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">*start_indices = batched_args</span>
  <span class="s1">operand_bd</span><span class="s2">, </span><span class="s1">*start_idx_bds = batch_dims</span>
  <span class="s1">operand_shape = (operand.shape </span><span class="s2">if </span><span class="s1">operand_bd </span><span class="s2">is </span><span class="s1">batching.not_mapped</span>
                   <span class="s2">else </span><span class="s1">tuple(np.delete(operand.shape</span><span class="s2">, </span><span class="s1">operand_bd)))</span>
  <span class="s1">dims = tuple(range(len(operand_shape)))</span>
  <span class="s1">dnums = GatherDimensionNumbers(offset_dims=dims</span><span class="s2">, </span><span class="s1">collapsed_slice_dims=()</span><span class="s2">,</span>
                                 <span class="s1">start_index_map=dims)</span>
  <span class="s1">index</span><span class="s2">, </span><span class="s1">index_bdim = _batch_dynamic_slice_indices(start_indices</span><span class="s2">, </span><span class="s1">start_idx_bds)</span>
  <span class="s2">return </span><span class="s1">_gather_batching_rule(</span>
    <span class="s1">[operand</span><span class="s2">, </span><span class="s1">index]</span><span class="s2">, </span><span class="s1">[operand_bd</span><span class="s2">, </span><span class="s1">index_bdim]</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
    <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices=</span><span class="s2">True, </span><span class="s1">indices_are_sorted=</span><span class="s2">True,</span>
    <span class="s1">mode=GatherScatterMode.PROMISE_IN_BOUNDS</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s2">None</span><span class="s1">)</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_staging_rule(trace</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">*starts_and_dyn_sizes</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s1">start_indices</span><span class="s2">, </span><span class="s1">dyn = util.split_list(starts_and_dyn_sizes</span><span class="s2">, </span><span class="s1">[x.ndim])</span>
  <span class="s2">if not </span><span class="s1">dyn:</span>
    <span class="s2">return </span><span class="s1">trace.default_process_primitive(dynamic_slice_p</span><span class="s2">, </span><span class="s1">(x</span><span class="s2">, </span><span class="s1">*start_indices)</span><span class="s2">,</span>
                                           <span class="s1">dict(slice_sizes=slice_sizes))</span>
  <span class="s1">shape = lax._merge_dyn_shape(slice_sizes</span><span class="s2">, </span><span class="s1">dyn)</span>
  <span class="s1">aval = core.DShapedArray(shape</span><span class="s2">, </span><span class="s1">x.dtype</span><span class="s2">, False</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">lax._dyn_shape_staging_rule(trace</span><span class="s2">, </span><span class="s1">dynamic_slice_p</span><span class="s2">, </span><span class="s1">aval</span><span class="s2">, </span><span class="s1">x</span><span class="s2">,</span>
                                     <span class="s1">*starts_and_dyn_sizes</span><span class="s2">,</span>
                                     <span class="s1">slice_sizes=slice_sizes)</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_typecheck_rule(_</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">*starts_and_dyn_sizes</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s1">start_indices</span><span class="s2">, </span><span class="s1">dyn = util.split_list(starts_and_dyn_sizes</span><span class="s2">, </span><span class="s1">[x.aval.ndim])</span>
  <span class="s2">if not </span><span class="s1">dyn:</span>
    <span class="s1">out_aval</span><span class="s2">, </span><span class="s1">effects = dynamic_slice_p.abstract_eval(</span>
        <span class="s1">x.aval</span><span class="s2">, </span><span class="s1">*(d.aval </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">start_indices)</span><span class="s2">, </span><span class="s1">slice_sizes=slice_sizes)</span>
    <span class="s2">return </span><span class="s1">[out_aval]</span><span class="s2">, </span><span class="s1">effects</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s0"># TODO(mattjj): perform more checks</span>
    <span class="s1">out_shape = lax._merge_dyn_shape(slice_sizes</span><span class="s2">, </span><span class="s1">dyn)</span>
    <span class="s1">out_shape = [d.val </span><span class="s2">if </span><span class="s1">type(d) </span><span class="s2">is </span><span class="s1">core.Literal </span><span class="s2">else </span><span class="s1">d </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">out_shape]</span>
    <span class="s1">out_aval = core.DShapedArray(tuple(out_shape)</span><span class="s2">, </span><span class="s1">x.aval.dtype</span><span class="s2">,</span>
                                 <span class="s1">x.aval.weak_type)</span>
    <span class="s2">return </span><span class="s1">[out_aval]</span><span class="s2">, </span><span class="s1">core.no_effects</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_padding_rule(in_avals</span><span class="s2">, </span><span class="s1">out_avals</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">*starts_and_dyn</span><span class="s2">,</span>
                                <span class="s1">slice_sizes):</span>
  <span class="s1">x_aval</span><span class="s2">, </span><span class="s1">start_indices_avals</span><span class="s2">, </span><span class="s1">dyn_avals = util.split_list(in_avals</span><span class="s2">, </span><span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">x.ndim])</span>
  <span class="s1">start_indices</span><span class="s2">, </span><span class="s1">dyn = util.split_list(starts_and_dyn</span><span class="s2">, </span><span class="s1">[x.ndim])</span>
  <span class="s1">dyn_ = [a.dtype.bound </span><span class="s2">if </span><span class="s1">type(a.dtype) </span><span class="s2">is </span><span class="s1">core.bint </span><span class="s2">else </span><span class="s1">d</span>
          <span class="s2">for </span><span class="s1">a</span><span class="s2">, </span><span class="s1">d </span><span class="s2">in </span><span class="s1">zip(dyn_avals</span><span class="s2">, </span><span class="s1">dyn)]</span>
  <span class="s1">slice_sizes_ = lax._merge_dyn_shape(slice_sizes</span><span class="s2">, </span><span class="s1">dyn_)</span>
  <span class="s1">start_idx = [d.val </span><span class="s2">if </span><span class="s1">type(d) </span><span class="s2">is </span><span class="s1">core.DArray </span><span class="s2">else </span><span class="s1">d </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">start_indices]</span>
  <span class="s2">return </span><span class="s1">[dynamic_slice(x</span><span class="s2">, </span><span class="s1">start_idx</span><span class="s2">, </span><span class="s1">slice_sizes_)]</span>

<span class="s1">dynamic_slice_p = standard_primitive(</span>
    <span class="s1">_dynamic_slice_shape_rule</span><span class="s2">, </span><span class="s1">_dynamic_slice_dtype_rule</span><span class="s2">, </span><span class="s4">'dynamic_slice'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>
<span class="s1">ad.primitive_jvps[dynamic_slice_p] = _dynamic_slice_jvp</span>
<span class="s1">ad.primitive_transposes[dynamic_slice_p] = _dynamic_slice_transpose_rule</span>
<span class="s1">batching.primitive_batchers[dynamic_slice_p] = _dynamic_slice_batching_rule</span>
<span class="s1">pe.custom_staging_rules[dynamic_slice_p] = _dynamic_slice_staging_rule</span>
<span class="s1">core.custom_typechecks[dynamic_slice_p] = _dynamic_slice_typecheck_rule</span>
<span class="s1">pe.padding_rules[dynamic_slice_p] = _dynamic_slice_padding_rule</span>

<span class="s2">def </span><span class="s1">_dynamic_slice_lower(ctx</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">*starts_and_dyn_sizes</span><span class="s2">, </span><span class="s1">slice_sizes):</span>
  <span class="s1">x_aval</span><span class="s2">, </span><span class="s1">*_ = ctx.avals_in</span>
  <span class="s1">start_indices</span><span class="s2">, </span><span class="s1">dyn = util.split_list(starts_and_dyn_sizes</span><span class="s2">, </span><span class="s1">[x_aval.ndim])</span>
  <span class="s1">aval_out</span><span class="s2">, </span><span class="s1">= ctx.avals_out</span>
  <span class="s2">if </span><span class="s1">dyn:</span>
    <span class="s1">aval_out = aval_out.update(shape=lax._merge_dyn_shape(slice_sizes</span><span class="s2">, </span><span class="s1">dyn))</span>
  <span class="s2">return </span><span class="s1">[mlir.dynamic_slice(ctx</span><span class="s2">, </span><span class="s1">aval_out</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">start_indices=start_indices)]</span>

<span class="s1">mlir.register_lowering(dynamic_slice_p</span><span class="s2">, </span><span class="s1">_dynamic_slice_lower)</span>

<span class="s0"># def _getslice_lower(ctx, x, lo, hi):</span>
<span class="s0">#   aval_out, = ctx.avals_out</span>
<span class="s0">#   return hlo.RealDynamicSliceOp(</span>
<span class="s0">#       mlir.aval_to_ir_type(aval_out), x,</span>
<span class="s0">#       mlir.shape_tensor([lo]), mlir.shape_tensor([hi]), mlir.shape_tensor([1])</span>
<span class="s0">#   ).results</span>
<span class="s0"># mlir.register_lowering(getslice_p, _getslice_lower)</span>


<span class="s2">def </span><span class="s1">_dynamic_update_slice_shape_rule(operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_indices):</span>
  <span class="s2">if </span><span class="s1">operand.ndim != update.ndim:</span>
    <span class="s1">msg = (</span><span class="s4">&quot;dynamic_update_slice update must have the same rank as operand, &quot;</span>
           <span class="s4">&quot;got update shape {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(update.shape</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if </span><span class="s1">operand.ndim != len(start_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;dynamic_update_slice start_indices must have length equal to the &quot;</span>
           <span class="s4">&quot;rank of operand, got indices {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(start_indices</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if not </span><span class="s1">core.greater_equal_shape(operand.shape</span><span class="s2">, </span><span class="s1">update.shape):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;dynamic_update_slice update shape must be smaller than operand &quot;</span>
           <span class="s4">&quot;shape, got update shape {} for operand shape {}.&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(update.shape</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if </span><span class="s1">any(idx.ndim != </span><span class="s5">0 </span><span class="s2">for </span><span class="s1">idx </span><span class="s2">in </span><span class="s1">start_indices):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;start_indices arguments to dynamic_update_slice must be &quot;</span>
                    <span class="s4">f&quot;scalars, got indices </span><span class="s2">{</span><span class="s1">start_indices</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">operand.shape</span>

<span class="s2">def </span><span class="s1">_dynamic_update_slice_dtype_rule(operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_indices):</span>
  <span class="s1">lax._check_same_dtypes(</span><span class="s4">&quot;dynamic_update_slice&quot;</span><span class="s2">, False, </span><span class="s1">operand.dtype</span><span class="s2">,</span>
                         <span class="s1">update.dtype)</span>
  <span class="s2">if </span><span class="s1">any(i.dtype != start_indices[</span><span class="s5">0</span><span class="s1">].dtype </span><span class="s2">or</span>
         <span class="s2">not </span><span class="s1">dtypes.issubdtype(i.dtype</span><span class="s2">, </span><span class="s1">np.integer) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">start_indices):</span>
    <span class="s1">msg = (</span><span class="s4">&quot;index arguments to dynamic_update_slice must be integers of the &quot;</span>
           <span class="s4">&quot;same type, got {}&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">TypeError(msg.format(</span><span class="s4">&quot;, &quot;</span><span class="s1">.join(i.dtype.name </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">start_indices)))</span>
  <span class="s2">return </span><span class="s1">operand.dtype</span>

<span class="s2">def </span><span class="s1">_dynamic_update_slice_jvp(primals</span><span class="s2">, </span><span class="s1">tangents):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">update = primals[:</span><span class="s5">2</span><span class="s1">]</span>
  <span class="s1">start_indices = primals[</span><span class="s5">2</span><span class="s1">:]</span>
  <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">g_update = tangents[:</span><span class="s5">2</span><span class="s1">]</span>
  <span class="s1">val_out = dynamic_update_slice_p.bind(operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_indices)</span>
  <span class="s2">if </span><span class="s1">type(g_operand) </span><span class="s2">is </span><span class="s1">ad_util.Zero </span><span class="s2">and </span><span class="s1">type(g_update) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">tangent_out = ad_util.Zero.from_value(val_out)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">g_operand = ad.instantiate_zeros(g_operand)</span>
    <span class="s1">g_update = ad.instantiate_zeros(g_update)</span>
    <span class="s1">tangent_out = dynamic_update_slice_p.bind(g_operand</span><span class="s2">, </span><span class="s1">g_update</span><span class="s2">, </span><span class="s1">*start_indices)</span>
  <span class="s2">return </span><span class="s1">val_out</span><span class="s2">, </span><span class="s1">tangent_out</span>

<span class="s2">def </span><span class="s1">_dynamic_update_slice_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_indices):</span>
  <span class="s2">assert </span><span class="s1">all(</span><span class="s2">not </span><span class="s1">ad.is_undefined_primal(x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">start_indices)</span>
  <span class="s2">if </span><span class="s1">ad.is_undefined_primal(update):</span>
    <span class="s1">update_shape = update.aval.shape</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">update_shape = update.shape</span>
  <span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">operand_t = ad_util.Zero(operand.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand) </span><span class="s2">else None</span>
    <span class="s1">update_t = ad_util.Zero(update.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(update) </span><span class="s2">else None</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">dus = dynamic_update_slice_p.bind</span>
    <span class="s1">ds = dynamic_slice_p.bind</span>
    <span class="s1">zeros = lax._zeros(t</span><span class="s2">, </span><span class="s1">shape=update_shape)</span>
    <span class="s1">operand_t = dus(t</span><span class="s2">, </span><span class="s1">zeros</span><span class="s2">, </span><span class="s1">*start_indices) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand) </span><span class="s2">else None</span>
    <span class="s1">update_t = ds(t</span><span class="s2">, </span><span class="s1">*start_indices</span><span class="s2">, </span><span class="s1">slice_sizes=update_shape) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(update) </span><span class="s2">else None</span>
  <span class="s2">return </span><span class="s1">[operand_t</span><span class="s2">, </span><span class="s1">update_t] + [</span><span class="s2">None</span><span class="s1">] * len(start_indices)</span>

<span class="s2">def </span><span class="s1">_dynamic_update_slice_batching_rule(batched_args</span><span class="s2">, </span><span class="s1">batch_dims):</span>
  <span class="s0"># A dynamic update slice is a special case of scatter; we can delegate to the</span>
  <span class="s0"># scatter batching rule.</span>
  <span class="s0"># TODO(phawkins): consider removing dynamic_update_slice entirely and using</span>
  <span class="s0"># scatter always.</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_idx = batched_args</span>
  <span class="s1">operand_bd</span><span class="s2">, </span><span class="s1">update_bd</span><span class="s2">, </span><span class="s1">*start_idx_bd = batch_dims</span>
  <span class="s1">update_shape = (np.shape(update) </span><span class="s2">if </span><span class="s1">update_bd </span><span class="s2">is </span><span class="s1">batching.not_mapped</span>
                  <span class="s2">else </span><span class="s1">tuple(np.delete(np.shape(update)</span><span class="s2">, </span><span class="s1">update_bd)))</span>
  <span class="s1">dims = tuple(range(len(update_shape)))</span>
  <span class="s1">dnums = ScatterDimensionNumbers(update_window_dims=dims</span><span class="s2">,</span>
                                  <span class="s1">inserted_window_dims=()</span><span class="s2">,</span>
                                  <span class="s1">scatter_dims_to_operand_dims=dims)</span>
  <span class="s1">index</span><span class="s2">, </span><span class="s1">index_bdim = _batch_dynamic_slice_indices(start_idx</span><span class="s2">, </span><span class="s1">start_idx_bd)</span>
  <span class="s2">return </span><span class="s1">_scatter_batching_rule(</span>
    <span class="s1">scatter</span><span class="s2">, </span><span class="s1">(operand</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">update)</span><span class="s2">, </span><span class="s1">(operand_bd</span><span class="s2">, </span><span class="s1">index_bdim</span><span class="s2">, </span><span class="s1">update_bd)</span><span class="s2">,</span>
    <span class="s1">update_jaxpr=</span><span class="s2">None, </span><span class="s1">update_consts=</span><span class="s2">None, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
    <span class="s1">indices_are_sorted=</span><span class="s2">True, </span><span class="s1">unique_indices=</span><span class="s2">True,</span>
    <span class="s1">mode=GatherScatterMode.CLIP)</span>


<span class="s1">dynamic_update_slice_p = standard_primitive(</span>
    <span class="s1">_dynamic_update_slice_shape_rule</span><span class="s2">, </span><span class="s1">_dynamic_update_slice_dtype_rule</span><span class="s2">,</span>
    <span class="s4">'dynamic_update_slice'</span><span class="s1">)</span>
<span class="s1">ad.primitive_jvps[dynamic_update_slice_p] = _dynamic_update_slice_jvp</span>
<span class="s1">ad.primitive_transposes[dynamic_update_slice_p] = \</span>
    <span class="s1">_dynamic_update_slice_transpose_rule</span>
<span class="s1">batching.primitive_batchers[dynamic_update_slice_p] = \</span>
    <span class="s1">_dynamic_update_slice_batching_rule</span>

<span class="s2">def </span><span class="s1">_dynamic_update_slice_lower(ctx</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">update</span><span class="s2">, </span><span class="s1">*start_indices):</span>
  <span class="s1">aval_out</span><span class="s2">, </span><span class="s1">= ctx.avals_out</span>
  <span class="s2">return </span><span class="s1">[mlir.dynamic_update_slice(ctx</span><span class="s2">, </span><span class="s1">aval_out</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">update</span><span class="s2">,</span>
                                    <span class="s1">start_indices=start_indices)]</span>

<span class="s1">mlir.register_lowering(dynamic_update_slice_p</span><span class="s2">, </span><span class="s1">_dynamic_update_slice_lower)</span>


<span class="s2">def </span><span class="s1">_gather_dtype_rule(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">**kwargs):</span>
  <span class="s2">if not </span><span class="s1">dtypes.issubdtype(indices.dtype</span><span class="s2">, </span><span class="s1">np.integer):</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;indices must have an integer type&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">dtypes.canonicalize_dtype(operand.dtype</span><span class="s2">, </span><span class="s1">allow_opaque_dtype=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s1">_rank = </span><span class="s2">lambda </span><span class="s1">arr: len(arr.shape)</span>

<span class="s2">def </span><span class="s1">_is_sorted(dims</span><span class="s2">, </span><span class="s1">op_name</span><span class="s2">, </span><span class="s1">name):</span>
  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">len(dims)):</span>
    <span class="s2">if </span><span class="s1">dims[i] &lt; dims[i - </span><span class="s5">1</span><span class="s1">]:</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s4">in </span><span class="s2">{</span><span class="s1">op_name</span><span class="s2">} </span><span class="s4">op must be sorted; got </span><span class="s2">{</span><span class="s1">dims</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

<span class="s2">def </span><span class="s1">_sorted_dims_in_range(dims</span><span class="s2">, </span><span class="s1">rank</span><span class="s2">, </span><span class="s1">op_name</span><span class="s2">, </span><span class="s1">name):</span>
  <span class="s2">if </span><span class="s1">len(dims) == </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s2">return</span>
  <span class="s1">invalid_dim = </span><span class="s2">None</span>
  <span class="s2">if </span><span class="s1">dims[</span><span class="s5">0</span><span class="s1">] &lt; </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s1">invalid_dim = dims[</span><span class="s5">0</span><span class="s1">]</span>
  <span class="s2">elif </span><span class="s1">dims[-</span><span class="s5">1</span><span class="s1">] &gt;= rank:</span>
    <span class="s1">invalid_dim = dims[-</span><span class="s5">1</span><span class="s1">]</span>
  <span class="s2">if </span><span class="s1">invalid_dim:</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Invalid </span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s4">set in </span><span class="s2">{</span><span class="s1">op_name</span><span class="s2">} </span><span class="s4">op; valid range is &quot;</span>
                    <span class="s4">f&quot;[0, </span><span class="s2">{</span><span class="s1">rank</span><span class="s2">}</span><span class="s4">); got: </span><span class="s2">{</span><span class="s1">invalid_dim</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

<span class="s2">def </span><span class="s1">_no_duplicate_dims(dims</span><span class="s2">, </span><span class="s1">op_name</span><span class="s2">, </span><span class="s1">name):</span>
  <span class="s2">if </span><span class="s1">len(set(dims)) != len(dims):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">name</span><span class="s2">} </span><span class="s4">in </span><span class="s2">{</span><span class="s1">op_name</span><span class="s2">} </span><span class="s4">op must not repeat; got: </span><span class="s2">{</span><span class="s1">dims</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

<span class="s2">def </span><span class="s1">_gather_shape_rule(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                       <span class="s1">slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">,</span>
                       <span class="s1">mode</span><span class="s2">, </span><span class="s1">fill_value):</span>
  <span class="s3">&quot;&quot;&quot;Validates the well-formedness of the arguments to Gather. 
 
  The code implements the checks based on the detailed operation semantics of 
  XLA's `Gather &lt;https://www.tensorflow.org/xla/operation_semantics#gather&gt;`_ 
  operator and following the outline of the implementation of 
  ShapeInference::InferGatherShape in TensorFlow. 
  &quot;&quot;&quot;</span>

  <span class="s1">offset_dims = dimension_numbers.offset_dims</span>
  <span class="s1">collapsed_slice_dims = dimension_numbers.collapsed_slice_dims</span>
  <span class="s1">start_index_map = dimension_numbers.start_index_map</span>

  <span class="s0"># Note: in JAX, index_vector_dim is always computed as below, cf. the</span>
  <span class="s0"># documentation of the GatherDimensionNumbers class.</span>
  <span class="s1">index_vector_dim = _rank(indices) - </span><span class="s5">1</span>

  <span class="s0"># This case should never happen in JAX, due to the implicit construction of</span>
  <span class="s0"># index_vector_dim, but is included for completeness.</span>
  <span class="s2">if </span><span class="s1">_rank(indices) &lt; index_vector_dim </span><span class="s2">or </span><span class="s1">index_vector_dim &lt; </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Gather index leaf dimension must be within [0, rank(&quot;</span>
                    <span class="s4">f&quot;indices) + 1). rank(indices) is </span><span class="s2">{</span><span class="s1">_rank(indices)</span><span class="s2">} </span><span class="s4">and &quot;</span>
                    <span class="s4">f&quot;gather index leaf dimension is </span><span class="s2">{</span><span class="s1">index_vector_dim</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s1">expanded_indices_shape = list(indices.shape)</span>

  <span class="s0"># This case should never happen in JAX, due to the implicit construction of</span>
  <span class="s0"># index_vector_dim, but is included for completeness.</span>
  <span class="s2">if </span><span class="s1">len(expanded_indices_shape) == index_vector_dim:</span>
    <span class="s1">expanded_indices_shape.append(</span><span class="s5">1</span><span class="s1">)</span>

  <span class="s0"># Start ValidateGatherDimensions</span>
  <span class="s0"># In the error messages output by XLA, &quot;offset_dims&quot; is called &quot;Output window</span>
  <span class="s0"># dimensions&quot; in error messages. For consistency's sake, our error messages</span>
  <span class="s0"># stick to &quot;offset_dims&quot;.</span>
  <span class="s1">_is_sorted(offset_dims</span><span class="s2">, </span><span class="s4">&quot;gather&quot;</span><span class="s2">, </span><span class="s4">&quot;offset_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_no_duplicate_dims(offset_dims</span><span class="s2">, </span><span class="s4">&quot;gather&quot;</span><span class="s2">, </span><span class="s4">&quot;offset_dims&quot;</span><span class="s1">)</span>

  <span class="s1">output_offset_dim_count = len(offset_dims)</span>
  <span class="s1">output_shape_rank = len(offset_dims) + _rank(indices) - </span><span class="s5">1</span>

  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(output_offset_dim_count):</span>
    <span class="s1">offset_dim = offset_dims[i]</span>
    <span class="s2">if </span><span class="s1">offset_dim &lt; </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">offset_dim &gt;= output_shape_rank:</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Offset dimension </span><span class="s2">{</span><span class="s1">i</span><span class="s2">} </span><span class="s4">in gather op is out of bounds; &quot;</span>
                      <span class="s4">f&quot;got </span><span class="s2">{</span><span class="s1">offset_dim</span><span class="s2">}</span><span class="s4">, but should have been in &quot;</span>
                      <span class="s4">f&quot;[0, </span><span class="s2">{</span><span class="s1">output_shape_rank</span><span class="s2">}</span><span class="s4">)&quot;</span><span class="s1">)</span>

  <span class="s2">if </span><span class="s1">len(start_index_map) != indices.shape[index_vector_dim]:</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Gather op has </span><span class="s2">{</span><span class="s1">len(start_index_map)</span><span class="s2">} </span><span class="s4">elements in &quot;</span>
                    <span class="s4">f&quot;start_index_map and the bound of dimension &quot;</span>
                    <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">index_vector_dim=</span><span class="s2">} </span><span class="s4">of indices is &quot;</span>
                    <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">indices.shape[index_vector_dim]</span><span class="s2">}</span><span class="s4">. These two &quot;</span>
                    <span class="s4">f&quot;numbers must be equal.&quot;</span><span class="s1">)</span>

  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(start_index_map)):</span>
    <span class="s1">operand_dim_for_start_index_i = start_index_map[i]</span>
    <span class="s2">if </span><span class="s1">(operand_dim_for_start_index_i &lt; </span><span class="s5">0 </span><span class="s2">or</span>
        <span class="s1">operand_dim_for_start_index_i &gt;= _rank(operand)):</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Invalid start_index_map; domain is &quot;</span>
                      <span class="s4">f&quot;[0, </span><span class="s2">{</span><span class="s1">_rank(operand)</span><span class="s2">}</span><span class="s4">), got: &quot;</span>
                      <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">i</span><span class="s2">}</span><span class="s4">-&gt;</span><span class="s2">{</span><span class="s1">operand_dim_for_start_index_i</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s1">_no_duplicate_dims(start_index_map</span><span class="s2">, </span><span class="s4">&quot;gather&quot;</span><span class="s2">, </span><span class="s4">&quot;start_index_map&quot;</span><span class="s1">)</span>

  <span class="s0"># _is_sorted and _sorted_dims_in_range are checked in the opposite order</span>
  <span class="s0"># compared to the XLA implementation. In cases when the input is not sorted</span>
  <span class="s0"># AND there are problematic collapsed_slice_dims, the error message will thus</span>
  <span class="s0"># be different.</span>
  <span class="s1">_is_sorted(collapsed_slice_dims</span><span class="s2">, </span><span class="s4">&quot;gather&quot;</span><span class="s2">, </span><span class="s4">&quot;collapsed_slice_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_sorted_dims_in_range(collapsed_slice_dims</span><span class="s2">, </span><span class="s1">_rank(operand)</span><span class="s2">, </span><span class="s4">&quot;gather&quot;</span><span class="s2">,</span>
                        <span class="s4">&quot;collapsed_slice_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_no_duplicate_dims(collapsed_slice_dims</span><span class="s2">, </span><span class="s4">&quot;gather&quot;</span><span class="s2">, </span><span class="s4">&quot;collapsed_slice_dims&quot;</span><span class="s1">)</span>
  <span class="s0"># End ValidateGatherDimensions</span>

  <span class="s2">if </span><span class="s1">_rank(operand) != len(slice_sizes):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Gather op must have one slice size for every input &quot;</span>
                    <span class="s4">f&quot;dimension; got: len(slice_sizes)=</span><span class="s2">{</span><span class="s1">len(slice_sizes)</span><span class="s2">}</span><span class="s4">, &quot;</span>
                    <span class="s4">f&quot;input_shape.rank=</span><span class="s2">{</span><span class="s1">_rank(operand)</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

  <span class="s2">if </span><span class="s1">len(slice_sizes) != len(offset_dims) + len(collapsed_slice_dims):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;All components of the offset index in a gather op must &quot;</span>
                    <span class="s4">f&quot;either be a offset dimension or explicitly collapsed; &quot;</span>
                    <span class="s4">f&quot;got len(slice_sizes)=</span><span class="s2">{</span><span class="s1">len(slice_sizes)</span><span class="s2">}</span><span class="s4">, &quot;</span>
                    <span class="s4">f&quot;output_slice_sizes=</span><span class="s2">{</span><span class="s1">offset_dims</span><span class="s2">}</span><span class="s4">, collapsed_slice_dims=&quot;</span>
                    <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">collapsed_slice_dims</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(slice_sizes)):</span>
    <span class="s1">slice_size = slice_sizes[i]</span>
    <span class="s1">corresponding_input_size = operand.shape[i]</span>

    <span class="s2">if not </span><span class="s1">(core.greater_equal_dim(slice_size</span><span class="s2">, </span><span class="s5">0</span><span class="s1">) </span><span class="s2">and</span>
            <span class="s1">core.greater_equal_dim(corresponding_input_size</span><span class="s2">, </span><span class="s1">slice_size)):</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Slice size at index </span><span class="s2">{</span><span class="s1">i</span><span class="s2">} </span><span class="s4">in gather op is out of range, &quot;</span>
                      <span class="s4">f&quot;must be within [0, </span><span class="s2">{</span><span class="s1">corresponding_input_size</span><span class="s2">} </span><span class="s4">+ 1), &quot;</span>
                      <span class="s4">f&quot;got </span><span class="s2">{</span><span class="s1">slice_size</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(collapsed_slice_dims)):</span>
    <span class="s1">bound = slice_sizes[collapsed_slice_dims[i]]</span>
    <span class="s2">if </span><span class="s1">bound != </span><span class="s5">1</span><span class="s1">:</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Gather op can only collapse slice dims with bound 1, &quot;</span>
                      <span class="s4">f&quot;but bound is </span><span class="s2">{</span><span class="s1">bound</span><span class="s2">} </span><span class="s4">for index &quot;</span>
                      <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">collapsed_slice_dims[i]</span><span class="s2">} </span><span class="s4">at position </span><span class="s2">{</span><span class="s1">i</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s1">expanded_indices_shape.pop(index_vector_dim)</span>
  <span class="s1">indices_shape = iter(expanded_indices_shape)</span>

  <span class="s1">slice_sizes = (s </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">s </span><span class="s2">in </span><span class="s1">enumerate(slice_sizes)</span>
                 <span class="s2">if </span><span class="s1">i </span><span class="s2">not in </span><span class="s1">collapsed_slice_dims)</span>
  <span class="s2">return </span><span class="s1">tuple(next(slice_sizes) </span><span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">offset_dims</span>
               <span class="s2">else </span><span class="s1">next(indices_shape) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(output_shape_rank))</span>


<span class="s2">def </span><span class="s1">_gather_fill(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">slice_sizes</span><span class="s2">,</span>
                 <span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">,</span>
                 <span class="s1">output_shape):</span>
  <span class="s3">&quot;&quot;&quot;Lowers a FILL_OR_DROP gather as a PROMISE_IN_BOUNDS gather with masking.&quot;&quot;&quot;</span>
  <span class="s1">dnums = dimension_numbers</span>
  <span class="s1">intarray = partial(np.array</span><span class="s2">, </span><span class="s1">dtype=np.int64)</span>
  <span class="s1">operand_dims = lax.shape_as_value(operand.shape)</span>
  <span class="s1">indices = lax.convert_element_type(indices</span><span class="s2">, </span><span class="s1">np.int64)</span>
  <span class="s1">num_batch_dims = len(indices.shape) - </span><span class="s5">1</span>

  <span class="s1">upper_bound = (</span>
      <span class="s1">operand_dims[intarray(dnums.start_index_map)] -</span>
      <span class="s1">lax.shape_as_value(slice_sizes)[intarray(dnums.start_index_map)])</span>
  <span class="s1">mask = lax.bitwise_and(</span>
      <span class="s1">lax.ge(indices</span><span class="s2">, </span><span class="s1">np.int64(</span><span class="s5">0</span><span class="s1">))</span><span class="s2">,</span>
      <span class="s1">lax.le(indices</span><span class="s2">, </span><span class="s1">lax.expand_dims(upper_bound</span><span class="s2">, </span><span class="s1">tuple(range(num_batch_dims)))))</span>
  <span class="s1">mask = lax._reduce_and(mask</span><span class="s2">, </span><span class="s1">[num_batch_dims])</span>

  <span class="s0"># Computes the output shape and the positions of the batch dimensions in the</span>
  <span class="s0"># output</span>
  <span class="s1">output_ndims = num_batch_dims + len(dnums.offset_dims)</span>
  <span class="s1">batch_dims_in_output = np.delete(np.arange(output_ndims)</span><span class="s2">,</span>
                                   <span class="s1">dnums.offset_dims)</span>

  <span class="s0"># We don't consume unique_indices directly in gather(), only in its transpose</span>
  <span class="s0"># (scatter).</span>
  <span class="s1">gather_out = gather(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dnums</span><span class="s2">, </span><span class="s1">slice_sizes</span><span class="s2">,</span>
                      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                      <span class="s1">mode=GatherScatterMode.PROMISE_IN_BOUNDS)</span>
  <span class="s2">return </span><span class="s1">lax.select(</span>
    <span class="s1">lax.broadcast_in_dim(mask</span><span class="s2">, </span><span class="s1">output_shape</span><span class="s2">, </span><span class="s1">batch_dims_in_output)</span><span class="s2">,</span>
    <span class="s1">gather_out</span><span class="s2">, </span><span class="s1">lax.full_like(gather_out</span><span class="s2">, </span><span class="s1">fill_value=fill_value))</span>


<span class="s2">def </span><span class="s1">_gather_jvp_rule(g</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                     <span class="s1">slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">,</span>
                     <span class="s1">fill_value):</span>
  <span class="s2">return </span><span class="s1">gather(g</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">slice_sizes</span><span class="s2">,</span>
                <span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
                <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">,</span>
                <span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>

<span class="s2">def </span><span class="s1">_gather_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                           <span class="s1">slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">,</span>
                           <span class="s1">mode</span><span class="s2">, </span><span class="s1">fill_value):</span>
  <span class="s2">assert </span><span class="s1">ad.is_undefined_primal(operand)</span>
  <span class="s1">operand_shape = operand.aval.shape</span>
  <span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">out = ad_util.Zero(operand.aval)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">zeros = lax.full(operand_shape</span><span class="s2">, </span><span class="s1">lax._zero(t))</span>
    <span class="s1">scatter_dnums = ScatterDimensionNumbers(</span>
      <span class="s1">update_window_dims=dimension_numbers.offset_dims</span><span class="s2">,</span>
      <span class="s1">inserted_window_dims=dimension_numbers.collapsed_slice_dims</span><span class="s2">,</span>
      <span class="s1">scatter_dims_to_operand_dims=dimension_numbers.start_index_map)</span>
    <span class="s1">out = scatter_add(zeros</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">t</span><span class="s2">, </span><span class="s1">scatter_dnums</span><span class="s2">,</span>
                      <span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
                      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                      <span class="s1">mode=mode)</span>
  <span class="s2">return </span><span class="s1">[out</span><span class="s2">, None</span><span class="s1">]</span>

<span class="s2">def </span><span class="s1">_gather_batching_rule(batched_args</span><span class="s2">, </span><span class="s1">batch_dims</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                          <span class="s1">slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">,</span>
                          <span class="s1">mode</span><span class="s2">, </span><span class="s1">fill_value):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices = batched_args</span>
  <span class="s1">operand_bdim</span><span class="s2">, </span><span class="s1">indices_bdim = batch_dims</span>

  <span class="s2">if </span><span class="s1">operand_bdim </span><span class="s2">is not None and </span><span class="s1">indices_bdim </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">operand = batching.moveaxis(operand</span><span class="s2">, </span><span class="s1">operand_bdim</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">slice_sizes = (operand.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">) + slice_sizes</span>
    <span class="s1">offset_dims = (</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.offset_dims))</span>
    <span class="s1">collapsed_slice_dims = tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.collapsed_slice_dims))</span>
    <span class="s1">start_index_map = tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.start_index_map))</span>
    <span class="s1">dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=offset_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=collapsed_slice_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=start_index_map)</span>
    <span class="s2">return </span><span class="s1">gather(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                  <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
                  <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">,</span>
                  <span class="s1">fill_value=fill_value)</span><span class="s2">, </span><span class="s5">0</span>

  <span class="s2">elif </span><span class="s1">operand_bdim </span><span class="s2">is None and </span><span class="s1">indices_bdim </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">indices = batching.moveaxis(indices</span><span class="s2">, </span><span class="s1">indices_bdim</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">offset_dims = tuple(</span><span class="s5">1 </span><span class="s1">+ d </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">dimension_numbers.offset_dims)</span>
    <span class="s1">dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=offset_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=dimension_numbers.collapsed_slice_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=dimension_numbers.start_index_map)</span>
    <span class="s0"># If batching indexed accesses into the same array, the batched gather may</span>
    <span class="s0"># no longer have sorted or unique indices.</span>
    <span class="s2">return </span><span class="s1">gather(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                  <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices=</span><span class="s2">False,</span>
                  <span class="s1">indices_are_sorted=</span><span class="s2">False, </span><span class="s1">mode=mode</span><span class="s2">, </span><span class="s1">fill_value=fill_value)</span><span class="s2">, </span><span class="s5">0</span>

  <span class="s2">else</span><span class="s1">:</span>
    <span class="s0"># move batch dimensions to the front to simplify logic</span>
    <span class="s1">operand = batching.moveaxis(operand</span><span class="s2">, </span><span class="s1">operand_bdim</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">indices = batching.moveaxis(indices</span><span class="s2">, </span><span class="s1">indices_bdim</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>

    <span class="s0"># This slightly awkward special case is needed because the shape rule for</span>
    <span class="s0"># gather does not allow size-1 slices out of a size-0 dimension, even if</span>
    <span class="s0"># the number of slices is zero. Likely the best fix would be to change the</span>
    <span class="s0"># definition of gather() so it can be batched without the construction of</span>
    <span class="s0"># an explicit iota of size-1 slices.</span>
    <span class="s2">if </span><span class="s1">core.symbolic_equal_dim(operand.shape[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s5">0</span><span class="s1">):</span>
      <span class="s1">output_shape = _gather_shape_rule(</span>
          <span class="s1">core.ShapedArray(operand.shape[</span><span class="s5">1</span><span class="s1">:]</span><span class="s2">, </span><span class="s1">operand.dtype)</span><span class="s2">,</span>
          <span class="s1">core.ShapedArray(indices.shape[</span><span class="s5">1</span><span class="s1">:]</span><span class="s2">,</span>
                           <span class="s1">dtypes.canonicalize_dtype(indices.dtype))</span><span class="s2">,</span>
          <span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">, </span><span class="s1">slice_sizes=slice_sizes</span><span class="s2">,</span>
          <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
          <span class="s1">mode=mode</span><span class="s2">, </span><span class="s1">fill_value=fill_value)</span>
      <span class="s2">return </span><span class="s1">lax.full((</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + output_shape</span><span class="s2">, </span><span class="s1">lax._zero(operand))</span><span class="s2">, </span><span class="s5">0</span>

    <span class="s0"># Example: user code had indices shape (3, 4, 5), and we have to deal with</span>
    <span class="s0"># indices shape (7, 3, 4, 5). We transform that to indices of shape</span>
    <span class="s0"># (7, 3, 4, 6) where we concatenated an iota that counts along our batch</span>
    <span class="s0"># dimension to the front of the ndindex.</span>
    <span class="s1">count_shape = list(indices.shape)</span>
    <span class="s1">count_shape[-</span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1</span>
    <span class="s1">counts = lax.broadcasted_iota(indices.dtype</span><span class="s2">, </span><span class="s1">tuple(count_shape)</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">indices = lax.concatenate([counts</span><span class="s2">, </span><span class="s1">indices]</span><span class="s2">, </span><span class="s1">len(count_shape) - </span><span class="s5">1</span><span class="s1">)</span>

    <span class="s1">slice_sizes = (</span><span class="s5">1</span><span class="s2">,</span><span class="s1">) + slice_sizes</span>
    <span class="s1">collapsed_slice_dims = (</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.collapsed_slice_dims))</span>
    <span class="s1">offset_dims = tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.offset_dims))</span>
    <span class="s1">start_index_map = (</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.start_index_map))</span>

    <span class="s1">dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=offset_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=collapsed_slice_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=start_index_map)</span>
    <span class="s2">return </span><span class="s1">gather(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                  <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
                  <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">,</span>
                  <span class="s1">fill_value=fill_value)</span><span class="s2">, </span><span class="s5">0</span>

<span class="s2">def </span><span class="s1">_gather_pad_rule(in_avals</span><span class="s2">, </span><span class="s1">out_avals</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                     <span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">,</span>
                     <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">, </span><span class="s1">fill_value):</span>
  <span class="s1">operand_aval</span><span class="s2">, </span><span class="s1">indices_aval = in_avals</span>
  <span class="s2">if </span><span class="s1">any(isinstance(d</span><span class="s2">, </span><span class="s1">pe.BoundedAxisSize) </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">operand_aval.shape):</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s2">if </span><span class="s1">mode != GatherScatterMode.PROMISE_IN_BOUNDS:</span>
    <span class="s0"># with fill, jnp.where on operand; with clip, jnp.where on indices</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s2">return </span><span class="s1">[gather(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
                 <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">, </span><span class="s1">fill_value=fill_value)]</span>

<span class="s1">gather_p = standard_primitive(</span>
    <span class="s1">_gather_shape_rule</span><span class="s2">, </span><span class="s1">_gather_dtype_rule</span><span class="s2">, </span><span class="s4">'gather'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>
<span class="s1">ad.defjvp(gather_p</span><span class="s2">, </span><span class="s1">_gather_jvp_rule</span><span class="s2">, None</span><span class="s1">)</span>
<span class="s1">ad.primitive_transposes[gather_p] = _gather_transpose_rule</span>
<span class="s1">batching.primitive_batchers[gather_p] = _gather_batching_rule</span>
<span class="s1">pe.padding_rules[gather_p] = _gather_pad_rule</span>


<span class="s2">def </span><span class="s1">_gather_lower(ctx</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                  <span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">,</span>
                  <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">, </span><span class="s1">fill_value):</span>
  <span class="s1">aval_out</span><span class="s2">, </span><span class="s1">= ctx.avals_out</span>
  <span class="s2">if </span><span class="s1">core.is_opaque_dtype(aval_out.dtype):</span>
    <span class="s2">return </span><span class="s1">[aval_out.dtype._rules.gather_mlir(</span>
        <span class="s1">ctx</span><span class="s2">, </span><span class="s1">ctx.avals_in</span><span class="s2">, </span><span class="s1">aval_out</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
        <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
        <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">, </span><span class="s1">fill_value=fill_value)]</span>

  <span class="s2">if </span><span class="s1">mode == GatherScatterMode.FILL_OR_DROP:</span>
    <span class="s1">gather_fill_fn = mlir.lower_fun(_gather_fill</span><span class="s2">, </span><span class="s1">multiple_results=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">gather_fill_fn(</span>
        <span class="s1">ctx</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">,</span>
        <span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">, </span><span class="s1">slice_sizes=slice_sizes</span><span class="s2">,</span>
        <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
        <span class="s1">fill_value=fill_value</span><span class="s2">, </span><span class="s1">output_shape=aval_out.shape)</span>

  <span class="s2">assert </span><span class="s1">mode </span><span class="s2">in </span><span class="s1">(GatherScatterMode.PROMISE_IN_BOUNDS</span><span class="s2">,</span>
                  <span class="s1">GatherScatterMode.CLIP)</span><span class="s2">, </span><span class="s1">mode</span>
  <span class="s1">dnums = hlo.GatherDimensionNumbers.get(</span>
    <span class="s1">collapsed_slice_dims=list(dimension_numbers.collapsed_slice_dims)</span><span class="s2">,</span>
    <span class="s1">index_vector_dim=len(ctx.avals_in[</span><span class="s5">1</span><span class="s1">].shape) - </span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">offset_dims=list(dimension_numbers.offset_dims)</span><span class="s2">,</span>
    <span class="s1">start_index_map=list(dimension_numbers.start_index_map))</span>
  <span class="s2">if not </span><span class="s1">core.is_constant_shape(slice_sizes):</span>
    <span class="s1">slice_sizes = mlir.eval_dynamic_shape(ctx</span><span class="s2">, </span><span class="s1">slice_sizes)</span>
    <span class="s0"># TODO(burmako): Fix overly conservative type inference of DynamicGatherOp.</span>
    <span class="s0"># For now use the build_generic so that we can specify the result type.</span>
    <span class="s0"># return hlo.DynamicGatherOp(</span>
    <span class="s0">#     operand, indices, mlir.shape_tensor(slice_sizes),</span>
    <span class="s0">#     dnums, indices_are_sorted=ir.BoolAttr.get(indices_are_sorted)).results</span>
    <span class="s1">results = [mlir.aval_to_ir_type(aval_out)]</span>
    <span class="s1">operands = [operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">mlir.shape_tensor(slice_sizes)]</span>
    <span class="s1">attributes = {</span>
        <span class="s4">&quot;dimension_numbers&quot;</span><span class="s1">: dnums</span><span class="s2">,</span>
        <span class="s4">&quot;indices_are_sorted&quot;</span><span class="s1">: ir.BoolAttr.get(indices_are_sorted)</span>
    <span class="s1">}</span>
    <span class="s2">return </span><span class="s1">hlo.DynamicGatherOp.build_generic(</span>
        <span class="s1">results=results</span><span class="s2">, </span><span class="s1">operands=operands</span><span class="s2">, </span><span class="s1">attributes=attributes).results</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">hlo.GatherOp(</span>
        <span class="s1">operand</span><span class="s2">,</span>
        <span class="s1">indices</span><span class="s2">,</span>
        <span class="s1">dnums</span><span class="s2">,</span>
        <span class="s1">mlir.dense_int_elements(slice_sizes)</span><span class="s2">,</span>
        <span class="s1">indices_are_sorted=ir.BoolAttr.get(indices_are_sorted)).results</span>

<span class="s1">mlir.register_lowering(gather_p</span><span class="s2">, </span><span class="s1">_gather_lower)</span>

<span class="s2">def </span><span class="s1">_scatter_dtype_rule(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">**kwargs):</span>
  <span class="s2">if not </span><span class="s1">dtypes.issubdtype(indices.dtype</span><span class="s2">, </span><span class="s1">np.integer):</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;indices must have an integer type&quot;</span><span class="s1">)</span>
  <span class="s1">lax._check_same_dtypes(</span><span class="s4">&quot;scatter&quot;</span><span class="s2">, False, </span><span class="s1">operand.dtype</span><span class="s2">, </span><span class="s1">updates.dtype)</span>
  <span class="s2">return </span><span class="s1">dtypes.canonicalize_dtype(operand.dtype)</span>

<span class="s2">def </span><span class="s1">_scatter_shape_rule(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">update_jaxpr</span><span class="s2">,</span>
                        <span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">,</span>
                        <span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s3">&quot;&quot;&quot;Validates the well-formedness of the ``dimension_numbers`` argument to 
  Scatter. 
 
  The code implements the checks based on the detailed operation semantics of 
  XLA's `Scatter &lt;https://www.tensorflow.org/xla/operation_semantics#scatter&gt;`_ 
  operator and following the outline of the implementation of 
  ShapeInference::InferScatterShape in TensorFlow. 
  &quot;&quot;&quot;</span>

  <span class="s1">update_window_dims = dimension_numbers.update_window_dims</span>
  <span class="s1">inserted_window_dims = dimension_numbers.inserted_window_dims</span>
  <span class="s1">scatter_dims_to_operand_dims = dimension_numbers.scatter_dims_to_operand_dims</span>
  <span class="s0"># Note: in JAX, index_vector_dim is always computed as below, cf. the</span>
  <span class="s0"># documentation of the ScatterDimensionNumbers class.</span>
  <span class="s1">index_vector_dim = _rank(indices) - </span><span class="s5">1</span>

  <span class="s0"># This case should never happen in JAX, due to the implicit construction of</span>
  <span class="s0"># index_vector_dim, but is included for completeness.</span>
  <span class="s2">if </span><span class="s1">_rank(indices) &lt; index_vector_dim </span><span class="s2">or </span><span class="s1">index_vector_dim &lt; </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Scatter index leaf dimension must be within [0, &quot;</span>
                    <span class="s4">f&quot;rank(indices) + 1). rank(indices) is </span><span class="s2">{</span><span class="s1">_rank(indices)</span><span class="s2">} </span><span class="s4">&quot;</span>
                    <span class="s4">f&quot;and scatter index leaf dimension is </span><span class="s2">{</span><span class="s1">index_vector_dim</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s1">expanded_indices_shape = list(indices.shape)</span>
  <span class="s0"># This case should never happen in JAX, due to the implicit construction of</span>
  <span class="s0"># index_vector_dim, but is included for completeness.</span>
  <span class="s2">if </span><span class="s1">len(expanded_indices_shape) == index_vector_dim:</span>
    <span class="s1">expanded_indices_shape.append(</span><span class="s5">1</span><span class="s1">)</span>

  <span class="s1">expected_updates_rank = (len(expanded_indices_shape) - </span><span class="s5">1 </span><span class="s1">+</span>
                           <span class="s1">len(update_window_dims))</span>

  <span class="s2">if </span><span class="s1">_rank(updates) != expected_updates_rank:</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Updates tensor must be of rank </span><span class="s2">{</span><span class="s1">expected_updates_rank</span><span class="s2">}</span><span class="s4">; &quot;</span>
                    <span class="s4">f&quot;got </span><span class="s2">{</span><span class="s1">_rank(updates)</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s0"># Validate update_window_dims</span>
  <span class="s1">_is_sorted(update_window_dims</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">, </span><span class="s4">&quot;update_window_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_no_duplicate_dims(update_window_dims</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">, </span><span class="s4">&quot;update_window_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_sorted_dims_in_range(update_window_dims</span><span class="s2">, </span><span class="s1">_rank(updates)</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">,</span>
                        <span class="s4">&quot;update_window_dims&quot;</span><span class="s1">)</span>

  <span class="s0"># Validate inserted_window_dims</span>
  <span class="s1">_is_sorted(inserted_window_dims</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">, </span><span class="s4">&quot;inserted_window_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_no_duplicate_dims(inserted_window_dims</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">, </span><span class="s4">&quot;inserted_window_dims&quot;</span><span class="s1">)</span>
  <span class="s1">_sorted_dims_in_range(inserted_window_dims</span><span class="s2">, </span><span class="s1">_rank(operand)</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">,</span>
                        <span class="s4">&quot;inserted_window_dims&quot;</span><span class="s1">)</span>

  <span class="s0"># Validate window_size</span>
  <span class="s1">window_size = len(update_window_dims) + len(inserted_window_dims)</span>
  <span class="s2">if </span><span class="s1">_rank(operand) != window_size:</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Scatter op has window of size </span><span class="s2">{</span><span class="s1">window_size</span><span class="s2">}</span><span class="s4">; doesn't &quot;</span>
                    <span class="s4">f&quot;match operand of rank </span><span class="s2">{</span><span class="s1">_rank(operand)</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s0"># Validate scatter_dims_to_operand_dims</span>
  <span class="s2">if </span><span class="s1">(len(scatter_dims_to_operand_dims) !=</span>
      <span class="s1">indices.shape[index_vector_dim]):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Scatter op has </span><span class="s2">{</span><span class="s1">len(scatter_dims_to_operand_dims)</span><span class="s2">} </span><span class="s4">&quot;</span>
                    <span class="s4">f&quot;elements in scatter_dims_to_operand_dims and the bound &quot;</span>
                    <span class="s4">f&quot;of dimension </span><span class="s2">{</span><span class="s1">index_vector_dim=</span><span class="s2">} </span><span class="s4">of &quot;</span>
                    <span class="s4">f&quot;indices is </span><span class="s2">{</span><span class="s1">indices.shape[index_vector_dim]</span><span class="s2">}</span><span class="s4">. These two &quot;</span>
                    <span class="s4">f&quot;numbers must be equal&quot;</span><span class="s1">)</span>

  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(scatter_dims_to_operand_dims)):</span>
    <span class="s1">dim = scatter_dims_to_operand_dims[i]</span>
    <span class="s2">if </span><span class="s1">dim &lt; </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">dim &gt;= _rank(operand):</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Invalid scatter_dims_to_operand_dims mapping; domain &quot;</span>
                      <span class="s4">f&quot;is [0, </span><span class="s2">{</span><span class="s1">_rank(operand)</span><span class="s2">}</span><span class="s4">), got: </span><span class="s2">{</span><span class="s1">i</span><span class="s2">}</span><span class="s4">-&gt;</span><span class="s2">{</span><span class="s1">dim</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s1">_no_duplicate_dims(scatter_dims_to_operand_dims</span><span class="s2">, </span><span class="s4">&quot;scatter&quot;</span><span class="s2">,</span>
                     <span class="s4">&quot;scatter_dims_to_operand_dims&quot;</span><span class="s1">)</span>

  <span class="s1">max_update_slice_sizes = [operand.shape[i] </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(operand.shape))</span>
                            <span class="s2">if not </span><span class="s1">i </span><span class="s2">in </span><span class="s1">set(inserted_window_dims)]</span>

  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(update_window_dims)):</span>
    <span class="s1">update_window_dim = update_window_dims[i]</span>
    <span class="s2">if not </span><span class="s1">core.greater_equal_dim(max_update_slice_sizes[i]</span><span class="s2">, </span><span class="s1">updates.shape[update_window_dim]):</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Bounds of the window dimensions of updates must not &quot;</span>
                      <span class="s4">f&quot;exceed the bounds of the corresponding dimensions of &quot;</span>
                      <span class="s4">f&quot;operand. For dimension </span><span class="s2">{</span><span class="s1">update_window_dim</span><span class="s2">}</span><span class="s4">, updates &quot;</span>
                      <span class="s4">f&quot;bound is </span><span class="s2">{</span><span class="s1">updates.shape[update_window_dim]</span><span class="s2">}</span><span class="s4">, operand &quot;</span>
                      <span class="s4">f&quot;bound is </span><span class="s2">{</span><span class="s1">max_update_slice_sizes[i]</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>

  <span class="s1">update_scatter_dims = [dim </span><span class="s2">for </span><span class="s1">dim </span><span class="s2">in </span><span class="s1">range(_rank(updates)) </span><span class="s2">if </span><span class="s1">dim </span><span class="s2">not in</span>
                         <span class="s1">set(update_window_dims)]</span>

  <span class="s1">scatter_dims_seen = </span><span class="s5">0</span>
  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">update_scatter_dims:</span>
    <span class="s2">if </span><span class="s1">scatter_dims_seen == index_vector_dim:</span>
      <span class="s1">scatter_dims_seen += </span><span class="s5">1</span>
    <span class="s2">if not </span><span class="s1">core.symbolic_equal_dim(updates.shape[i]</span><span class="s2">, </span><span class="s1">expanded_indices_shape[scatter_dims_seen]):</span>
      <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Bounds of the scatter dimensions of updates must be &quot;</span>
                      <span class="s4">f&quot;the same as the bounds of the corresponding dimensions &quot;</span>
                      <span class="s4">f&quot;of scatter indices. For scatter dimension </span><span class="s2">{</span><span class="s1">i</span><span class="s2">}</span><span class="s4">, updates &quot;</span>
                      <span class="s4">f&quot;bound is </span><span class="s2">{</span><span class="s1">updates.shape[i]</span><span class="s2">}</span><span class="s4">, indices bound is &quot;</span>
                      <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">expanded_indices_shape[scatter_dims_seen]</span><span class="s2">}</span><span class="s4">.&quot;</span><span class="s1">)</span>
    <span class="s1">scatter_dims_seen += </span><span class="s5">1</span>

  <span class="s2">return </span><span class="s1">operand.shape</span>


<span class="s2">def </span><span class="s1">_clamp_scatter_indices(operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dnums):</span>
  <span class="s3">&quot;&quot;&quot;Clamps `indices` to be in-range for a scatter.&quot;&quot;&quot;</span>
  <span class="s1">slice_sizes = []</span>
  <span class="s1">pos = </span><span class="s5">0</span>
  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(operand.shape)):</span>
    <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">dnums.inserted_window_dims:</span>
      <span class="s1">slice_sizes.append(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">slice_sizes.append(updates.shape[dnums.update_window_dims[pos]])</span>
      <span class="s1">pos += </span><span class="s5">1</span>

  <span class="s1">upper_bounds: core.Shape = tuple(operand.shape[i] - slice_sizes[i]</span>
                                   <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">dnums.scatter_dims_to_operand_dims)</span>
  <span class="s0"># Stack upper_bounds into a Array[n]</span>
  <span class="s1">upper_bound = lax.shape_as_value(upper_bounds)</span>
  <span class="s0"># This fix fails lax_test_no_jax_array</span>
  <span class="s1">upper_bound = lax.min(upper_bound</span><span class="s2">,</span>
                        <span class="s1">lax.convert_element_type(np.uint64(np.iinfo(indices.dtype).max)</span><span class="s2">,</span>
                                                  <span class="s1">np.int64))</span>

  <span class="s1">upper_bound = lax.broadcast_in_dim(upper_bound</span><span class="s2">, </span><span class="s1">indices.shape</span><span class="s2">,</span>
                                     <span class="s1">(len(indices.shape) - </span><span class="s5">1</span><span class="s2">,</span><span class="s1">))</span>
  <span class="s2">return </span><span class="s1">lax.clamp(np.int64(</span><span class="s5">0</span><span class="s1">)</span><span class="s2">, </span><span class="s1">lax.convert_element_type(indices</span><span class="s2">, </span><span class="s1">np.int64)</span><span class="s2">,</span>
                   <span class="s1">upper_bound)</span>

<span class="s2">def </span><span class="s1">_scatter_add_jvp(primals</span><span class="s2">, </span><span class="s1">tangents</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">,</span>
                     <span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">,</span>
                     <span class="s1">mode):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates = primals</span>
  <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">g_indices</span><span class="s2">, </span><span class="s1">g_updates = tangents</span>
  <span class="s2">del </span><span class="s1">g_indices  </span><span class="s0"># ignored</span>
  <span class="s1">val_out = scatter_add_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=mode)</span>
  <span class="s2">if </span><span class="s1">type(g_operand) </span><span class="s2">is </span><span class="s1">ad_util.Zero </span><span class="s2">and </span><span class="s1">type(g_updates) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">tangent_out = ad_util.Zero.from_value(val_out)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">g_operand = ad.instantiate_zeros(g_operand)</span>
    <span class="s1">g_updates = ad.instantiate_zeros(g_updates)</span>
    <span class="s1">tangent_out = scatter_add_p.bind(</span>
        <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">g_updates</span><span class="s2">, </span><span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
        <span class="s1">update_consts=update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
        <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
        <span class="s1">mode=mode)</span>
  <span class="s2">return </span><span class="s1">val_out</span><span class="s2">, </span><span class="s1">tangent_out</span>

<span class="s2">def </span><span class="s1">_scatter_add_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                                <span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                                <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s2">assert not </span><span class="s1">ad.is_undefined_primal(indices)</span>
  <span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates):</span>
    <span class="s1">updates_shape = updates.aval.shape</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">updates_shape = updates.shape</span>
  <span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">operand_t = ad_util.Zero(operand.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand) </span><span class="s2">else None</span>
    <span class="s1">update_t = ad_util.Zero(updates.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates) </span><span class="s2">else None</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">operand_t = update_t = </span><span class="s2">None</span>
    <span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand):</span>
      <span class="s1">operand_t = t</span>

    <span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates):</span>
      <span class="s1">gather_dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=dimension_numbers.update_window_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=dimension_numbers.inserted_window_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=dimension_numbers.scatter_dims_to_operand_dims)</span>
      <span class="s1">slice_sizes = []</span>
      <span class="s1">pos = </span><span class="s5">0</span>
      <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(t.shape)):</span>
        <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">dimension_numbers.inserted_window_dims:</span>
          <span class="s1">slice_sizes.append(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
          <span class="s1">slice_sizes.append(updates_shape[dimension_numbers.update_window_dims[pos]])</span>
          <span class="s1">pos += </span><span class="s5">1</span>
      <span class="s1">update_t = gather(t</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=gather_dnums</span><span class="s2">,</span>
                        <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">[operand_t</span><span class="s2">, None, </span><span class="s1">update_t]</span>

<span class="s2">def </span><span class="s1">_scatter_mul_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                                <span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                                <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s2">assert not </span><span class="s1">ad.is_undefined_primal(indices)</span>
  <span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates):</span>
    <span class="s1">updates_shape = updates.aval.shape</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">updates_shape = updates.shape</span>
  <span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">operand_t = ad_util.Zero(operand.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand) </span><span class="s2">else None</span>
    <span class="s1">update_t = ad_util.Zero(updates.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates) </span><span class="s2">else None</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">operand_t = update_t = </span><span class="s2">None</span>
    <span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand):</span>
      <span class="s1">operand_t = scatter_mul(</span>
          <span class="s1">t</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
          <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
          <span class="s1">mode=mode)</span>
    <span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates):</span>
      <span class="s2">if not </span><span class="s1">unique_indices:</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span>
          <span class="s4">&quot;scatter_mul gradients are only implemented if `unique_indices=True`&quot;</span><span class="s1">)</span>
      <span class="s1">gather_dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=dimension_numbers.update_window_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=dimension_numbers.inserted_window_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=dimension_numbers.scatter_dims_to_operand_dims)</span>
      <span class="s1">slice_sizes = []</span>
      <span class="s1">pos = </span><span class="s5">0</span>
      <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(t.shape)):</span>
        <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">dimension_numbers.inserted_window_dims:</span>
          <span class="s1">slice_sizes.append(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
          <span class="s1">slice_sizes.append(updates_shape[dimension_numbers.update_window_dims[pos]])</span>
          <span class="s1">pos += </span><span class="s5">1</span>
      <span class="s1">update_t = gather(lax.mul(t</span><span class="s2">, </span><span class="s1">operand)</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">,</span>
                        <span class="s1">dimension_numbers=gather_dnums</span><span class="s2">, </span><span class="s1">slice_sizes=slice_sizes</span><span class="s2">,</span>
                        <span class="s1">mode=mode</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">[operand_t</span><span class="s2">, None, </span><span class="s1">update_t]</span>


<span class="s2">def </span><span class="s1">_scatter_batching_rule(scatter_op</span><span class="s2">, </span><span class="s1">batched_args</span><span class="s2">, </span><span class="s1">batch_dims</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                           <span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                           <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates = batched_args</span>
  <span class="s1">operand_bdim</span><span class="s2">, </span><span class="s1">indices_bdim</span><span class="s2">, </span><span class="s1">updates_bdim = batch_dims</span>
  <span class="s2">del </span><span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts  </span><span class="s0"># Unused.</span>

  <span class="s0"># move the operand batch dim to the front if it is not None, otherwise create</span>
  <span class="s0"># it at the front (so that we can scatter into it)</span>
  <span class="s1">size = next(x.shape[ax] </span><span class="s2">for </span><span class="s1">x</span><span class="s2">, </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">zip(batched_args</span><span class="s2">, </span><span class="s1">batch_dims)</span>
              <span class="s2">if </span><span class="s1">ax </span><span class="s2">is not None</span><span class="s1">)</span>
  <span class="s1">operand = batching.bdim_at_front(operand</span><span class="s2">, </span><span class="s1">operand_bdim</span><span class="s2">, </span><span class="s1">size)</span>
  <span class="s1">operand_bdim = </span><span class="s5">0</span>

  <span class="s1">updates = batching.bdim_at_front(updates</span><span class="s2">, </span><span class="s1">updates_bdim</span><span class="s2">, </span><span class="s1">size)</span>

  <span class="s2">if </span><span class="s1">indices_bdim </span><span class="s2">is None</span><span class="s1">:</span>
    <span class="s1">inserted_window_dims = tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.inserted_window_dims))</span>
    <span class="s1">update_window_dims = (</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.update_window_dims))</span>
    <span class="s1">scatter_dims_to_operand_dims = tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.scatter_dims_to_operand_dims))</span>
    <span class="s1">dnums = ScatterDimensionNumbers(</span>
        <span class="s1">update_window_dims=update_window_dims</span><span class="s2">,</span>
        <span class="s1">inserted_window_dims=inserted_window_dims</span><span class="s2">,</span>
        <span class="s1">scatter_dims_to_operand_dims=scatter_dims_to_operand_dims)</span>
    <span class="s2">return </span><span class="s1">scatter_op(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=mode)</span><span class="s2">, </span><span class="s5">0</span>


  <span class="s0"># see the third case in _gather_batching_rule for comparison and comments</span>
  <span class="s1">indices = batching.bdim_at_front(indices</span><span class="s2">, </span><span class="s1">indices_bdim</span><span class="s2">, </span><span class="s1">size)</span>

  <span class="s1">count_shape = list(indices.shape)</span>
  <span class="s1">count_shape[-</span><span class="s5">1</span><span class="s1">] = </span><span class="s5">1</span>
  <span class="s1">counts = lax.broadcasted_iota(indices.dtype</span><span class="s2">, </span><span class="s1">tuple(count_shape)</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
  <span class="s1">indices = lax.concatenate([counts</span><span class="s2">, </span><span class="s1">indices]</span><span class="s2">, </span><span class="s1">len(count_shape) - </span><span class="s5">1</span><span class="s1">)</span>

  <span class="s1">update_window_dims = tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.update_window_dims))</span>
  <span class="s1">inserted_window_dims = (</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.inserted_window_dims))</span>
  <span class="s1">scatter_dims_to_operand_dims = (</span><span class="s5">0</span><span class="s2">,</span><span class="s1">) + tuple(np.add(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dimension_numbers.scatter_dims_to_operand_dims))</span>

  <span class="s1">dnums = ScatterDimensionNumbers(</span>
      <span class="s1">update_window_dims=update_window_dims</span><span class="s2">,</span>
      <span class="s1">inserted_window_dims=inserted_window_dims</span><span class="s2">,</span>
      <span class="s1">scatter_dims_to_operand_dims=scatter_dims_to_operand_dims)</span>
  <span class="s2">return </span><span class="s1">scatter_op(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=mode)</span><span class="s2">, </span><span class="s5">0</span>

<span class="s1">scatter_add_p = standard_primitive(</span>
    <span class="s1">_scatter_shape_rule</span><span class="s2">, </span><span class="s1">_scatter_dtype_rule</span><span class="s2">, </span><span class="s4">'scatter-add'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>
<span class="s1">ad.primitive_jvps[scatter_add_p] = _scatter_add_jvp</span>
<span class="s1">ad.primitive_transposes[scatter_add_p] = _scatter_add_transpose_rule</span>
<span class="s1">batching.primitive_batchers[scatter_add_p] = (</span>
  <span class="s1">partial(_scatter_batching_rule</span><span class="s2">, </span><span class="s1">scatter_add))</span>

<span class="s1">scatter_mul_p = standard_primitive(</span>
    <span class="s1">_scatter_shape_rule</span><span class="s2">, </span><span class="s1">_scatter_dtype_rule</span><span class="s2">, </span><span class="s4">'scatter-mul'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>

<span class="s2">def </span><span class="s1">_scatter_mul_jvp_rhs(g</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                         <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">, </span><span class="s1">**kw):</span>
  <span class="s2">if not </span><span class="s1">unique_indices:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span>
      <span class="s4">&quot;scatter_mul gradients are only implemented if `unique_indices=True`&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">lax.mul(x</span><span class="s2">, </span><span class="s1">scatter_add(</span>
      <span class="s1">lax.zeros_like_array(x)</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">g</span><span class="s2">, </span><span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=mode))</span>

<span class="s1">ad.defjvp(scatter_mul_p</span><span class="s2">,</span>
          <span class="s2">lambda </span><span class="s1">g</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">**kw: scatter_mul_p.bind(g</span><span class="s2">, </span><span class="s1">i</span><span class="s2">, </span><span class="s1">y</span><span class="s2">, </span><span class="s1">**kw)</span><span class="s2">,</span>
          <span class="s2">None,</span>
          <span class="s1">_scatter_mul_jvp_rhs)</span>
<span class="s1">ad.primitive_transposes[scatter_mul_p] = _scatter_mul_transpose_rule</span>
<span class="s1">batching.primitive_batchers[scatter_mul_p] = (</span>
  <span class="s1">partial(_scatter_batching_rule</span><span class="s2">, </span><span class="s1">scatter_mul))</span>

<span class="s2">def </span><span class="s1">_scatter_extremal_jvp(scatter_op</span><span class="s2">, </span><span class="s1">primals</span><span class="s2">, </span><span class="s1">tangents</span><span class="s2">, </span><span class="s1">update_jaxpr</span><span class="s2">,</span>
                          <span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                          <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates = primals</span>
  <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">g_indices</span><span class="s2">, </span><span class="s1">g_updates = tangents</span>

  <span class="s1">scatter_dnums = dimension_numbers</span>
  <span class="s1">updates_shape = updates.shape</span>

  <span class="s1">val_out = scatter_op.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers=scatter_dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
      <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">mode=mode)</span>

  <span class="s2">if </span><span class="s1">type(g_operand) </span><span class="s2">is </span><span class="s1">ad_util.Zero </span><span class="s2">and </span><span class="s1">type(g_updates) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">tangent_out = ad_util.Zero.from_value(val_out)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">g_operand = ad.instantiate_zeros(g_operand)</span>
    <span class="s1">g_updates = ad.instantiate_zeros(g_updates)</span>

    <span class="s0"># gather_dnums and slice_sizes define the gather op that is the inverse of</span>
    <span class="s0"># the scatter op specified by scatter_dnums</span>
    <span class="s1">gather_dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=scatter_dnums.update_window_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=scatter_dnums.inserted_window_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=scatter_dnums.scatter_dims_to_operand_dims)</span>

    <span class="s1">slice_sizes = []</span>
    <span class="s1">pos = </span><span class="s5">0</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(operand.shape)):</span>
      <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">scatter_dnums.inserted_window_dims:</span>
        <span class="s1">slice_sizes.append(</span><span class="s5">1</span><span class="s1">)</span>
      <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">slice_sizes.append(updates_shape[scatter_dnums.update_window_dims[pos]])</span>
        <span class="s1">pos += </span><span class="s5">1</span>

    <span class="s0"># For consistency with other max operations, if there are two or more values</span>
    <span class="s0"># in updates that are contending to replace the same index location, the</span>
    <span class="s0"># resulting tangent at that location will be the average of the associated</span>
    <span class="s0"># tangents for the values in updates.</span>

    <span class="s1">initial_vals = gather(</span>
        <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">gather_dnums</span><span class="s2">, </span><span class="s1">np.array(slice_sizes))</span>

    <span class="s1">target_vals = gather(</span>
        <span class="s1">val_out</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">gather_dnums</span><span class="s2">, </span><span class="s1">np.array(slice_sizes))</span>

    <span class="s1">successful_updates = (updates == target_vals)</span>
    <span class="s1">retained_values = (initial_vals == target_vals)</span>

    <span class="s1">num_updates = gather(</span>
        <span class="s1">scatter_add(</span>
            <span class="s1">lax._zeros(operand)</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">,</span>
            <span class="s1">lax.select(successful_updates</span><span class="s2">, </span><span class="s1">lax._ones(updates)</span><span class="s2">,</span>
                       <span class="s1">lax._zeros(updates))</span><span class="s2">,</span>
            <span class="s1">scatter_dnums)</span><span class="s2">,</span>
        <span class="s1">indices</span><span class="s2">,</span>
        <span class="s1">gather_dnums</span><span class="s2">,</span>
        <span class="s1">np.array(slice_sizes))</span>

    <span class="s1">num_refs = gather(</span>
        <span class="s1">scatter_add(lax._zeros(operand)</span><span class="s2">,</span>
                    <span class="s1">indices</span><span class="s2">,</span>
                    <span class="s1">lax._ones(updates)</span><span class="s2">,</span>
                    <span class="s1">scatter_dnums)</span><span class="s2">,</span>
        <span class="s1">indices</span><span class="s2">,</span>
        <span class="s1">gather_dnums</span><span class="s2">,</span>
        <span class="s1">np.array(slice_sizes))</span>

    <span class="s1">updates_normalizer = lax.select(retained_values</span><span class="s2">,</span>
                                    <span class="s5">1.0 </span><span class="s1">/ (num_updates + </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                                    <span class="s5">1.0 </span><span class="s1">/ num_updates)</span>

    <span class="s1">updates_coef = lax.select(successful_updates</span><span class="s2">,</span>
                              <span class="s1">updates_normalizer</span><span class="s2">,</span>
                              <span class="s1">lax._zeros(updates))</span>

    <span class="s1">operand_normalizer = lax.select(retained_values</span><span class="s2">,</span>
                                    <span class="s5">1.0 </span><span class="s1">/ (num_updates + </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
                                    <span class="s1">lax._zeros(num_updates))</span>

    <span class="s1">operand_coef = (-</span><span class="s5">1.0 </span><span class="s1">+ operand_normalizer) / num_refs</span>

    <span class="s0"># This can be simplified once scatter has transpose implemented</span>
    <span class="s1">target_tangents = gather(</span>
        <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">gather_dnums</span><span class="s2">, </span><span class="s1">np.array(slice_sizes))</span>

    <span class="s1">tangent_updates = (target_tangents * operand_coef +</span>
                       <span class="s1">g_updates * updates_coef)</span>

    <span class="s1">tangent_out = scatter_add(g_operand</span><span class="s2">,</span>
                              <span class="s1">indices</span><span class="s2">,</span>
                              <span class="s1">tangent_updates</span><span class="s2">,</span>
                              <span class="s1">scatter_dnums</span><span class="s2">,</span>
                              <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                              <span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
                              <span class="s1">mode=mode)</span>

  <span class="s2">return </span><span class="s1">val_out</span><span class="s2">, </span><span class="s1">tangent_out</span>

<span class="s1">scatter_min_p = standard_primitive(</span>
    <span class="s1">_scatter_shape_rule</span><span class="s2">, </span><span class="s1">_scatter_dtype_rule</span><span class="s2">, </span><span class="s4">'scatter-min'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>
<span class="s1">batching.primitive_batchers[scatter_min_p] = (</span>
  <span class="s1">partial(_scatter_batching_rule</span><span class="s2">, </span><span class="s1">scatter_min))</span>
<span class="s1">ad.primitive_jvps[scatter_min_p] = partial(_scatter_extremal_jvp</span><span class="s2">, </span><span class="s1">scatter_min_p)</span>

<span class="s1">scatter_max_p = standard_primitive(</span>
    <span class="s1">_scatter_shape_rule</span><span class="s2">, </span><span class="s1">_scatter_dtype_rule</span><span class="s2">, </span><span class="s4">'scatter-max'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>
<span class="s1">batching.primitive_batchers[scatter_max_p] = (</span>
  <span class="s1">partial(_scatter_batching_rule</span><span class="s2">, </span><span class="s1">scatter_max))</span>
<span class="s1">ad.primitive_jvps[scatter_max_p] = partial(_scatter_extremal_jvp</span><span class="s2">, </span><span class="s1">scatter_max_p)</span>

<span class="s2">def </span><span class="s1">_scatter_jvp(primals</span><span class="s2">, </span><span class="s1">tangents</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">,</span>
                 <span class="s1">dimension_numbers</span><span class="s2">, </span><span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">,</span>
                 <span class="s1">mode):</span>
  <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates = primals</span>
  <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">g_indices</span><span class="s2">, </span><span class="s1">g_updates = tangents</span>
  <span class="s1">dnums = dimension_numbers</span>

  <span class="s2">if </span><span class="s1">type(g_operand) </span><span class="s2">is </span><span class="s1">ad_util.Zero </span><span class="s2">and </span><span class="s1">type(g_updates) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">val_out = scatter_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=unique_indices</span><span class="s2">,</span>
      <span class="s1">mode=mode)</span>
    <span class="s2">return </span><span class="s1">val_out</span><span class="s2">, </span><span class="s1">ad_util.Zero.from_value(val_out)</span>

  <span class="s1">g_operand = ad.instantiate_zeros(g_operand)</span>
  <span class="s1">g_updates = ad.instantiate_zeros(g_updates)</span>

  <span class="s2">if </span><span class="s1">unique_indices:</span>
    <span class="s0"># If the user has promised that the updates don't overlap, we can use a much</span>
    <span class="s0"># simpler JVP.</span>
    <span class="s1">val_out = scatter_p.bind(</span>
      <span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=</span><span class="s2">True, </span><span class="s1">mode=mode)</span>
    <span class="s1">tangent_out = scatter_p.bind(</span>
      <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">g_updates</span><span class="s2">, </span><span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
      <span class="s1">update_consts=update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices=</span><span class="s2">True, </span><span class="s1">mode=mode)</span>
    <span class="s2">return </span><span class="s1">val_out</span><span class="s2">, </span><span class="s1">tangent_out</span>

  <span class="s0"># If there are overlapping indices in the scatter, it is unspecified which</span>
  <span class="s0"># update &quot;wins&quot;. So we use the following perhaps surprising scheme:</span>
  <span class="s0"># a) attach a positive ID to each update in updates, and perform the scatter</span>
  <span class="s0">#    on the IDs</span>
  <span class="s0"># b) perform the inverse gather on the scattered IDs (similar to</span>
  <span class="s0">#    _scatter_add_transpose).</span>
  <span class="s0"># c) use the gathered IDs to mask the primal and tangent values.</span>
  <span class="s0"># d) perform a scatter-add on the masked primal and tangent values. A benefit</span>
  <span class="s0">#    of using scatter-add here is that we don't need a `scatter` transpose</span>
  <span class="s0">#    rule.</span>


  <span class="s0"># a) attach a positive ID to each update in `updates`, and perform a scatter</span>
  <span class="s0">#    on the IDs.</span>
  <span class="s1">ids_shape = np.array(updates.shape</span><span class="s2">, </span><span class="s1">dtype=np.int64)</span>
  <span class="s1">ids_shape[dnums.update_window_dims</span><span class="s2">,</span><span class="s1">] = </span><span class="s5">1</span>
  <span class="s1">num_ids = np.prod(ids_shape)</span>
  <span class="s1">id_dtype = np.uint32 </span><span class="s2">if </span><span class="s1">(num_ids + </span><span class="s5">1</span><span class="s1">) &lt; np.iinfo(np.uint32).max </span><span class="s2">else </span><span class="s1">np.uint64</span>
  <span class="s1">update_ids = lax.add(lax.reshape(lax.iota(id_dtype</span><span class="s2">, </span><span class="s1">num_ids)</span><span class="s2">, </span><span class="s1">ids_shape)</span><span class="s2">,</span>
                       <span class="s1">lax._ones(updates</span><span class="s2">, </span><span class="s1">dtype=id_dtype))</span>

  <span class="s1">scattered_ids = scatter(lax.full(operand.shape</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s1">id_dtype)</span><span class="s2">,</span>
                          <span class="s1">indices</span><span class="s2">, </span><span class="s1">update_ids</span><span class="s2">, </span><span class="s1">dnums</span><span class="s2">,</span>
                          <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                          <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">mode=mode)</span>

  <span class="s0"># b) compute the inverse gather that &quot;undoes&quot; the scatter on the id values.</span>
  <span class="s1">gather_dnums = GatherDimensionNumbers(</span>
    <span class="s1">offset_dims=dnums.update_window_dims</span><span class="s2">,</span>
    <span class="s1">collapsed_slice_dims=dnums.inserted_window_dims</span><span class="s2">,</span>
    <span class="s1">start_index_map=dnums.scatter_dims_to_operand_dims)</span>
  <span class="s1">slice_sizes = []</span>
  <span class="s1">pos = </span><span class="s5">0</span>
  <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(scattered_ids.shape)):</span>
    <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">dnums.inserted_window_dims:</span>
      <span class="s1">slice_sizes.append(</span><span class="s5">1</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">slice_sizes.append(updates.shape[dnums.update_window_dims[pos]])</span>
      <span class="s1">pos += </span><span class="s5">1</span>
  <span class="s1">gathered_update_ids = gather(scattered_ids</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">,</span>
                               <span class="s1">dimension_numbers=gather_dnums</span><span class="s2">,</span>
                               <span class="s1">slice_sizes=slice_sizes)</span>

  <span class="s0"># c) mask off input elements that do not correspond to a primal output.</span>
  <span class="s1">masked_operand = lax.select(lax.eq(scattered_ids</span><span class="s2">, </span><span class="s1">lax._zeros(scattered_ids))</span><span class="s2">,</span>
                              <span class="s1">operand</span><span class="s2">, </span><span class="s1">lax._zeros(operand))</span>
  <span class="s1">masked_updates = lax.select(lax.eq(update_ids</span><span class="s2">,  </span><span class="s1">gathered_update_ids)</span><span class="s2">,</span>
                              <span class="s1">updates</span><span class="s2">, </span><span class="s1">lax._zeros(updates))</span>
  <span class="s1">masked_g_operand = lax.select(lax.eq(scattered_ids</span><span class="s2">, </span><span class="s1">lax._zeros(scattered_ids))</span><span class="s2">,</span>
                                <span class="s1">g_operand</span><span class="s2">, </span><span class="s1">lax._zeros(g_operand))</span>
  <span class="s1">masked_g_updates = lax.select(lax.eq(update_ids</span><span class="s2">, </span><span class="s1">gathered_update_ids)</span><span class="s2">,</span>
                                <span class="s1">g_updates</span><span class="s2">, </span><span class="s1">lax._zeros(g_updates))</span>

  <span class="s0"># d) perform scatter-adds to compute the primal and tangent outputs.</span>
  <span class="s1">val_out = scatter_add(masked_operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">masked_updates</span><span class="s2">,</span>
                        <span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                        <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                        <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">mode=mode)</span>
  <span class="s1">tangent_out = scatter_add(masked_g_operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">masked_g_updates</span><span class="s2">,</span>
                            <span class="s1">dimension_numbers=dnums</span><span class="s2">,</span>
                            <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                            <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">mode=mode)</span>
  <span class="s2">return </span><span class="s1">val_out</span><span class="s2">, </span><span class="s1">tangent_out</span>

<span class="s2">def </span><span class="s1">_scatter_transpose_rule(t</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                            <span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                            <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s2">if not </span><span class="s1">unique_indices:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s4">&quot;scatter transpose is only implemented where&quot;</span>
                              <span class="s4">&quot;unique_indices=True&quot;</span><span class="s1">)</span>
  <span class="s2">assert not </span><span class="s1">ad.is_undefined_primal(indices)</span>
  <span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates):</span>
    <span class="s1">updates_shape = updates.aval.shape</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">updates_shape = updates.shape</span>
  <span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is </span><span class="s1">ad_util.Zero:</span>
    <span class="s1">operand_t = ad_util.Zero(operand.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand) </span><span class="s2">else None</span>
    <span class="s1">update_t = ad_util.Zero(updates.aval) </span><span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates) </span><span class="s2">else None</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">operand_t = update_t = </span><span class="s2">None</span>
    <span class="s2">if </span><span class="s1">ad.is_undefined_primal(operand):</span>
      <span class="s0"># Zero out gradient entries that correspond to updated indices.</span>
      <span class="s1">mask = scatter(lax._ones(t</span><span class="s2">, </span><span class="s1">dtype=np.bool_)</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">,</span>
                     <span class="s1">lax.full(updates_shape</span><span class="s2">, False</span><span class="s1">)</span><span class="s2">,</span>
                     <span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
                     <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                     <span class="s1">unique_indices=</span><span class="s2">True, </span><span class="s1">mode=mode)</span>
      <span class="s1">operand_t = lax.select(mask</span><span class="s2">, </span><span class="s1">t</span><span class="s2">, </span><span class="s1">lax._zeros(t))</span>

    <span class="s2">if </span><span class="s1">ad.is_undefined_primal(updates):</span>
      <span class="s1">gather_dnums = GatherDimensionNumbers(</span>
        <span class="s1">offset_dims=dimension_numbers.update_window_dims</span><span class="s2">,</span>
        <span class="s1">collapsed_slice_dims=dimension_numbers.inserted_window_dims</span><span class="s2">,</span>
        <span class="s1">start_index_map=dimension_numbers.scatter_dims_to_operand_dims)</span>
      <span class="s1">slice_sizes = []</span>
      <span class="s1">pos = </span><span class="s5">0</span>
      <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(t.shape)):</span>
        <span class="s2">if </span><span class="s1">i </span><span class="s2">in </span><span class="s1">dimension_numbers.inserted_window_dims:</span>
          <span class="s1">slice_sizes.append(</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
          <span class="s1">slice_sizes.append(updates_shape[dimension_numbers.update_window_dims[pos]])</span>
          <span class="s1">pos += </span><span class="s5">1</span>
      <span class="s1">update_t = gather(t</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">dimension_numbers=gather_dnums</span><span class="s2">,</span>
                        <span class="s1">slice_sizes=slice_sizes</span><span class="s2">, </span><span class="s1">mode=mode</span><span class="s2">,</span>
                        <span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>

  <span class="s2">return </span><span class="s1">[operand_t</span><span class="s2">, None, </span><span class="s1">update_t]</span>

<span class="s1">scatter_p = standard_primitive(</span>
    <span class="s1">_scatter_shape_rule</span><span class="s2">, </span><span class="s1">_scatter_dtype_rule</span><span class="s2">, </span><span class="s4">'scatter'</span><span class="s2">,</span>
    <span class="s1">weak_type_rule=_argnum_weak_type(</span><span class="s5">0</span><span class="s1">))</span>
<span class="s1">ad.primitive_jvps[scatter_p] = _scatter_jvp</span>
<span class="s1">ad.primitive_transposes[scatter_p] = _scatter_transpose_rule</span>
<span class="s1">batching.primitive_batchers[scatter_p] = (</span>
  <span class="s1">partial(_scatter_batching_rule</span><span class="s2">, </span><span class="s1">scatter))</span>


<span class="s2">def </span><span class="s1">_scatter_lower(ctx</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">, </span><span class="s1">*</span><span class="s2">,</span>
                   <span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                   <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s2">if </span><span class="s1">mode == GatherScatterMode.CLIP:</span>
    <span class="s1">clip_fn = mlir.lower_fun(_clamp_scatter_indices</span><span class="s2">, </span><span class="s1">multiple_results=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">(indices</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">= clip_fn(ctx.replace(avals_out=</span><span class="s2">None</span><span class="s1">)</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">,</span>
                          <span class="s1">updates</span><span class="s2">, </span><span class="s1">dnums=dimension_numbers)</span>

  <span class="s1">aval_out</span><span class="s2">, </span><span class="s1">= ctx.avals_out</span>
  <span class="s1">dnums = dimension_numbers</span>
  <span class="s1">scatter_dnums = hlo.ScatterDimensionNumbers.get(</span>
    <span class="s1">update_window_dims=list(dnums.update_window_dims)</span><span class="s2">,</span>
    <span class="s1">inserted_window_dims=list(dnums.inserted_window_dims)</span><span class="s2">,</span>
    <span class="s1">scattered_dims_to_operand_dims=list(dnums.scatter_dims_to_operand_dims)</span><span class="s2">,</span>
    <span class="s1">index_vector_dim=len(ctx.avals_in[</span><span class="s5">1</span><span class="s1">].shape) - </span><span class="s5">1</span><span class="s1">)</span>
  <span class="s1">result = mlir.aval_to_ir_types(aval_out)</span>
  <span class="s1">operand = [operand]</span>
  <span class="s1">updates = [updates]</span>
  <span class="s1">op = hlo.ScatterOp(</span>
      <span class="s1">result</span><span class="s2">,</span>
      <span class="s1">operand</span><span class="s2">,</span>
      <span class="s1">indices</span><span class="s2">,</span>
      <span class="s1">updates</span><span class="s2">,</span>
      <span class="s1">scatter_dnums</span><span class="s2">,</span>
      <span class="s1">indices_are_sorted=ir.BoolAttr.get(indices_are_sorted)</span><span class="s2">,</span>
      <span class="s1">unique_indices=ir.BoolAttr.get(unique_indices))</span>
  <span class="s1">scalar_type = mlir.aval_to_ir_type(core.ShapedArray(()</span><span class="s2">, </span><span class="s1">aval_out.dtype))</span>
  <span class="s1">update = op.update_computation.blocks.append(scalar_type</span><span class="s2">, </span><span class="s1">scalar_type)</span>
  <span class="s2">with </span><span class="s1">ir.InsertionPoint(update):</span>
    <span class="s1">update_ctx = ctx.module_context.replace(</span>
        <span class="s1">name_stack=source_info_util.new_name_stack())</span>
    <span class="s2">if </span><span class="s1">update_jaxpr.effects:</span>
      <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s4">'Cannot lower effectful `scatter`.'</span><span class="s1">)</span>
    <span class="s1">out_nodes</span><span class="s2">, </span><span class="s1">_ = mlir.jaxpr_subcomp(</span>
        <span class="s1">update_ctx</span><span class="s2">, </span><span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">mlir.TokenSet()</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">,</span>
        <span class="s1">(update.arguments[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(update.arguments[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">dim_var_values=ctx.dim_var_values)</span>
    <span class="s1">hlo.ReturnOp(util.flatten(out_nodes))</span>
  <span class="s2">return </span><span class="s1">op.results</span>

<span class="s1">mlir.register_lowering(scatter_p</span><span class="s2">, </span><span class="s1">_scatter_lower)</span>
<span class="s1">mlir.register_lowering(scatter_add_p</span><span class="s2">, </span><span class="s1">_scatter_lower)</span>
<span class="s1">mlir.register_lowering(scatter_mul_p</span><span class="s2">, </span><span class="s1">_scatter_lower)</span>
<span class="s1">mlir.register_lowering(scatter_min_p</span><span class="s2">, </span><span class="s1">_scatter_lower)</span>
<span class="s1">mlir.register_lowering(scatter_max_p</span><span class="s2">, </span><span class="s1">_scatter_lower)</span>


<span class="s2">def </span><span class="s1">_real_dtype(dtype): </span><span class="s2">return </span><span class="s1">np.finfo(dtype).dtype</span>

<span class="s2">def </span><span class="s1">_scatter_add_lower_gpu(ctx</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">,</span>
                           <span class="s1">*</span><span class="s2">, </span><span class="s1">update_jaxpr</span><span class="s2">, </span><span class="s1">update_consts</span><span class="s2">, </span><span class="s1">dimension_numbers</span><span class="s2">,</span>
                           <span class="s1">indices_are_sorted</span><span class="s2">, </span><span class="s1">unique_indices</span><span class="s2">, </span><span class="s1">mode):</span>
  <span class="s1">operand_aval_in</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">updates_aval_in = ctx.avals_in</span>
  <span class="s2">if </span><span class="s1">operand_aval_in.dtype != np.complex128:</span>
    <span class="s2">return </span><span class="s1">_scatter_lower(ctx</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">,</span>
                          <span class="s1">update_jaxpr=update_jaxpr</span><span class="s2">,</span>
                          <span class="s1">update_consts=update_consts</span><span class="s2">,</span>
                          <span class="s1">dimension_numbers=dimension_numbers</span><span class="s2">,</span>
                          <span class="s1">indices_are_sorted=indices_are_sorted</span><span class="s2">,</span>
                          <span class="s1">unique_indices=unique_indices</span><span class="s2">, </span><span class="s1">mode=mode)</span>

  <span class="s2">if </span><span class="s1">mode == GatherScatterMode.CLIP:</span>
    <span class="s1">clip_fn = mlir.lower_fun(_clamp_scatter_indices</span><span class="s2">, </span><span class="s1">multiple_results=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">(indices</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">= clip_fn(ctx.replace(avals_out=</span><span class="s2">None</span><span class="s1">)</span><span class="s2">, </span><span class="s1">operand</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">updates</span><span class="s2">,</span>
                          <span class="s1">dnums=dimension_numbers)</span>

  <span class="s1">aval_out</span><span class="s2">, </span><span class="s1">= ctx.avals_out</span>
  <span class="s1">dnums = dimension_numbers</span>
  <span class="s1">scatter_dnums = hlo.ScatterDimensionNumbers.get(</span>
    <span class="s1">update_window_dims=list(dnums.update_window_dims)</span><span class="s2">,</span>
    <span class="s1">inserted_window_dims=list(dnums.inserted_window_dims)</span><span class="s2">,</span>
    <span class="s1">scattered_dims_to_operand_dims=list(dnums.scatter_dims_to_operand_dims)</span><span class="s2">,</span>
    <span class="s1">index_vector_dim=len(ctx.avals_in[</span><span class="s5">1</span><span class="s1">].shape) - </span><span class="s5">1</span><span class="s1">)</span>
  <span class="s1">real_dtype = _real_dtype(aval_out.dtype)</span>
  <span class="s1">operand_type_part = mlir.aval_to_ir_types(</span>
      <span class="s1">core.ShapedArray(aval_out.shape</span><span class="s2">, </span><span class="s1">real_dtype))</span>

  <span class="s2">def </span><span class="s1">_scatter(operand_part</span><span class="s2">, </span><span class="s1">updates_part):</span>
    <span class="s1">operand_part = [operand_part]</span>
    <span class="s1">updates_part = [updates_part]</span>

    <span class="s1">scatter = hlo.ScatterOp(</span>
        <span class="s1">operand_type_part</span><span class="s2">,</span>
        <span class="s1">operand_part</span><span class="s2">,</span>
        <span class="s1">indices</span><span class="s2">,</span>
        <span class="s1">updates_part</span><span class="s2">,</span>
        <span class="s1">scatter_dnums</span><span class="s2">,</span>
        <span class="s1">indices_are_sorted=ir.BoolAttr.get(indices_are_sorted)</span><span class="s2">,</span>
        <span class="s1">unique_indices=ir.BoolAttr.get(unique_indices))</span>
    <span class="s1">scalar_type = mlir.aval_to_ir_type(core.ShapedArray(()</span><span class="s2">, </span><span class="s1">real_dtype))</span>
    <span class="s1">reducer = scatter.regions[</span><span class="s5">0</span><span class="s1">].blocks.append(scalar_type</span><span class="s2">, </span><span class="s1">scalar_type)</span>
    <span class="s2">with </span><span class="s1">ir.InsertionPoint(reducer):</span>
      <span class="s1">add = hlo.AddOp(*reducer.arguments).result</span>
      <span class="s1">hlo.ReturnOp([add])</span>
    <span class="s2">return </span><span class="s1">scatter.result</span>

  <span class="s1">real = _scatter(hlo.RealOp(operand).result</span><span class="s2">, </span><span class="s1">hlo.RealOp(updates).result)</span>
  <span class="s1">imag = _scatter(hlo.ImagOp(operand).result</span><span class="s2">, </span><span class="s1">hlo.ImagOp(updates).result)</span>
  <span class="s2">return </span><span class="s1">hlo.ComplexOp(real</span><span class="s2">, </span><span class="s1">imag).results</span>

<span class="s1">mlir.register_lowering(scatter_add_p</span><span class="s2">, </span><span class="s1">_scatter_add_lower_gpu</span><span class="s2">, </span><span class="s1">platform=</span><span class="s4">&quot;gpu&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_dynamic_slice_indices(</span>
    <span class="s1">operand: Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">,</span>
    <span class="s1">start_indices: Union[Union[Array</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">Sequence[ArrayLike]]</span>
  <span class="s1">) -&gt; List[ArrayLike]:</span>
  <span class="s0"># Normalize the start_indices w.r.t. operand.shape</span>
  <span class="s2">if </span><span class="s1">len(start_indices) != operand.ndim:</span>
    <span class="s1">msg = (</span><span class="s4">&quot;Length of slice indices must match number of operand dimensions ({} &quot;</span>
          <span class="s4">&quot;vs {})&quot;</span><span class="s1">)</span>
    <span class="s2">raise </span><span class="s1">ValueError(msg.format(len(start_indices)</span><span class="s2">, </span><span class="s1">operand.shape))</span>
  <span class="s2">if not </span><span class="s1">isinstance(start_indices</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
    <span class="s2">if </span><span class="s1">start_indices.ndim != </span><span class="s5">1</span><span class="s1">:  </span><span class="s0"># type: ignore[union-attr]</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Slice indices must be a 1D sequence, got {}&quot;</span>
                       <span class="s1">.format(start_indices.shape))  </span><span class="s0"># type: ignore[union-attr]</span>
    <span class="s1">start_indices = list(start_indices)</span>
  <span class="s1">result: List[ArrayLike] = []</span>
  <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">d </span><span class="s2">in </span><span class="s1">zip(start_indices</span><span class="s2">, </span><span class="s1">operand.shape):</span>
    <span class="s0"># We test whether i and d are static to avoid unnecessary staging.</span>
    <span class="s2">if </span><span class="s1">isinstance(i</span><span class="s2">, </span><span class="s1">(int</span><span class="s2">, </span><span class="s1">np.integer)) </span><span class="s2">and </span><span class="s1">core.is_constant_dim(d):</span>
      <span class="s1">result.append(lax.convert_element_type(i + d </span><span class="s2">if </span><span class="s1">i &lt; </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">i</span><span class="s2">, </span><span class="s1">_dtype(i)))</span>
      <span class="s2">continue</span>
    <span class="s1">d = core.dimension_as_value(d)</span>
    <span class="s2">if </span><span class="s1">isinstance(i</span><span class="s2">, </span><span class="s1">(int</span><span class="s2">, </span><span class="s1">np.integer)):</span>
      <span class="s1">result.append(i + lax.convert_element_type(d</span><span class="s2">, </span><span class="s1">_dtype(i)) </span><span class="s2">if </span><span class="s1">i &lt; </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">i)</span>
      <span class="s2">continue</span>
    <span class="s1">d_arr = lax.convert_element_type(d</span><span class="s2">, </span><span class="s1">_dtype(i))</span>
    <span class="s1">result.append(lax.select(i &lt; </span><span class="s5">0</span><span class="s2">, </span><span class="s1">i + d_arr</span><span class="s2">, </span><span class="s1">i))</span>
  <span class="s2">return </span><span class="s1">result</span>
</pre>
</body>
</html>