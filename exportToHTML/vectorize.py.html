<html>
<head>
<title>vectorize.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
vectorize.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2020 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">import </span><span class="s1">functools</span>
<span class="s2">import </span><span class="s1">re</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">Any</span><span class="s2">, </span><span class="s1">Callable</span><span class="s2">, </span><span class="s1">Dict</span><span class="s2">, </span><span class="s1">List</span><span class="s2">, </span><span class="s1">Tuple</span>

<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">api</span>
<span class="s2">from </span><span class="s1">jax </span><span class="s2">import </span><span class="s1">lax</span>
<span class="s2">from </span><span class="s1">jax._src.numpy </span><span class="s2">import </span><span class="s1">lax_numpy </span><span class="s2">as </span><span class="s1">jnp</span>
<span class="s2">from </span><span class="s1">jax._src.util </span><span class="s2">import </span><span class="s1">safe_map </span><span class="s2">as </span><span class="s1">map</span><span class="s2">, </span><span class="s1">safe_zip </span><span class="s2">as </span><span class="s1">zip</span>


<span class="s0"># See http://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html</span>
<span class="s1">_DIMENSION_NAME = </span><span class="s3">r'\w+'</span>
<span class="s1">_CORE_DIMENSION_LIST = </span><span class="s3">'(?:{0:}(?:,{0:})*)?'</span><span class="s1">.format(_DIMENSION_NAME)</span>
<span class="s1">_ARGUMENT = </span><span class="s3">fr'\(</span><span class="s2">{</span><span class="s1">_CORE_DIMENSION_LIST</span><span class="s2">}</span><span class="s3">\)'</span>
<span class="s1">_ARGUMENT_LIST = </span><span class="s3">'{0:}(?:,{0:})*'</span><span class="s1">.format(_ARGUMENT)</span>
<span class="s1">_SIGNATURE = </span><span class="s3">'^{0:}-&gt;{0:}$'</span><span class="s1">.format(_ARGUMENT_LIST)</span>


<span class="s1">CoreDims = Tuple[str</span><span class="s2">, </span><span class="s1">...]</span>
<span class="s1">NDArray = Any</span>


<span class="s2">def </span><span class="s1">_parse_gufunc_signature(</span>
    <span class="s1">signature: str</span><span class="s2">,</span>
<span class="s1">) -&gt; Tuple[List[CoreDims]</span><span class="s2">, </span><span class="s1">List[CoreDims]]:</span>
  <span class="s4">&quot;&quot;&quot;Parse string signatures for a generalized universal function. 
 
  Args: 
    signature: generalized universal function signature, e.g., 
      ``(m,n),(n,p)-&gt;(m,p)`` for ``jnp.matmul``. 
 
  Returns: 
    Input and output core dimensions parsed from the signature. 
  &quot;&quot;&quot;</span>
  <span class="s2">if not </span><span class="s1">re.match(_SIGNATURE</span><span class="s2">, </span><span class="s1">signature):</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span>
        <span class="s3">f'not a valid gufunc signature: </span><span class="s2">{</span><span class="s1">signature</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
  <span class="s1">args</span><span class="s2">, </span><span class="s1">retvals = ([tuple(re.findall(_DIMENSION_NAME</span><span class="s2">, </span><span class="s1">arg))</span>
                   <span class="s2">for </span><span class="s1">arg </span><span class="s2">in </span><span class="s1">re.findall(_ARGUMENT</span><span class="s2">, </span><span class="s1">arg_list)]</span>
                   <span class="s2">for </span><span class="s1">arg_list </span><span class="s2">in </span><span class="s1">signature.split(</span><span class="s3">'-&gt;'</span><span class="s1">))</span>
  <span class="s2">return </span><span class="s1">args</span><span class="s2">, </span><span class="s1">retvals</span>


<span class="s2">def </span><span class="s1">_update_dim_sizes(</span>
    <span class="s1">dim_sizes: Dict[str</span><span class="s2">, </span><span class="s1">int]</span><span class="s2">,</span>
    <span class="s1">shape: Tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">,</span>
    <span class="s1">core_dims: CoreDims</span><span class="s2">,</span>
    <span class="s1">error_context: str = </span><span class="s3">&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">*</span><span class="s2">,</span>
    <span class="s1">is_input: bool):</span>
  <span class="s4">&quot;&quot;&quot;Incrementally check and update core dimension sizes for a single argument. 
 
  Args: 
    dim_sizes: sizes of existing core dimensions. Will be updated in-place. 
    shape: shape of this argument. 
    core_dims: core dimensions for this argument. 
    error_context: string context for error messages. 
    is_input: are we parsing input or output arguments? 
  &quot;&quot;&quot;</span>
  <span class="s1">num_core_dims = len(core_dims)</span>
  <span class="s2">if </span><span class="s1">is_input:</span>
    <span class="s2">if </span><span class="s1">len(shape) &lt; num_core_dims:</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span>
          <span class="s3">'input with shape %r does not have enough dimensions for all core '</span>
          <span class="s3">'dimensions %r %s' </span><span class="s1">% (shape</span><span class="s2">, </span><span class="s1">core_dims</span><span class="s2">, </span><span class="s1">error_context))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">if </span><span class="s1">len(shape) != num_core_dims:</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span>
          <span class="s3">'output shape %r does not match core dimensions %r %s'</span>
          <span class="s1">% (shape</span><span class="s2">, </span><span class="s1">core_dims</span><span class="s2">, </span><span class="s1">error_context))</span>

  <span class="s1">core_shape = shape[-num_core_dims:] </span><span class="s2">if </span><span class="s1">core_dims </span><span class="s2">else </span><span class="s1">()</span>
  <span class="s2">for </span><span class="s1">dim</span><span class="s2">, </span><span class="s1">size </span><span class="s2">in </span><span class="s1">zip(core_dims</span><span class="s2">, </span><span class="s1">core_shape):</span>
    <span class="s2">if </span><span class="s1">dim </span><span class="s2">not in </span><span class="s1">dim_sizes:</span>
      <span class="s1">dim_sizes[dim] = size</span>
    <span class="s2">elif </span><span class="s1">size != dim_sizes[dim]:</span>
      <span class="s2">raise </span><span class="s1">ValueError(</span>
          <span class="s3">'inconsistent size for core dimension %r: %r vs %r %s'</span>
          <span class="s1">% (dim</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">dim_sizes[dim]</span><span class="s2">, </span><span class="s1">error_context))</span>


<span class="s2">def </span><span class="s1">_parse_input_dimensions(</span>
    <span class="s1">args: Tuple[NDArray</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">,</span>
    <span class="s1">input_core_dims: List[CoreDims]</span><span class="s2">,</span>
    <span class="s1">error_context: str = </span><span class="s3">&quot;&quot;</span><span class="s2">,</span>
<span class="s1">) -&gt; Tuple[Tuple[int</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">Dict[str</span><span class="s2">, </span><span class="s1">int]]:</span>
  <span class="s4">&quot;&quot;&quot;Parse broadcast and core dimensions for vectorize with a signature. 
 
  Args: 
    args: tuple of input arguments to examine. 
    input_core_dims: list of core dimensions corresponding to each input. 
    error_context: string context for error messages. 
 
  Returns: 
    broadcast_shape: common shape to broadcast all non-core dimensions to. 
    dim_sizes: common sizes for named core dimensions. 
  &quot;&quot;&quot;</span>
  <span class="s2">if </span><span class="s1">len(args) != len(input_core_dims):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span>
        <span class="s3">'wrong number of positional arguments: expected %r, got %r %s'</span>
        <span class="s1">% (len(input_core_dims)</span><span class="s2">, </span><span class="s1">len(args)</span><span class="s2">, </span><span class="s1">error_context))</span>
  <span class="s1">shapes = []</span>
  <span class="s1">dim_sizes: Dict[str</span><span class="s2">, </span><span class="s1">int] = {}</span>
  <span class="s2">for </span><span class="s1">arg</span><span class="s2">, </span><span class="s1">core_dims </span><span class="s2">in </span><span class="s1">zip(args</span><span class="s2">, </span><span class="s1">input_core_dims):</span>
    <span class="s1">_update_dim_sizes(dim_sizes</span><span class="s2">, </span><span class="s1">arg.shape</span><span class="s2">, </span><span class="s1">core_dims</span><span class="s2">, </span><span class="s1">error_context</span><span class="s2">,</span>
                      <span class="s1">is_input=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">ndim = arg.ndim - len(core_dims)</span>
    <span class="s1">shapes.append(arg.shape[:ndim])</span>
  <span class="s1">broadcast_shape = lax.broadcast_shapes(*shapes)</span>
  <span class="s0"># TODO(mattjj): this code needs updating for dynamic shapes (hence ignore)</span>
  <span class="s2">return </span><span class="s1">broadcast_shape</span><span class="s2">, </span><span class="s1">dim_sizes  </span><span class="s0"># type: ignore</span>


<span class="s2">def </span><span class="s1">_check_output_dims(</span>
    <span class="s1">func: Callable</span><span class="s2">,</span>
    <span class="s1">dim_sizes: Dict[str</span><span class="s2">, </span><span class="s1">int]</span><span class="s2">,</span>
    <span class="s1">expected_output_core_dims: List[CoreDims]</span><span class="s2">,</span>
    <span class="s1">error_context: str = </span><span class="s3">&quot;&quot;</span><span class="s2">,</span>
<span class="s1">) -&gt; Callable:</span>
  <span class="s4">&quot;&quot;&quot;Check that output core dimensions match the signature.&quot;&quot;&quot;</span>
  <span class="s2">def </span><span class="s1">wrapped(*args):</span>
    <span class="s1">out = func(*args)</span>
    <span class="s1">out_shapes = map(jnp.shape</span><span class="s2">, </span><span class="s1">out </span><span class="s2">if </span><span class="s1">isinstance(out</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">else </span><span class="s1">[out])</span>

    <span class="s2">if </span><span class="s1">expected_output_core_dims </span><span class="s2">is None</span><span class="s1">:</span>
      <span class="s1">output_core_dims = [()] * len(out_shapes)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">output_core_dims = expected_output_core_dims</span>
      <span class="s2">if </span><span class="s1">len(output_core_dims) &gt; </span><span class="s5">1 </span><span class="s2">and not </span><span class="s1">isinstance(out</span><span class="s2">, </span><span class="s1">tuple):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s3">&quot;output must be a tuple when multiple outputs are expected, &quot;</span>
            <span class="s3">&quot;got: {!r}</span><span class="s2">\n</span><span class="s3">{}&quot;</span><span class="s1">.format(out</span><span class="s2">, </span><span class="s1">error_context))</span>
      <span class="s2">if </span><span class="s1">len(out_shapes) != len(output_core_dims):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s3">'wrong number of output arguments: expected %r, got %r %s'</span>
            <span class="s1">% (len(output_core_dims)</span><span class="s2">, </span><span class="s1">len(out_shapes)</span><span class="s2">, </span><span class="s1">error_context))</span>

    <span class="s1">sizes = dict(dim_sizes)</span>
    <span class="s2">for </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">core_dims </span><span class="s2">in </span><span class="s1">zip(out_shapes</span><span class="s2">, </span><span class="s1">output_core_dims):</span>
      <span class="s1">_update_dim_sizes(sizes</span><span class="s2">, </span><span class="s1">shape</span><span class="s2">, </span><span class="s1">core_dims</span><span class="s2">, </span><span class="s1">error_context</span><span class="s2">,</span>
                        <span class="s1">is_input=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">out</span>
  <span class="s2">return </span><span class="s1">wrapped</span>


<span class="s2">def </span><span class="s1">_apply_excluded(func</span><span class="s2">, </span><span class="s1">excluded</span><span class="s2">, </span><span class="s1">args):</span>
  <span class="s4">&quot;&quot;&quot;Partially apply positional arguments in `excluded` to a function.&quot;&quot;&quot;</span>
  <span class="s2">if not </span><span class="s1">excluded:</span>
    <span class="s2">return </span><span class="s1">func</span><span class="s2">, </span><span class="s1">args</span>

  <span class="s2">if </span><span class="s1">max(excluded) &gt;= len(args):</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">&quot;excluded={!r} is invalid for {!r} argument(s)&quot;</span>
                     <span class="s1">.format(excluded</span><span class="s2">, </span><span class="s1">len(args)))</span>

  <span class="s1">dynamic_args = [arg </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">arg </span><span class="s2">in </span><span class="s1">enumerate(args) </span><span class="s2">if </span><span class="s1">i </span><span class="s2">not in </span><span class="s1">excluded]</span>
  <span class="s1">static_args = [(i</span><span class="s2">, </span><span class="s1">args[i]) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">sorted(excluded)]</span>

  <span class="s2">def </span><span class="s1">new_func(*args):</span>
    <span class="s1">args = list(args)</span>
    <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">arg </span><span class="s2">in </span><span class="s1">static_args:</span>
      <span class="s1">args.insert(i</span><span class="s2">, </span><span class="s1">arg)</span>
    <span class="s2">return </span><span class="s1">func(*args)</span>

  <span class="s2">return </span><span class="s1">new_func</span><span class="s2">, </span><span class="s1">dynamic_args</span>


<span class="s2">def </span><span class="s1">vectorize(pyfunc</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">excluded=frozenset()</span><span class="s2">, </span><span class="s1">signature=</span><span class="s2">None</span><span class="s1">):</span>
  <span class="s4">&quot;&quot;&quot;Define a vectorized function with broadcasting. 
 
  :func:`vectorize` is a convenience wrapper for defining vectorized 
  functions with broadcasting, in the style of NumPy's 
  `generalized universal functions &lt;https://numpy.org/doc/stable/reference/c-api/generalized-ufuncs.html&gt;`_. 
  It allows for defining functions that are automatically repeated across 
  any leading dimensions, without the implementation of the function needing to 
  be concerned about how to handle higher dimensional inputs. 
 
  :func:`jax.numpy.vectorize` has the same interface as 
  :class:`numpy.vectorize`, but it is syntactic sugar for an auto-batching 
  transformation (:func:`vmap`) rather than a Python loop. This should be 
  considerably more efficient, but the implementation must be written in terms 
  of functions that act on JAX arrays. 
 
  Args: 
    pyfunc: function to vectorize. 
    excluded: optional set of integers representing positional arguments for 
      which the function will not be vectorized. These will be passed directly 
      to ``pyfunc`` unmodified. 
    signature: optional generalized universal function signature, e.g., 
      ``(m,n),(n)-&gt;(m)`` for vectorized matrix-vector multiplication. If 
      provided, ``pyfunc`` will be called with (and expected to return) arrays 
      with shapes given by the size of corresponding core dimensions. By 
      default, pyfunc is assumed to take scalars arrays as input and output. 
 
  Returns: 
    Vectorized version of the given function. 
 
  Here are a few examples of how one could write vectorized linear algebra 
  routines using :func:`vectorize`: 
 
  &gt;&gt;&gt; from functools import partial 
 
  &gt;&gt;&gt; @partial(jnp.vectorize, signature='(k),(k)-&gt;(k)') 
  ... def cross_product(a, b): 
  ...   assert a.shape == b.shape and a.ndim == b.ndim == 1 
  ...   return jnp.array([a[1] * b[2] - a[2] * b[1], 
  ...                     a[2] * b[0] - a[0] * b[2], 
  ...                     a[0] * b[1] - a[1] * b[0]]) 
 
  &gt;&gt;&gt; @partial(jnp.vectorize, signature='(n,m),(m)-&gt;(n)') 
  ... def matrix_vector_product(matrix, vector): 
  ...   assert matrix.ndim == 2 and matrix.shape[1:] == vector.shape 
  ...   return matrix @ vector 
 
  These functions are only written to handle 1D or 2D arrays (the ``assert`` 
  statements will never be violated), but with vectorize they support 
  arbitrary dimensional inputs with NumPy style broadcasting, e.g., 
 
  &gt;&gt;&gt; cross_product(jnp.ones(3), jnp.ones(3)).shape 
  (3,) 
  &gt;&gt;&gt; cross_product(jnp.ones((2, 3)), jnp.ones(3)).shape 
  (2, 3) 
  &gt;&gt;&gt; cross_product(jnp.ones((1, 2, 3)), jnp.ones((2, 1, 3))).shape 
  (2, 2, 3) 
  &gt;&gt;&gt; matrix_vector_product(jnp.ones(3), jnp.ones(3))  # doctest: +IGNORE_EXCEPTION_DETAIL 
  Traceback (most recent call last): 
  ValueError: input with shape (3,) does not have enough dimensions for all 
  core dimensions ('n', 'k') on vectorized function with excluded=frozenset() 
  and signature='(n,k),(k)-&gt;(k)' 
  &gt;&gt;&gt; matrix_vector_product(jnp.ones((2, 3)), jnp.ones(3)).shape 
  (2,) 
  &gt;&gt;&gt; matrix_vector_product(jnp.ones((2, 3)), jnp.ones((4, 3))).shape 
  (4, 2) 
 
  Note that this has different semantics than `jnp.matmul`: 
 
  &gt;&gt;&gt; jnp.matmul(jnp.ones((2, 3)), jnp.ones((4, 3)))  # doctest: +IGNORE_EXCEPTION_DETAIL 
  Traceback (most recent call last): 
  TypeError: dot_general requires contracting dimensions to have the same shape, got [3] and [4]. 
  &quot;&quot;&quot;</span>
  <span class="s2">if </span><span class="s1">any(</span><span class="s2">not </span><span class="s1">isinstance(exclude</span><span class="s2">, </span><span class="s1">int) </span><span class="s2">for </span><span class="s1">exclude </span><span class="s2">in </span><span class="s1">excluded):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s3">&quot;jax.numpy.vectorize can only exclude integer arguments, &quot;</span>
                    <span class="s3">&quot;but excluded={!r}&quot;</span><span class="s1">.format(excluded))</span>
  <span class="s2">if </span><span class="s1">excluded </span><span class="s2">and </span><span class="s1">min(excluded) &lt; </span><span class="s5">0</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s3">f&quot;excluded=</span><span class="s2">{</span><span class="s1">excluded</span><span class="s2">!r} </span><span class="s3">contains negative numbers&quot;</span><span class="s1">)</span>

  <span class="s1">@functools.wraps(pyfunc)</span>
  <span class="s2">def </span><span class="s1">wrapped(*args):</span>
    <span class="s1">error_context = (</span><span class="s3">&quot;on vectorized function with excluded={!r} and &quot;</span>
                     <span class="s3">&quot;signature={!r}&quot;</span><span class="s1">.format(excluded</span><span class="s2">, </span><span class="s1">signature))</span>
    <span class="s1">excluded_func</span><span class="s2">, </span><span class="s1">args = _apply_excluded(pyfunc</span><span class="s2">, </span><span class="s1">excluded</span><span class="s2">, </span><span class="s1">args)</span>
    <span class="s1">args = tuple(map(jnp.asarray</span><span class="s2">, </span><span class="s1">args))</span>

    <span class="s2">if </span><span class="s1">signature </span><span class="s2">is not None</span><span class="s1">:</span>
      <span class="s1">input_core_dims</span><span class="s2">, </span><span class="s1">output_core_dims = _parse_gufunc_signature(signature)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">input_core_dims = [()] * len(args)</span>
      <span class="s1">output_core_dims = </span><span class="s2">None</span>

    <span class="s1">broadcast_shape</span><span class="s2">, </span><span class="s1">dim_sizes = _parse_input_dimensions(</span>
        <span class="s1">args</span><span class="s2">, </span><span class="s1">input_core_dims</span><span class="s2">, </span><span class="s1">error_context)</span>

    <span class="s1">checked_func = _check_output_dims(</span>
        <span class="s1">excluded_func</span><span class="s2">, </span><span class="s1">dim_sizes</span><span class="s2">, </span><span class="s1">output_core_dims</span><span class="s2">, </span><span class="s1">error_context)</span>

    <span class="s0"># Rather than broadcasting all arguments to full broadcast shapes, prefer</span>
    <span class="s0"># expanding dimensions using vmap. By pushing broadcasting</span>
    <span class="s0"># into vmap, we can make use of more efficient batching rules for</span>
    <span class="s0"># primitives where only some arguments are batched (e.g., for</span>
    <span class="s0"># lax_linalg.triangular_solve), and avoid instantiating large broadcasted</span>
    <span class="s0"># arrays.</span>

    <span class="s1">squeezed_args = []</span>
    <span class="s1">rev_filled_shapes = []</span>

    <span class="s2">for </span><span class="s1">arg</span><span class="s2">, </span><span class="s1">core_dims </span><span class="s2">in </span><span class="s1">zip(args</span><span class="s2">, </span><span class="s1">input_core_dims):</span>
      <span class="s1">noncore_shape = arg.shape[:arg.ndim - len(core_dims)]</span>

      <span class="s1">pad_ndim = len(broadcast_shape) - len(noncore_shape)</span>
      <span class="s1">filled_shape = pad_ndim * (</span><span class="s5">1</span><span class="s2">,</span><span class="s1">) + noncore_shape</span>
      <span class="s1">rev_filled_shapes.append(filled_shape[::-</span><span class="s5">1</span><span class="s1">])</span>

      <span class="s1">squeeze_indices = tuple(i </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">size </span><span class="s2">in </span><span class="s1">enumerate(noncore_shape) </span><span class="s2">if </span><span class="s1">size == </span><span class="s5">1</span><span class="s1">)</span>
      <span class="s1">squeezed_arg = jnp.squeeze(arg</span><span class="s2">, </span><span class="s1">axis=squeeze_indices)</span>
      <span class="s1">squeezed_args.append(squeezed_arg)</span>

    <span class="s1">vectorized_func = checked_func</span>
    <span class="s1">dims_to_expand = []</span>
    <span class="s2">for </span><span class="s1">negdim</span><span class="s2">, </span><span class="s1">axis_sizes </span><span class="s2">in </span><span class="s1">enumerate(zip(*rev_filled_shapes)):</span>
      <span class="s1">in_axes = tuple(</span><span class="s2">None if </span><span class="s1">size == </span><span class="s5">1 </span><span class="s2">else </span><span class="s5">0 </span><span class="s2">for </span><span class="s1">size </span><span class="s2">in </span><span class="s1">axis_sizes)</span>
      <span class="s2">if </span><span class="s1">all(axis </span><span class="s2">is None for </span><span class="s1">axis </span><span class="s2">in </span><span class="s1">in_axes):</span>
        <span class="s1">dims_to_expand.append(len(broadcast_shape) - </span><span class="s5">1 </span><span class="s1">- negdim)</span>
      <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">vectorized_func = api.vmap(vectorized_func</span><span class="s2">, </span><span class="s1">in_axes)</span>
    <span class="s1">result = vectorized_func(*squeezed_args)</span>

    <span class="s2">if not </span><span class="s1">dims_to_expand:</span>
      <span class="s2">return </span><span class="s1">result</span>
    <span class="s2">elif </span><span class="s1">isinstance(result</span><span class="s2">, </span><span class="s1">tuple):</span>
      <span class="s2">return </span><span class="s1">tuple(jnp.expand_dims(r</span><span class="s2">, </span><span class="s1">axis=dims_to_expand) </span><span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span class="s1">result)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s2">return </span><span class="s1">jnp.expand_dims(result</span><span class="s2">, </span><span class="s1">axis=dims_to_expand)</span>

  <span class="s2">return </span><span class="s1">wrapped</span>
</pre>
</body>
</html>