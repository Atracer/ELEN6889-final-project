<html>
<head>
<title>csr.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #629755; font-style: italic;}
.s3 { color: #cc7832;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
csr.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2021 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>

<span class="s2">&quot;&quot;&quot;CSR (compressed sparse row) matrix object and associated primitives.&quot;&quot;&quot;</span>
<span class="s3">from </span><span class="s1">__future__ </span><span class="s3">import </span><span class="s1">annotations</span>

<span class="s3">from </span><span class="s1">functools </span><span class="s3">import </span><span class="s1">partial</span>
<span class="s3">import </span><span class="s1">operator</span>
<span class="s3">from </span><span class="s1">typing </span><span class="s3">import </span><span class="s1">Optional</span><span class="s3">, </span><span class="s1">Tuple</span>
<span class="s3">import </span><span class="s1">warnings</span>

<span class="s3">import </span><span class="s1">numpy </span><span class="s3">as </span><span class="s1">np</span>

<span class="s3">import </span><span class="s1">jax</span>
<span class="s3">from </span><span class="s1">jax.interpreters </span><span class="s3">import </span><span class="s1">mlir</span>
<span class="s3">from </span><span class="s1">jax.experimental.sparse._base </span><span class="s3">import </span><span class="s1">JAXSparse</span>
<span class="s3">from </span><span class="s1">jax.experimental.sparse.coo </span><span class="s3">import </span><span class="s1">_coo_matmat</span><span class="s3">, </span><span class="s1">_coo_matvec</span><span class="s3">, </span><span class="s1">_coo_todense</span><span class="s3">, </span><span class="s1">COOInfo</span>
<span class="s3">from </span><span class="s1">jax.experimental.sparse.util </span><span class="s3">import </span><span class="s1">_csr_to_coo</span><span class="s3">, </span><span class="s1">_csr_extract</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning</span>
<span class="s3">from </span><span class="s1">jax </span><span class="s3">import </span><span class="s1">lax</span>
<span class="s3">from </span><span class="s1">jax </span><span class="s3">import </span><span class="s1">tree_util</span>
<span class="s3">from </span><span class="s1">jax._src </span><span class="s3">import </span><span class="s1">core</span>
<span class="s3">from </span><span class="s1">jax._src </span><span class="s3">import </span><span class="s1">dispatch</span>
<span class="s3">from </span><span class="s1">jax._src.interpreters </span><span class="s3">import </span><span class="s1">ad</span>
<span class="s3">from </span><span class="s1">jax._src.lax.lax </span><span class="s3">import </span><span class="s1">_const</span>
<span class="s3">from </span><span class="s1">jax._src.lib </span><span class="s3">import </span><span class="s1">gpu_sparse</span>
<span class="s3">from </span><span class="s1">jax._src.numpy.util </span><span class="s3">import </span><span class="s1">promote_dtypes</span>
<span class="s3">from </span><span class="s1">jax._src.typing </span><span class="s3">import </span><span class="s1">Array</span><span class="s3">, </span><span class="s1">ArrayLike</span><span class="s3">, </span><span class="s1">DTypeLike</span>
<span class="s3">import </span><span class="s1">jax.numpy </span><span class="s3">as </span><span class="s1">jnp</span>


<span class="s1">Shape = Tuple[int</span><span class="s3">, </span><span class="s1">...]</span>


<span class="s1">@tree_util.register_pytree_node_class</span>
<span class="s3">class </span><span class="s1">CSR(JAXSparse):</span>
  <span class="s2">&quot;&quot;&quot;Experimental CSR matrix implemented in JAX. 
 
  Note: this class has minimal compatibility with JAX transforms such as 
  grad and autodiff, and offers very little functionality. In general you 
  should prefer :class:`jax.experimental.sparse.BCOO`. 
 
  Additionally, there are known failures in the case that `nse` is larger 
  than the true number of nonzeros in the represented matrix. This situation 
  is better handled in BCOO. 
  &quot;&quot;&quot;</span>
  <span class="s1">data: jax.Array</span>
  <span class="s1">indices: jax.Array</span>
  <span class="s1">indptr: jax.Array</span>
  <span class="s1">shape: Tuple[int</span><span class="s3">, </span><span class="s1">int]</span>
  <span class="s1">nse = property(</span><span class="s3">lambda </span><span class="s1">self: self.data.size)</span>
  <span class="s1">dtype = property(</span><span class="s3">lambda </span><span class="s1">self: self.data.dtype)</span>
  <span class="s1">_bufs = property(</span><span class="s3">lambda </span><span class="s1">self: (self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr))</span>

  <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">args</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape):</span>
    <span class="s1">self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr = map(jnp.asarray</span><span class="s3">, </span><span class="s1">args)</span>
    <span class="s1">super().__init__(args</span><span class="s3">, </span><span class="s1">shape=shape)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">fromdense(cls</span><span class="s3">, </span><span class="s1">mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse=</span><span class="s3">None, </span><span class="s1">index_dtype=np.int32):</span>
    <span class="s3">if </span><span class="s1">nse </span><span class="s3">is None</span><span class="s1">:</span>
      <span class="s1">nse = (mat != </span><span class="s4">0</span><span class="s1">).sum()</span>
    <span class="s3">return </span><span class="s1">csr_fromdense(mat</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">_empty(cls</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s3">None, </span><span class="s1">index_dtype=</span><span class="s5">'int32'</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Create an empty CSR instance. Public method is sparse.empty().&quot;&quot;&quot;</span>
    <span class="s1">shape = tuple(shape)</span>
    <span class="s3">if </span><span class="s1">len(shape) != </span><span class="s4">2</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;CSR must have ndim=2; got </span><span class="s3">{</span><span class="s1">shape=</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
    <span class="s1">data = jnp.empty(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">dtype)</span>
    <span class="s1">indices = jnp.empty(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">index_dtype)</span>
    <span class="s1">indptr = jnp.zeros(shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">index_dtype)</span>
    <span class="s3">return </span><span class="s1">cls((data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">shape=shape)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">_eye(cls</span><span class="s3">, </span><span class="s1">N</span><span class="s3">, </span><span class="s1">M</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s3">None, </span><span class="s1">index_dtype=</span><span class="s5">'int32'</span><span class="s1">):</span>
    <span class="s3">if </span><span class="s1">k &gt; </span><span class="s4">0</span><span class="s1">:</span>
      <span class="s1">diag_size = min(N</span><span class="s3">, </span><span class="s1">M - k)</span>
    <span class="s3">else</span><span class="s1">:</span>
      <span class="s1">diag_size = min(N + k</span><span class="s3">, </span><span class="s1">M)</span>

    <span class="s3">if </span><span class="s1">diag_size &lt;= </span><span class="s4">0</span><span class="s1">:</span>
      <span class="s0"># if k is out of range, return an empty matrix.</span>
      <span class="s3">return </span><span class="s1">cls._empty((N</span><span class="s3">, </span><span class="s1">M)</span><span class="s3">, </span><span class="s1">dtype=dtype</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>

    <span class="s1">data = jnp.ones(diag_size</span><span class="s3">, </span><span class="s1">dtype=dtype)</span>
    <span class="s1">idx = jnp.arange(diag_size</span><span class="s3">, </span><span class="s1">dtype=index_dtype)</span>
    <span class="s1">zero = _const(idx</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
    <span class="s1">k = _const(idx</span><span class="s3">, </span><span class="s1">k)</span>
    <span class="s1">col = lax.add(idx</span><span class="s3">, </span><span class="s1">lax.cond(k &lt;= </span><span class="s4">0</span><span class="s3">, lambda</span><span class="s1">: zero</span><span class="s3">, lambda</span><span class="s1">: k))</span>
    <span class="s1">indices = col.astype(index_dtype)</span>
    <span class="s0"># TODO(jakevdp): this can be done more efficiently.</span>
    <span class="s1">row = lax.sub(idx</span><span class="s3">, </span><span class="s1">lax.cond(k &gt;= </span><span class="s4">0</span><span class="s3">, lambda</span><span class="s1">: zero</span><span class="s3">, lambda</span><span class="s1">: k))</span>
    <span class="s1">indptr = jnp.zeros(N + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">dtype=index_dtype).at[</span><span class="s4">1</span><span class="s1">:].set(</span>
        <span class="s1">jnp.cumsum(jnp.bincount(row</span><span class="s3">, </span><span class="s1">length=N).astype(index_dtype)))</span>
    <span class="s3">return </span><span class="s1">cls((data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">shape=(N</span><span class="s3">, </span><span class="s1">M))</span>

  <span class="s3">def </span><span class="s1">todense(self):</span>
    <span class="s3">return </span><span class="s1">csr_todense(self)</span>

  <span class="s3">def </span><span class="s1">transpose(self</span><span class="s3">, </span><span class="s1">axes=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s3">assert </span><span class="s1">axes </span><span class="s3">is None</span>
    <span class="s3">return </span><span class="s1">CSC((self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr)</span><span class="s3">, </span><span class="s1">shape=self.shape[::-</span><span class="s4">1</span><span class="s1">])</span>

  <span class="s3">def </span><span class="s1">__matmul__(self</span><span class="s3">, </span><span class="s1">other):</span>
    <span class="s3">if </span><span class="s1">isinstance(other</span><span class="s3">, </span><span class="s1">JAXSparse):</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">&quot;matmul between two sparse objects.&quot;</span><span class="s1">)</span>
    <span class="s1">other = jnp.asarray(other)</span>
    <span class="s1">data</span><span class="s3">, </span><span class="s1">other = promote_dtypes(self.data</span><span class="s3">, </span><span class="s1">other)</span>
    <span class="s3">if </span><span class="s1">other.ndim == </span><span class="s4">1</span><span class="s1">:</span>
      <span class="s3">return </span><span class="s1">_csr_matvec(data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr</span><span class="s3">, </span><span class="s1">other</span><span class="s3">, </span><span class="s1">shape=self.shape)</span>
    <span class="s3">elif </span><span class="s1">other.ndim == </span><span class="s4">2</span><span class="s1">:</span>
      <span class="s3">return </span><span class="s1">_csr_matmat(data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr</span><span class="s3">, </span><span class="s1">other</span><span class="s3">, </span><span class="s1">shape=self.shape)</span>
    <span class="s3">else</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">f&quot;matmul with object of shape </span><span class="s3">{</span><span class="s1">other.shape</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">tree_flatten(self):</span>
    <span class="s3">return </span><span class="s1">(self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr)</span><span class="s3">, </span><span class="s1">{</span><span class="s5">&quot;shape&quot;</span><span class="s1">: self.shape}</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">tree_unflatten(cls</span><span class="s3">, </span><span class="s1">aux_data</span><span class="s3">, </span><span class="s1">children):</span>
    <span class="s1">obj = object.__new__(cls)</span>
    <span class="s1">obj.data</span><span class="s3">, </span><span class="s1">obj.indices</span><span class="s3">, </span><span class="s1">obj.indptr = children</span>
    <span class="s3">if </span><span class="s1">aux_data.keys() != {</span><span class="s5">'shape'</span><span class="s1">}:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;CSR.tree_unflatten: invalid </span><span class="s3">{</span><span class="s1">aux_data=</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
    <span class="s1">obj.__dict__.update(**aux_data)</span>
    <span class="s3">return </span><span class="s1">obj</span>


<span class="s1">@tree_util.register_pytree_node_class</span>
<span class="s3">class </span><span class="s1">CSC(JAXSparse):</span>
  <span class="s2">&quot;&quot;&quot;Experimental CSC matrix implemented in JAX; API subject to change.&quot;&quot;&quot;</span>
  <span class="s1">data: jax.Array</span>
  <span class="s1">indices: jax.Array</span>
  <span class="s1">indptr: jax.Array</span>
  <span class="s1">shape: Tuple[int</span><span class="s3">, </span><span class="s1">int]</span>
  <span class="s1">nse = property(</span><span class="s3">lambda </span><span class="s1">self: self.data.size)</span>
  <span class="s1">dtype = property(</span><span class="s3">lambda </span><span class="s1">self: self.data.dtype)</span>

  <span class="s3">def </span><span class="s1">__init__(self</span><span class="s3">, </span><span class="s1">args</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape):</span>
    <span class="s1">self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr = map(jnp.asarray</span><span class="s3">, </span><span class="s1">args)</span>
    <span class="s1">super().__init__(args</span><span class="s3">, </span><span class="s1">shape=shape)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">fromdense(cls</span><span class="s3">, </span><span class="s1">mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse=</span><span class="s3">None, </span><span class="s1">index_dtype=np.int32):</span>
    <span class="s3">if </span><span class="s1">nse </span><span class="s3">is None</span><span class="s1">:</span>
      <span class="s1">nse = (mat != </span><span class="s4">0</span><span class="s1">).sum()</span>
    <span class="s3">return </span><span class="s1">csr_fromdense(mat.T</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype).T</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">_empty(cls</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s3">None, </span><span class="s1">index_dtype=</span><span class="s5">'int32'</span><span class="s1">):</span>
    <span class="s2">&quot;&quot;&quot;Create an empty CSC instance. Public method is sparse.empty().&quot;&quot;&quot;</span>
    <span class="s1">shape = tuple(shape)</span>
    <span class="s3">if </span><span class="s1">len(shape) != </span><span class="s4">2</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;CSC must have ndim=2; got </span><span class="s3">{</span><span class="s1">shape=</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
    <span class="s1">data = jnp.empty(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">dtype)</span>
    <span class="s1">indices = jnp.empty(</span><span class="s4">0</span><span class="s3">, </span><span class="s1">index_dtype)</span>
    <span class="s1">indptr = jnp.zeros(shape[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">index_dtype)</span>
    <span class="s3">return </span><span class="s1">cls((data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">shape=shape)</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">_eye(cls</span><span class="s3">, </span><span class="s1">N</span><span class="s3">, </span><span class="s1">M</span><span class="s3">, </span><span class="s1">k</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">dtype=</span><span class="s3">None, </span><span class="s1">index_dtype=</span><span class="s5">'int32'</span><span class="s1">):</span>
    <span class="s3">return </span><span class="s1">CSR._eye(M</span><span class="s3">, </span><span class="s1">N</span><span class="s3">, </span><span class="s1">-k</span><span class="s3">, </span><span class="s1">dtype=dtype</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype).T</span>

  <span class="s3">def </span><span class="s1">todense(self):</span>
    <span class="s3">return </span><span class="s1">csr_todense(self.T).T</span>

  <span class="s3">def </span><span class="s1">transpose(self</span><span class="s3">, </span><span class="s1">axes=</span><span class="s3">None</span><span class="s1">):</span>
    <span class="s3">assert </span><span class="s1">axes </span><span class="s3">is None</span>
    <span class="s3">return </span><span class="s1">CSR((self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr)</span><span class="s3">, </span><span class="s1">shape=self.shape[::-</span><span class="s4">1</span><span class="s1">])</span>

  <span class="s3">def </span><span class="s1">__matmul__(self</span><span class="s3">, </span><span class="s1">other):</span>
    <span class="s3">if </span><span class="s1">isinstance(other</span><span class="s3">, </span><span class="s1">JAXSparse):</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">&quot;matmul between two sparse objects.&quot;</span><span class="s1">)</span>
    <span class="s1">other = jnp.asarray(other)</span>
    <span class="s1">data</span><span class="s3">, </span><span class="s1">other = promote_dtypes(self.data</span><span class="s3">, </span><span class="s1">other)</span>
    <span class="s3">if </span><span class="s1">other.ndim == </span><span class="s4">1</span><span class="s1">:</span>
      <span class="s3">return </span><span class="s1">_csr_matvec(data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr</span><span class="s3">, </span><span class="s1">other</span><span class="s3">,</span>
                         <span class="s1">shape=self.shape[::-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">elif </span><span class="s1">other.ndim == </span><span class="s4">2</span><span class="s1">:</span>
      <span class="s3">return </span><span class="s1">_csr_matmat(data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr</span><span class="s3">, </span><span class="s1">other</span><span class="s3">,</span>
                         <span class="s1">shape=self.shape[::-</span><span class="s4">1</span><span class="s1">]</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">True</span><span class="s1">)</span>
    <span class="s3">else</span><span class="s1">:</span>
      <span class="s3">raise </span><span class="s1">NotImplementedError(</span><span class="s5">f&quot;matmul with object of shape </span><span class="s3">{</span><span class="s1">other.shape</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>

  <span class="s3">def </span><span class="s1">tree_flatten(self):</span>
    <span class="s3">return </span><span class="s1">(self.data</span><span class="s3">, </span><span class="s1">self.indices</span><span class="s3">, </span><span class="s1">self.indptr)</span><span class="s3">, </span><span class="s1">{</span><span class="s5">&quot;shape&quot;</span><span class="s1">: self.shape}</span>

  <span class="s1">@classmethod</span>
  <span class="s3">def </span><span class="s1">tree_unflatten(cls</span><span class="s3">, </span><span class="s1">aux_data</span><span class="s3">, </span><span class="s1">children):</span>
    <span class="s1">obj = object.__new__(cls)</span>
    <span class="s1">obj.data</span><span class="s3">, </span><span class="s1">obj.indices</span><span class="s3">, </span><span class="s1">obj.indptr = children</span>
    <span class="s3">if </span><span class="s1">aux_data.keys() != {</span><span class="s5">'shape'</span><span class="s1">}:</span>
      <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">f&quot;CSC.tree_unflatten: invalid </span><span class="s3">{</span><span class="s1">aux_data=</span><span class="s3">}</span><span class="s5">&quot;</span><span class="s1">)</span>
    <span class="s1">obj.__dict__.update(**aux_data)</span>
    <span class="s3">return </span><span class="s1">obj</span>


<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># csr_todense</span>

<span class="s1">csr_todense_p = core.Primitive(</span><span class="s5">'csr_todense'</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">csr_todense(mat: CSR) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Convert a CSR-format sparse matrix to a dense matrix. 
 
  Args: 
    mat : CSR matrix 
  Returns: 
    mat_dense: dense version of ``mat`` 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">_csr_todense(mat.data</span><span class="s3">, </span><span class="s1">mat.indices</span><span class="s3">, </span><span class="s1">mat.indptr</span><span class="s3">, </span><span class="s1">shape=mat.shape)</span>

<span class="s3">def </span><span class="s1">_csr_todense(data: Array</span><span class="s3">, </span><span class="s1">indices: Array</span><span class="s3">, </span><span class="s1">indptr: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape: Shape) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Convert CSR-format sparse matrix to a dense matrix. 
 
  Args: 
    data : array of shape ``(nse,)``. 
    indices : array of shape ``(nse,)`` 
    indptr : array of shape ``(shape[0] + 1,)`` and dtype ``indices.dtype`` 
    shape : length-2 tuple representing the matrix shape 
 
  Returns: 
    mat : array with specified shape and dtype matching ``data`` 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">csr_todense_p.bind(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">shape=shape)</span>

<span class="s3">def </span><span class="s1">_csr_todense_impl(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape):</span>
  <span class="s3">return </span><span class="s1">_coo_todense(data</span><span class="s3">, </span><span class="s1">*_csr_to_coo(indices</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">spinfo=COOInfo(shape=shape))</span>

<span class="s1">@csr_todense_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_csr_todense_abstract_eval(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape):</span>
  <span class="s3">assert </span><span class="s1">data.ndim == indices.ndim == indptr.ndim == </span><span class="s4">1</span>
  <span class="s3">assert </span><span class="s1">indices.dtype == indptr.dtype</span>
  <span class="s3">assert </span><span class="s1">data.shape == indices.shape</span>
  <span class="s3">assert </span><span class="s1">indptr.shape[</span><span class="s4">0</span><span class="s1">] == shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span>
  <span class="s3">return </span><span class="s1">core.ShapedArray(shape</span><span class="s3">, </span><span class="s1">data.dtype)</span>

<span class="s1">_csr_todense_lowering = mlir.lower_fun(</span>
    <span class="s1">_csr_todense_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">False</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_csr_todense_gpu_lowering(csr_todense_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">*</span><span class="s3">,</span>
                              <span class="s1">shape):</span>
  <span class="s1">data_aval</span><span class="s3">, </span><span class="s1">indices_aval</span><span class="s3">, </span><span class="s1">_ = ctx.avals_in</span>
  <span class="s1">dtype = data_aval.dtype</span>
  <span class="s3">if not </span><span class="s1">(np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.floating) </span><span class="s3">or </span><span class="s1">np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.complexfloating)):</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;csr_todense cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_csr_todense_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">shape=shape)</span>
  <span class="s3">return </span><span class="s1">[csr_todense_hlo(</span>
      <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">data_dtype=dtype</span><span class="s3">,</span>
      <span class="s1">index_dtype=indices_aval.dtype)]</span>


<span class="s3">def </span><span class="s1">_csr_todense_jvp(data_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape):</span>
  <span class="s3">return </span><span class="s1">_csr_todense(data_dot</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">shape=shape)</span>

<span class="s3">def </span><span class="s1">_csr_todense_transpose(ct</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape):</span>
  <span class="s0"># Note: we assume that transpose has the same sparsity pattern.</span>
  <span class="s0"># Can we check this?</span>
  <span class="s3">assert </span><span class="s1">ad.is_undefined_primal(data)</span>
  <span class="s3">if </span><span class="s1">ad.is_undefined_primal(indices) </span><span class="s3">or </span><span class="s1">ad.is_undefined_primal(indptr):</span>
    <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Cannot transpose with respect to sparse indices&quot;</span><span class="s1">)</span>
  <span class="s3">assert </span><span class="s1">ct.shape == shape</span>
  <span class="s3">assert </span><span class="s1">indices.aval.dtype == indptr.aval.dtype</span>
  <span class="s3">assert </span><span class="s1">ct.dtype == data.aval.dtype</span>
  <span class="s3">return </span><span class="s1">_csr_extract(indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">ct)</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span>

<span class="s1">ad.defjvp(csr_todense_p</span><span class="s3">, </span><span class="s1">_csr_todense_jvp</span><span class="s3">, None, None</span><span class="s1">)</span>
<span class="s1">ad.primitive_transposes[csr_todense_p] = _csr_todense_transpose</span>
<span class="s1">mlir.register_lowering(csr_todense_p</span><span class="s3">, </span><span class="s1">_csr_todense_lowering)</span>
<span class="s1">dispatch.simple_impl(csr_todense_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">csr_todense_p</span><span class="s3">,</span>
      <span class="s1">partial(_csr_todense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_csr_todense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">csr_todense_p</span><span class="s3">,</span>
      <span class="s1">partial(_csr_todense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_csr_todense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>


<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># csr_fromdense</span>

<span class="s1">csr_fromdense_p = core.Primitive(</span><span class="s5">'csr_fromdense'</span><span class="s1">)</span>
<span class="s1">csr_fromdense_p.multiple_results = </span><span class="s3">True</span>

<span class="s3">def </span><span class="s1">csr_fromdense(mat: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse: Optional[int] = </span><span class="s3">None, </span><span class="s1">index_dtype: DTypeLike = np.int32) -&gt; CSR:</span>
  <span class="s2">&quot;&quot;&quot;Create a CSR-format sparse matrix from a dense matrix. 
 
  Args: 
    mat : array to be converted to CSR. 
    nse : number of specified entries in ``mat``. If not specified, 
      it will be computed from the input matrix. 
    index_dtype : dtype of sparse indices 
 
  Returns: 
    mat_coo : CSR representation of the matrix. 
  &quot;&quot;&quot;</span>
  <span class="s3">if </span><span class="s1">nse </span><span class="s3">is None</span><span class="s1">:</span>
    <span class="s1">nse = int((mat != </span><span class="s4">0</span><span class="s1">).sum())</span>
  <span class="s1">nse_int = core.concrete_or_error(operator.index</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s5">&quot;coo_fromdense nse argument&quot;</span><span class="s1">)</span>
  <span class="s3">return </span><span class="s1">CSR(_csr_fromdense(mat</span><span class="s3">, </span><span class="s1">nse=nse_int</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span><span class="s3">, </span><span class="s1">shape=mat.shape)</span>

<span class="s3">def </span><span class="s1">_csr_fromdense(mat: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse: int</span><span class="s3">, </span><span class="s1">index_dtype: DTypeLike = np.int32) -&gt; Tuple[Array</span><span class="s3">, </span><span class="s1">Array</span><span class="s3">, </span><span class="s1">Array]:</span>
  <span class="s2">&quot;&quot;&quot;Create CSR-format sparse matrix from a dense matrix. 
 
  Args: 
    mat : array to be converted to CSR. 
    nse : number of specified entries in ``mat`` 
    index_dtype : dtype of sparse indices 
 
  Returns: 
    data : array of shape ``(nse,)`` and dtype ``mat.dtype``. 
    indices : array of shape ``(nse,)`` and dtype ``index_dtype`` 
    indptr : array of shape ``(mat.shape[0] + 1,)`` and dtype ``index_dtype`` 
  &quot;&quot;&quot;</span>
  <span class="s1">mat = jnp.asarray(mat)</span>
  <span class="s1">nse = core.concrete_or_error(operator.index</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s5">&quot;nse argument of csr_fromdense()&quot;</span><span class="s1">)</span>
  <span class="s3">return </span><span class="s1">csr_fromdense_p.bind(mat</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=np.dtype(index_dtype))</span>

<span class="s3">def </span><span class="s1">_csr_fromdense_impl(mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">mat = jnp.asarray(mat)</span>
  <span class="s3">assert </span><span class="s1">mat.ndim == </span><span class="s4">2</span>
  <span class="s1">m = mat.shape[</span><span class="s4">0</span><span class="s1">]</span>

  <span class="s1">row</span><span class="s3">, </span><span class="s1">col = jnp.nonzero(mat</span><span class="s3">, </span><span class="s1">size=nse)</span>
  <span class="s1">data = mat[row</span><span class="s3">, </span><span class="s1">col]</span>

  <span class="s1">true_nonzeros = jnp.arange(nse) &lt; (mat != </span><span class="s4">0</span><span class="s1">).sum()</span>
  <span class="s1">data = jnp.where(true_nonzeros</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s4">0</span><span class="s1">)</span>
  <span class="s1">row = jnp.where(true_nonzeros</span><span class="s3">, </span><span class="s1">row</span><span class="s3">, </span><span class="s1">m)</span>
  <span class="s1">indices = col.astype(index_dtype)</span>
  <span class="s1">indptr = jnp.zeros(m + </span><span class="s4">1</span><span class="s3">, </span><span class="s1">dtype=index_dtype).at[</span><span class="s4">1</span><span class="s1">:].set(</span>
      <span class="s1">jnp.cumsum(jnp.bincount(row</span><span class="s3">, </span><span class="s1">length=m).astype(index_dtype)))</span>
  <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span>

<span class="s1">@csr_fromdense_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_csr_fromdense_abstract_eval(mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">data = core.ShapedArray((nse</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">mat.dtype)</span>
  <span class="s1">indices = core.ShapedArray((nse</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">index_dtype)</span>
  <span class="s1">indptr = core.ShapedArray((mat.shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">index_dtype)</span>
  <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span>

<span class="s1">_csr_fromdense_lowering = mlir.lower_fun(_csr_fromdense_impl</span><span class="s3">,</span>
                                         <span class="s1">multiple_results=</span><span class="s3">True</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_csr_fromdense_gpu_lowering(csr_fromdense_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">mat</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">dtype = ctx.avals_in[</span><span class="s4">0</span><span class="s1">].dtype</span>
  <span class="s3">if not </span><span class="s1">(np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.floating) </span><span class="s3">or </span><span class="s1">np.issubdtype(dtype</span><span class="s3">, </span><span class="s1">np.complexfloating)):</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;csr_fromdense cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_csr_fromdense_lowering(ctx</span><span class="s3">, </span><span class="s1">mat</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr = csr_fromdense_hlo(</span>
      <span class="s1">mat</span><span class="s3">, </span><span class="s1">nnz=nse</span><span class="s3">, </span><span class="s1">index_dtype=np.dtype(index_dtype)</span><span class="s3">,</span>
      <span class="s1">data_dtype=dtype</span><span class="s3">, </span><span class="s1">index_type=mlir.dtype_to_ir_type(np.dtype(index_dtype)))</span>
  <span class="s3">return </span><span class="s1">[data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr]</span>


<span class="s3">def </span><span class="s1">_csr_fromdense_jvp(primals</span><span class="s3">, </span><span class="s1">tangents</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">M</span><span class="s3">, </span><span class="s1">= primals</span>
  <span class="s1">Mdot</span><span class="s3">, </span><span class="s1">= tangents</span>

  <span class="s1">primals_out = _csr_fromdense(M</span><span class="s3">, </span><span class="s1">nse=nse</span><span class="s3">, </span><span class="s1">index_dtype=index_dtype)</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr = primals_out</span>

  <span class="s3">if </span><span class="s1">type(Mdot) </span><span class="s3">is </span><span class="s1">ad.Zero:</span>
    <span class="s1">data_dot = ad.Zero.from_value(data)</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">data_dot = _csr_extract(indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">Mdot)</span>

  <span class="s1">tangents_out = (data_dot</span><span class="s3">, </span><span class="s1">ad.Zero.from_value(indices)</span><span class="s3">, </span><span class="s1">ad.Zero.from_value(indptr))</span>

  <span class="s3">return </span><span class="s1">primals_out</span><span class="s3">, </span><span class="s1">tangents_out</span>

<span class="s3">def </span><span class="s1">_csr_fromdense_transpose(ct</span><span class="s3">, </span><span class="s1">M</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">nse</span><span class="s3">, </span><span class="s1">index_dtype):</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr = ct</span>
  <span class="s3">assert </span><span class="s1">len(data) == nse</span>
  <span class="s3">assert </span><span class="s1">indices.dtype == indptr.dtype == index_dtype</span>
  <span class="s3">if </span><span class="s1">isinstance(indices</span><span class="s3">, </span><span class="s1">ad.Zero) </span><span class="s3">or </span><span class="s1">isinstance(indptr</span><span class="s3">, </span><span class="s1">ad.Zero):</span>
    <span class="s3">raise </span><span class="s1">ValueError(</span><span class="s5">&quot;Cannot transpose with respect to sparse indices&quot;</span><span class="s1">)</span>
  <span class="s3">assert </span><span class="s1">ad.is_undefined_primal(M)</span>
  <span class="s3">return </span><span class="s1">_csr_todense(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">shape=M.aval.shape)</span>

<span class="s1">ad.primitive_jvps[csr_fromdense_p] = _csr_fromdense_jvp</span>
<span class="s1">ad.primitive_transposes[csr_fromdense_p] = _csr_fromdense_transpose</span>
<span class="s1">mlir.register_lowering(csr_fromdense_p</span><span class="s3">, </span><span class="s1">_csr_fromdense_lowering)</span>
<span class="s1">dispatch.simple_impl(csr_fromdense_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">csr_fromdense_p</span><span class="s3">,</span>
      <span class="s1">partial(_csr_fromdense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_csr_fromdense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">csr_fromdense_p</span><span class="s3">,</span>
      <span class="s1">partial(_csr_fromdense_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_csr_fromdense)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>

<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># csr_matvec</span>

<span class="s1">csr_matvec_p = core.Primitive(</span><span class="s5">'csr_matvec'</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">csr_matvec(mat: CSR</span><span class="s3">, </span><span class="s1">v: Array</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of CSR sparse matrix and a dense vector. 
 
  Args: 
    mat : CSR matrix 
    v : one-dimensional array of size ``(shape[0] if transpose else shape[1],)`` and 
      dtype ``mat.dtype`` 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    y : array of shape ``(mat.shape[1] if transpose else mat.shape[0],)`` representing 
      the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr = mat._bufs</span>
  <span class="s3">return </span><span class="s1">_csr_matvec(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">shape=mat.shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matvec(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">False</span><span class="s1">):</span>
  <span class="s2">&quot;&quot;&quot;Product of CSR sparse matrix and a dense vector. 
 
  Args: 
    data : array of shape ``(nse,)``. 
    indices : array of shape ``(nse,)`` 
    indptr : array of shape ``(shape[0] + 1,)`` and dtype ``indices.dtype`` 
    v : array of shape ``(shape[0] if transpose else shape[1],)`` 
      and dtype ``data.dtype`` 
    shape : length-2 tuple representing the matrix shape 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    y : array of shape ``(shape[1] if transpose else shape[0],)`` representing 
      the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">csr_matvec_p.bind(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matvec_impl(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_coo_matvec(data</span><span class="s3">, </span><span class="s1">*_csr_to_coo(indices</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">spinfo=COOInfo(shape=shape)</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s1">@csr_matvec_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_csr_matvec_abstract_eval(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert </span><span class="s1">len(shape) == </span><span class="s4">2</span>
  <span class="s3">assert </span><span class="s1">v.ndim == data.ndim == indices.ndim == indptr.ndim == </span><span class="s4">1</span>
  <span class="s3">assert </span><span class="s1">data.shape == indices.shape</span>
  <span class="s3">assert </span><span class="s1">data.dtype == v.dtype</span>
  <span class="s3">assert </span><span class="s1">indices.dtype == indptr.dtype</span>
  <span class="s3">assert </span><span class="s1">indptr.shape[</span><span class="s4">0</span><span class="s1">] == shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span>
  <span class="s1">out_shape = shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">shape[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s3">assert </span><span class="s1">v.shape[</span><span class="s4">0</span><span class="s1">] == (shape[</span><span class="s4">0</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">shape[</span><span class="s4">1</span><span class="s1">])</span>
  <span class="s3">return </span><span class="s1">core.ShapedArray((out_shape</span><span class="s3">,</span><span class="s1">)</span><span class="s3">, </span><span class="s1">data.dtype)</span>

<span class="s1">_csr_matvec_lowering = mlir.lower_fun(_csr_matvec_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">False</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_csr_matvec_gpu_lowering(csr_matvec_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">,</span>
                             <span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s1">data_aval</span><span class="s3">, </span><span class="s1">indices_aval</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">v_aval = ctx.avals_in</span>
  <span class="s1">dtype = data_aval.dtype</span>
  <span class="s3">if </span><span class="s1">dtype </span><span class="s3">not in </span><span class="s1">[np.float32</span><span class="s3">, </span><span class="s1">np.float64</span><span class="s3">, </span><span class="s1">np.complex64</span><span class="s3">, </span><span class="s1">np.complex128]:</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;csr_matvec cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_csr_matvec_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">,</span>
                                <span class="s1">transpose=transpose)</span>
  <span class="s3">return </span><span class="s1">[csr_matvec_hlo(</span>
      <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose</span><span class="s3">,</span>
      <span class="s1">data_dtype=dtype</span><span class="s3">, </span><span class="s1">index_dtype=indices_aval.dtype</span><span class="s3">, </span><span class="s1">x_dtype=v_aval.dtype)]</span>


<span class="s3">def </span><span class="s1">_csr_matvec_jvp_mat(data_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_csr_matvec(data_dot</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matvec_jvp_vec(v_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_csr_matvec(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v_dot</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matvec_transpose(ct</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(indices)</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(indptr)</span>

  <span class="s3">if </span><span class="s1">ad.is_undefined_primal(v):</span>
    <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">_csr_matvec(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">ct</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">not </span><span class="s1">transpose)</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">v = jnp.asarray(v)</span>
    <span class="s0"># The following lines do this, but more efficiently.</span>
    <span class="s0"># return _csr_extract(indices, indptr, jnp.outer(ct, v)), indices, indptr, v</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = _csr_to_coo(indices</span><span class="s3">, </span><span class="s1">indptr)</span>
    <span class="s3">return </span><span class="s1">ct[row] * v[col]</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">v</span>

<span class="s1">ad.defjvp(csr_matvec_p</span><span class="s3">, </span><span class="s1">_csr_matvec_jvp_mat</span><span class="s3">, None, None, </span><span class="s1">_csr_matvec_jvp_vec)</span>
<span class="s1">ad.primitive_transposes[csr_matvec_p] = _csr_matvec_transpose</span>
<span class="s1">mlir.register_lowering(csr_matvec_p</span><span class="s3">, </span><span class="s1">_csr_matvec_lowering)</span>
<span class="s1">dispatch.simple_impl(csr_matvec_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">csr_matvec_p</span><span class="s3">,</span>
      <span class="s1">partial(_csr_matvec_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_csr_matvec)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
<span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
  <span class="s1">mlir.register_lowering(</span>
      <span class="s1">csr_matvec_p</span><span class="s3">,</span>
      <span class="s1">partial(_csr_matvec_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_csr_matvec)</span><span class="s3">,</span>
      <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>


<span class="s0">#--------------------------------------------------------------------</span>
<span class="s0"># csr_matmat</span>

<span class="s1">csr_matmat_p = core.Primitive(</span><span class="s5">'csr_matmat'</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">csr_matmat(mat: CSR</span><span class="s3">, </span><span class="s1">B: Array</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of CSR sparse matrix and a dense matrix. 
 
  Args: 
    mat : CSR matrix 
    B : array of shape ``(mat.shape[0] if transpose else mat.shape[1], cols)`` and 
      dtype ``mat.dtype`` 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    C : array of shape ``(mat.shape[1] if transpose else mat.shape[0], cols)`` 
      representing the matrix vector product. 
  &quot;&quot;&quot;</span>
  <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr = mat._bufs</span>
  <span class="s3">return </span><span class="s1">_csr_matmat(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">shape=mat.shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matmat(data: Array</span><span class="s3">, </span><span class="s1">indices: Array</span><span class="s3">, </span><span class="s1">indptr: Array</span><span class="s3">, </span><span class="s1">B: Array</span><span class="s3">,</span>
                <span class="s1">*</span><span class="s3">, </span><span class="s1">shape: Shape</span><span class="s3">, </span><span class="s1">transpose: bool = </span><span class="s3">False</span><span class="s1">) -&gt; Array:</span>
  <span class="s2">&quot;&quot;&quot;Product of CSR sparse matrix and a dense matrix. 
 
  Args: 
    data : array of shape ``(nse,)``. 
    indices : array of shape ``(nse,)`` 
    indptr : array of shape ``(shape[0] + 1,)`` and dtype ``indices.dtype`` 
    B : array of shape ``(shape[0] if transpose else shape[1], cols)`` and 
      dtype ``data.dtype`` 
    shape : length-2 tuple representing the matrix shape 
    transpose : boolean specifying whether to transpose the sparse matrix 
      before computing. 
 
  Returns: 
    C : array of shape ``(shape[1] if transpose else shape[0], cols)`` 
      representing the matrix-matrix product product. 
  &quot;&quot;&quot;</span>
  <span class="s3">return </span><span class="s1">csr_matmat_p.bind(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matmat_impl(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_coo_matmat(data</span><span class="s3">, </span><span class="s1">*_csr_to_coo(indices</span><span class="s3">, </span><span class="s1">indptr)</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">spinfo=COOInfo(shape=shape)</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s1">@csr_matmat_p.def_abstract_eval</span>
<span class="s3">def </span><span class="s1">_csr_matmat_abstract_eval(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert </span><span class="s1">len(shape) == </span><span class="s4">2</span>
  <span class="s3">assert </span><span class="s1">data.ndim == indices.ndim == indptr.ndim == </span><span class="s4">1</span>
  <span class="s3">assert </span><span class="s1">B.ndim == </span><span class="s4">2</span>
  <span class="s3">assert </span><span class="s1">data.shape == indices.shape</span>
  <span class="s3">assert </span><span class="s1">data.dtype == B.dtype</span>
  <span class="s3">assert </span><span class="s1">indices.dtype == indptr.dtype</span>
  <span class="s3">assert </span><span class="s1">indptr.shape[</span><span class="s4">0</span><span class="s1">] == shape[</span><span class="s4">0</span><span class="s1">] + </span><span class="s4">1</span>
  <span class="s1">out_shape = shape[</span><span class="s4">1</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">shape[</span><span class="s4">0</span><span class="s1">]</span>
  <span class="s3">assert </span><span class="s1">B.shape[</span><span class="s4">0</span><span class="s1">] == (shape[</span><span class="s4">0</span><span class="s1">] </span><span class="s3">if </span><span class="s1">transpose </span><span class="s3">else </span><span class="s1">shape[</span><span class="s4">1</span><span class="s1">])</span>
  <span class="s3">return </span><span class="s1">core.ShapedArray((out_shape</span><span class="s3">, </span><span class="s1">B.shape[</span><span class="s4">1</span><span class="s1">])</span><span class="s3">, </span><span class="s1">data.dtype)</span>

<span class="s1">_csr_matmat_lowering = mlir.lower_fun(_csr_matmat_impl</span><span class="s3">, </span><span class="s1">multiple_results=</span><span class="s3">False</span><span class="s1">)</span>

<span class="s3">def </span><span class="s1">_csr_matmat_gpu_lowering(csr_matmat_hlo</span><span class="s3">, </span><span class="s1">ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">,</span>
                             <span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s1">data_aval</span><span class="s3">, </span><span class="s1">indices_aval</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">B_aval = ctx.avals_in</span>
  <span class="s1">dtype = data_aval.dtype</span>
  <span class="s3">if </span><span class="s1">dtype </span><span class="s3">not in </span><span class="s1">[np.float32</span><span class="s3">, </span><span class="s1">np.float64</span><span class="s3">, </span><span class="s1">np.complex64</span><span class="s3">, </span><span class="s1">np.complex128]:</span>
    <span class="s1">warnings.warn(</span><span class="s5">f&quot;csr_matmat cusparse/hipsparse lowering not available for </span><span class="s3">{</span><span class="s1">dtype=</span><span class="s3">}</span><span class="s5">. &quot;</span>
                  <span class="s5">&quot;Falling back to default implementation.&quot;</span><span class="s3">, </span><span class="s1">CuSparseEfficiencyWarning)</span>
    <span class="s3">return </span><span class="s1">_csr_matmat_lowering(ctx</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">,</span>
                                <span class="s1">transpose=transpose)</span>
  <span class="s3">return </span><span class="s1">[csr_matmat_hlo(</span>
      <span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose</span><span class="s3">,</span>
      <span class="s1">index_dtype=indices_aval.dtype</span><span class="s3">, </span><span class="s1">data_dtype=data_aval.dtype</span><span class="s3">,</span>
      <span class="s1">B_dtype=B_aval.dtype)]</span>


<span class="s3">def </span><span class="s1">_csr_matmat_jvp_left(data_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_csr_matmat(data_dot</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matmat_jvp_right(B_dot</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">return </span><span class="s1">_csr_matmat(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B_dot</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=transpose)</span>

<span class="s3">def </span><span class="s1">_csr_matmat_transpose(ct</span><span class="s3">, </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span><span class="s3">, </span><span class="s1">*</span><span class="s3">, </span><span class="s1">shape</span><span class="s3">, </span><span class="s1">transpose):</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(indices)</span>
  <span class="s3">assert not </span><span class="s1">ad.is_undefined_primal(indptr)</span>

  <span class="s3">if </span><span class="s1">ad.is_undefined_primal(B):</span>
    <span class="s3">return </span><span class="s1">data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">_csr_matmat(data</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">ct</span><span class="s3">, </span><span class="s1">shape=shape</span><span class="s3">, </span><span class="s1">transpose=</span><span class="s3">not </span><span class="s1">transpose)</span>
  <span class="s3">else</span><span class="s1">:</span>
    <span class="s1">B = jnp.asarray(B)</span>
    <span class="s1">row</span><span class="s3">, </span><span class="s1">col = _csr_to_coo(indices</span><span class="s3">, </span><span class="s1">indptr)</span>
    <span class="s3">return </span><span class="s1">(ct[row] * B[col]).sum(</span><span class="s4">1</span><span class="s1">)</span><span class="s3">, </span><span class="s1">indices</span><span class="s3">, </span><span class="s1">indptr</span><span class="s3">, </span><span class="s1">B</span>

<span class="s1">ad.defjvp(csr_matmat_p</span><span class="s3">, </span><span class="s1">_csr_matmat_jvp_left</span><span class="s3">, None, None, </span><span class="s1">_csr_matmat_jvp_right)</span>
<span class="s1">ad.primitive_transposes[csr_matmat_p] = _csr_matmat_transpose</span>
<span class="s1">mlir.register_lowering(csr_matmat_p</span><span class="s3">, </span><span class="s1">_csr_matmat_lowering)</span>
<span class="s1">dispatch.simple_impl(csr_matmat_p)</span>

<span class="s3">if </span><span class="s1">gpu_sparse:</span>
  <span class="s3">if </span><span class="s1">gpu_sparse.cuda_is_supported:</span>
    <span class="s1">mlir.register_lowering(</span>
        <span class="s1">csr_matmat_p</span><span class="s3">,</span>
        <span class="s1">partial(_csr_matmat_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.cuda_csr_matmat)</span><span class="s3">,</span>
        <span class="s1">platform=</span><span class="s5">'cuda'</span><span class="s1">)</span>
  <span class="s3">if </span><span class="s1">gpu_sparse.rocm_is_supported:</span>
    <span class="s1">mlir.register_lowering(</span>
        <span class="s1">csr_matmat_p</span><span class="s3">,</span>
        <span class="s1">partial(_csr_matmat_gpu_lowering</span><span class="s3">, </span><span class="s1">gpu_sparse.rocm_csr_matmat)</span><span class="s3">,</span>
        <span class="s1">platform=</span><span class="s5">'rocm'</span><span class="s1">)</span>
</pre>
</body>
</html>