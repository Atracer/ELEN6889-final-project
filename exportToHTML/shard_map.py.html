<html>
<head>
<title>shard_map.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
shard_map.py</font>
</center></td></tr></table>
<pre><span class="s0"># Copyright 2023 The JAX Authors.</span>
<span class="s0">#</span>
<span class="s0"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="s0"># you may not use this file except in compliance with the License.</span>
<span class="s0"># You may obtain a copy of the License at</span>
<span class="s0">#</span>
<span class="s0">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="s0">#</span>
<span class="s0"># Unless required by applicable law or agreed to in writing, software</span>
<span class="s0"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="s0"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="s0"># See the License for the specific language governing permissions and</span>
<span class="s0"># limitations under the License.</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">import </span><span class="s1">enum</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span><span class="s2">, </span><span class="s1">lru_cache</span>
<span class="s2">import </span><span class="s1">inspect</span>
<span class="s2">import </span><span class="s1">itertools </span><span class="s2">as </span><span class="s1">it</span>
<span class="s2">import </span><span class="s1">math</span>
<span class="s2">import </span><span class="s1">operator </span><span class="s2">as </span><span class="s1">op</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(Any</span><span class="s2">, </span><span class="s1">Callable</span><span class="s2">, </span><span class="s1">Dict</span><span class="s2">, </span><span class="s1">Hashable</span><span class="s2">, </span><span class="s1">List</span><span class="s2">, </span><span class="s1">Optional</span><span class="s2">, </span><span class="s1">Sequence</span><span class="s2">,</span>
                    <span class="s1">Set</span><span class="s2">, </span><span class="s1">Tuple</span><span class="s2">, </span><span class="s1">TypeVar</span><span class="s2">, </span><span class="s1">Union</span><span class="s2">, </span><span class="s1">Protocol)</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">import </span><span class="s1">jax</span>
<span class="s2">from </span><span class="s1">jax.sharding </span><span class="s2">import </span><span class="s1">NamedSharding</span><span class="s2">, </span><span class="s1">PartitionSpec</span><span class="s2">, </span><span class="s1">Mesh</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">core</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">ad_util</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">custom_derivatives</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">debugging</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">linear_util </span><span class="s2">as </span><span class="s1">lu</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">ops</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">pjit</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">source_info_util</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">traceback_util</span>
<span class="s2">from </span><span class="s1">jax._src </span><span class="s2">import </span><span class="s1">util</span>
<span class="s2">from </span><span class="s1">jax._src.core </span><span class="s2">import </span><span class="s1">Tracer</span>
<span class="s2">from </span><span class="s1">jax._src.lax </span><span class="s2">import </span><span class="s1">(lax</span><span class="s2">, </span><span class="s1">parallel </span><span class="s2">as </span><span class="s1">lax_parallel</span><span class="s2">, </span><span class="s1">slicing</span><span class="s2">,</span>
                          <span class="s1">windowed_reductions</span><span class="s2">, </span><span class="s1">fft</span><span class="s2">, </span><span class="s1">linalg)</span>
<span class="s2">from </span><span class="s1">jax._src.util </span><span class="s2">import </span><span class="s1">(HashableFunction</span><span class="s2">, </span><span class="s1">HashablePartial</span><span class="s2">, </span><span class="s1">unzip2</span><span class="s2">,</span>
                           <span class="s1">as_hashable_function</span><span class="s2">, </span><span class="s1">memoize</span><span class="s2">, </span><span class="s1">partition_list</span><span class="s2">,</span>
                           <span class="s1">merge_lists)</span>
<span class="s2">from </span><span class="s1">jax.api_util </span><span class="s2">import </span><span class="s1">flatten_fun_nokwargs</span><span class="s2">, </span><span class="s1">shaped_abstractify</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">batching</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">mlir</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">partial_eval </span><span class="s2">as </span><span class="s1">pe</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">xla</span>
<span class="s2">from </span><span class="s1">jax._src.interpreters </span><span class="s2">import </span><span class="s1">pxla</span>
<span class="s2">from </span><span class="s1">jax.interpreters </span><span class="s2">import </span><span class="s1">ad</span>
<span class="s2">from </span><span class="s1">jax.tree_util </span><span class="s2">import </span><span class="s1">(tree_map</span><span class="s2">, </span><span class="s1">tree_flatten</span><span class="s2">, </span><span class="s1">tree_unflatten</span><span class="s2">,</span>
                           <span class="s1">tree_structure</span><span class="s2">, </span><span class="s1">tree_leaves</span><span class="s2">, </span><span class="s1">keystr)</span>
<span class="s2">from </span><span class="s1">jax._src.tree_util </span><span class="s2">import </span><span class="s1">(broadcast_prefix</span><span class="s2">, </span><span class="s1">prefix_errors</span><span class="s2">, </span><span class="s1">PyTreeDef</span><span class="s2">,</span>
                                <span class="s1">generate_key_paths</span><span class="s2">, </span><span class="s1">KeyPath)</span>

<span class="s1">P = PartitionSpec</span>

<span class="s1">map</span><span class="s2">, </span><span class="s1">unsafe_map = util.safe_map</span><span class="s2">, </span><span class="s1">map</span>
<span class="s1">zip</span><span class="s2">, </span><span class="s1">unsafe_zip = util.safe_zip</span><span class="s2">, </span><span class="s1">zip</span>
<span class="s1">traceback_util.register_exclusion(__file__)</span>

<span class="s0"># API</span>

<span class="s1">Specs = Any  </span><span class="s0"># PyTree[PartitionSpec]</span>

<span class="s1">@traceback_util.api_boundary</span>
<span class="s2">def </span><span class="s1">shard_map(f: Callable</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">, </span><span class="s1">in_specs: Specs</span><span class="s2">, </span><span class="s1">out_specs: Specs</span><span class="s2">,</span>
              <span class="s1">check_rep: bool = </span><span class="s2">True</span><span class="s1">):</span>
  <span class="s2">if not </span><span class="s1">callable(f):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s3">&quot;shard_map requires a callable for its first argument, &quot;</span>
                    <span class="s3">f&quot;but got </span><span class="s2">{</span><span class="s1">f</span><span class="s2">} </span><span class="s3">of type </span><span class="s2">{</span><span class="s1">type(f)</span><span class="s2">}</span><span class="s3">.&quot;</span><span class="s1">)</span>
  <span class="s2">if not </span><span class="s1">isinstance(mesh</span><span class="s2">, </span><span class="s1">Mesh):</span>
    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s3">&quot;shard_map requires a `jax.sharding.Mesh` instance for its &quot;</span>
                    <span class="s3">f&quot;second argument, but got </span><span class="s2">{</span><span class="s1">mesh</span><span class="s2">} </span><span class="s3">of type </span><span class="s2">{</span><span class="s1">type(mesh)</span><span class="s2">}</span><span class="s3">.&quot;</span><span class="s1">)</span>
  <span class="s1">_check_specs(SpecErrorType.input</span><span class="s2">, </span><span class="s1">in_specs)</span>
  <span class="s1">_check_specs(SpecErrorType.out</span><span class="s2">, </span><span class="s1">out_specs)</span>

  <span class="s1">@traceback_util.api_boundary</span>
  <span class="s2">def </span><span class="s1">wrapped(*args):</span>
    <span class="s1">fun = lu.wrap_init(f)</span>
    <span class="s1">args_flat</span><span class="s2">, </span><span class="s1">in_tree = tree_flatten(args)</span>
    <span class="s2">try</span><span class="s1">: in_specs_flat = broadcast_prefix(in_specs</span><span class="s2">, </span><span class="s1">args)</span>
    <span class="s2">except </span><span class="s1">ValueError:</span>
      <span class="s1">e</span><span class="s2">, </span><span class="s1">*_ = prefix_errors(in_specs</span><span class="s2">, </span><span class="s1">args)</span>
      <span class="s2">raise </span><span class="s1">e(</span><span class="s3">'shard_map in_specs'</span><span class="s1">) </span><span class="s2">from None</span>
    <span class="s1">_check_specs_vs_args(f</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_tree</span><span class="s2">, </span><span class="s1">in_specs</span><span class="s2">, </span><span class="s1">in_specs_flat</span><span class="s2">, </span><span class="s1">args_flat)</span>
    <span class="s1">in_names_flat = tuple(map(_canonicalize_spec</span><span class="s2">, </span><span class="s1">in_specs_flat))</span>
    <span class="s1">flat_fun</span><span class="s2">, </span><span class="s1">out_tree = flatten_fun_nokwargs(fun</span><span class="s2">, </span><span class="s1">in_tree)</span>

    <span class="s1">@memoize</span>
    <span class="s2">def </span><span class="s1">out_names_thunk():</span>
      <span class="s1">dummy = tree_unflatten(out_tree()</span><span class="s2">, </span><span class="s1">[object()] * out_tree().num_leaves)</span>
      <span class="s2">try</span><span class="s1">: out_specs_flat = broadcast_prefix(out_specs</span><span class="s2">, </span><span class="s1">dummy)</span>
      <span class="s2">except </span><span class="s1">ValueError:</span>
        <span class="s1">e</span><span class="s2">, </span><span class="s1">*_ = prefix_errors(out_specs</span><span class="s2">, </span><span class="s1">dummy)</span>
        <span class="s2">raise </span><span class="s1">e(</span><span class="s3">'shard_map out_specs'</span><span class="s1">) </span><span class="s2">from None</span>
      <span class="s2">return </span><span class="s1">tuple(map(_canonicalize_spec</span><span class="s2">, </span><span class="s1">out_specs_flat))</span>
    <span class="s2">try</span><span class="s1">:</span>
      <span class="s1">out_flat = shard_map_p.bind(</span>
          <span class="s1">flat_fun</span><span class="s2">, </span><span class="s1">*args_flat</span><span class="s2">, </span><span class="s1">mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=in_names_flat</span><span class="s2">,</span>
          <span class="s1">out_names_thunk=out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
    <span class="s2">except </span><span class="s1">_SpecError </span><span class="s2">as </span><span class="s1">e:</span>
      <span class="s1">fails</span><span class="s2">, </span><span class="s1">= e.args</span>
      <span class="s1">msg = _spec_rank_error(SpecErrorType.out</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">out_tree()</span><span class="s2">, </span><span class="s1">out_specs</span><span class="s2">, </span><span class="s1">fails)</span>
      <span class="s2">if </span><span class="s1">any(fail </span><span class="s2">is not </span><span class="s1">no_fail </span><span class="s2">and not </span><span class="s1">fail.shape </span><span class="s2">for </span><span class="s1">fail </span><span class="s2">in </span><span class="s1">fails):</span>
        <span class="s1">msg += (</span><span class="s3">&quot; In particular, for rank 0 outputs which are not constant &quot;</span>
                <span class="s3">&quot;over the mesh, add at least one (singleton) axis to them so &quot;</span>
                <span class="s3">&quot;that they can be concatenated using out_specs.&quot;</span><span class="s1">)</span>
      <span class="s2">raise </span><span class="s1">ValueError(msg) </span><span class="s2">from None</span>
    <span class="s2">except </span><span class="s1">_RepError </span><span class="s2">as </span><span class="s1">e:</span>
      <span class="s1">fails</span><span class="s2">, </span><span class="s1">= e.args</span>
      <span class="s1">msg = _rep_error(f</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">out_tree()</span><span class="s2">, </span><span class="s1">out_specs</span><span class="s2">, </span><span class="s1">fails)</span>
      <span class="s2">raise </span><span class="s1">ValueError(msg) </span><span class="s2">from None</span>
    <span class="s2">return </span><span class="s1">tree_unflatten(out_tree()</span><span class="s2">, </span><span class="s1">out_flat)</span>
  <span class="s2">return </span><span class="s1">wrapped</span>

<span class="s0"># Internally use AxisNames = Dict[int, Tuple[AxisName, ...]], not PartitionSpecs</span>
<span class="s1">AxisName = Hashable</span>
<span class="s1">AxisNames = Dict[int</span><span class="s2">, </span><span class="s1">Tuple[AxisName</span><span class="s2">, </span><span class="s1">...]]  </span><span class="s0"># TODO(mattjj): make it hashable</span>
<span class="s2">def </span><span class="s1">_canonicalize_spec(spec: PartitionSpec) -&gt; AxisNames:</span>
  <span class="s2">if </span><span class="s1">isinstance(spec</span><span class="s2">, </span><span class="s1">PartitionSpec):</span>
    <span class="s2">return </span><span class="s1">{i: names </span><span class="s2">if </span><span class="s1">isinstance(names</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">else </span><span class="s1">(names</span><span class="s2">,</span><span class="s1">)</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">names </span><span class="s2">in </span><span class="s1">enumerate(spec) </span><span class="s2">if </span><span class="s1">names </span><span class="s2">is not None</span><span class="s1">}</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">spec</span>

<span class="s0"># Error checking and messages</span>

<span class="s1">SpecErrorType = enum.Enum(</span><span class="s3">'SpecErrorType'</span><span class="s2">, </span><span class="s1">[</span><span class="s3">'input'</span><span class="s2">, </span><span class="s3">'out'</span><span class="s1">])</span>

<span class="s2">def </span><span class="s1">_check_specs(error_type: SpecErrorType</span><span class="s2">, </span><span class="s1">specs: Any) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
  <span class="s2">if </span><span class="s1">all(isinstance(p</span><span class="s2">, </span><span class="s1">PartitionSpec) </span><span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">tree_leaves(specs)): </span><span class="s2">return</span>
  <span class="s1">prefix = </span><span class="s3">'in' </span><span class="s2">if </span><span class="s1">error_type == SpecErrorType.input </span><span class="s2">else </span><span class="s3">'out'</span>
  <span class="s1">msgs = [</span><span class="s3">f&quot;  </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">_specs</span><span class="s2">{</span><span class="s1">keystr(key)</span><span class="s2">} </span><span class="s3">is </span><span class="s2">{</span><span class="s1">x</span><span class="s2">} </span><span class="s3">of type </span><span class="s2">{</span><span class="s1">type(x).__name__</span><span class="s2">}</span><span class="s3">, &quot;</span>
          <span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">generate_key_paths(specs) </span><span class="s2">if not </span><span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">P)]</span>
  <span class="s2">raise </span><span class="s1">TypeError(</span>
      <span class="s3">f&quot;shard_map </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">_specs argument must be a pytree of &quot;</span>
      <span class="s3">f&quot;`jax.sharding.PartitionSpec` instances, but:</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
      <span class="s1">+ </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">'</span><span class="s1">.join(msgs) + </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">'</span>
      <span class="s3">f&quot;Check the </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">_specs values passed to shard_map.&quot;</span><span class="s1">)</span>

<span class="s2">class </span><span class="s1">NoFail: </span><span class="s2">pass</span>
<span class="s1">no_fail = NoFail()</span>

<span class="s2">def </span><span class="s1">_check_specs_vs_args(</span>
    <span class="s1">f: Callable</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">, </span><span class="s1">in_tree: PyTreeDef</span><span class="s2">, </span><span class="s1">in_specs: Specs</span><span class="s2">,</span>
    <span class="s1">in_specs_flat: List[P]</span><span class="s2">, </span><span class="s1">xs: List) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
  <span class="s1">in_avals = map(shaped_abstractify</span><span class="s2">, </span><span class="s1">xs)</span>
  <span class="s1">fail = [a </span><span class="s2">if not </span><span class="s1">len(p) &lt;= a.ndim </span><span class="s2">else </span><span class="s1">no_fail</span>
          <span class="s2">for </span><span class="s1">p</span><span class="s2">, </span><span class="s1">a </span><span class="s2">in </span><span class="s1">zip(in_specs_flat</span><span class="s2">, </span><span class="s1">in_avals)]</span>
  <span class="s2">if </span><span class="s1">any(f </span><span class="s2">is not </span><span class="s1">no_fail </span><span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">fail):</span>
    <span class="s1">msg = _spec_rank_error(SpecErrorType.input</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">in_tree</span><span class="s2">, </span><span class="s1">in_specs</span><span class="s2">, </span><span class="s1">fail)</span>
    <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
  <span class="s1">in_names_flat = tuple(map(_canonicalize_spec</span><span class="s2">, </span><span class="s1">in_specs_flat))</span>
  <span class="s1">fail = [a </span><span class="s2">if </span><span class="s1">any(a.shape[d] % math.prod(mesh.shape[n] </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">ns)</span>
                   <span class="s2">for </span><span class="s1">d</span><span class="s2">, </span><span class="s1">ns </span><span class="s2">in </span><span class="s1">names.items()) </span><span class="s2">else </span><span class="s1">no_fail</span>
          <span class="s2">for </span><span class="s1">a</span><span class="s2">, </span><span class="s1">names </span><span class="s2">in </span><span class="s1">zip(in_avals</span><span class="s2">, </span><span class="s1">in_names_flat)]</span>
  <span class="s2">if </span><span class="s1">any(f </span><span class="s2">is not </span><span class="s1">no_fail </span><span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">fail):</span>
    <span class="s1">msg = _spec_divisibility_error(f</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_tree</span><span class="s2">, </span><span class="s1">in_specs</span><span class="s2">, </span><span class="s1">fail)</span>
    <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

<span class="s2">def </span><span class="s1">_spec_rank_error(</span>
    <span class="s1">error_type: SpecErrorType</span><span class="s2">, </span><span class="s1">f: Callable</span><span class="s2">, </span><span class="s1">tree: PyTreeDef</span><span class="s2">, </span><span class="s1">specs: Specs</span><span class="s2">,</span>
    <span class="s1">fails: List[Union[core.ShapedArray</span><span class="s2">, </span><span class="s1">NoFail]]) -&gt; str:</span>
  <span class="s2">if </span><span class="s1">error_type == SpecErrorType.input:</span>
    <span class="s1">prefix</span><span class="s2">, </span><span class="s1">base = </span><span class="s3">'in'</span><span class="s2">, </span><span class="s3">'args'</span>
    <span class="s1">ba = _try_infer_args(f</span><span class="s2">, </span><span class="s1">tree)</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s1">prefix</span><span class="s2">, </span><span class="s1">base = </span><span class="s3">'out'</span><span class="s2">, </span><span class="s3">f'</span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">(*args)'</span>
  <span class="s1">msgs = []</span>
  <span class="s2">for </span><span class="s1">(spec_key</span><span class="s2">, </span><span class="s1">spec)</span><span class="s2">, </span><span class="s1">(fail_key</span><span class="s2">, </span><span class="s1">aval) </span><span class="s2">in </span><span class="s1">_iter_paths(tree</span><span class="s2">, </span><span class="s1">specs</span><span class="s2">, </span><span class="s1">fails):</span>
    <span class="s2">if </span><span class="s1">error_type == SpecErrorType.input </span><span class="s2">and </span><span class="s1">ba </span><span class="s2">is not None</span><span class="s1">:</span>
      <span class="s1">arg_key</span><span class="s2">, </span><span class="s1">*_ = fail_key</span>
      <span class="s1">extra = (</span><span class="s3">f&quot;, where </span><span class="s2">{</span><span class="s1">base</span><span class="s2">}</span><span class="s3">[</span><span class="s2">{</span><span class="s1">arg_key</span><span class="s2">}</span><span class="s3">] is bound to </span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">'s &quot;</span>
               <span class="s3">f&quot;parameter '</span><span class="s2">{</span><span class="s1">list(ba.arguments.keys())[arg_key.idx]</span><span class="s2">}</span><span class="s3">',&quot;</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">extra = </span><span class="s3">&quot;&quot;</span>
    <span class="s1">msgs.append(</span>
        <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">_specs</span><span class="s2">{</span><span class="s1">keystr(spec_key)</span><span class="s2">} </span><span class="s3">is </span><span class="s2">{</span><span class="s1">spec</span><span class="s2">} </span><span class="s3">which has length &quot;</span>
        <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">len(spec)</span><span class="s2">}</span><span class="s3">, but &quot;</span>
        <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">base</span><span class="s2">}{</span><span class="s1">keystr(fail_key)</span><span class="s2">}{</span><span class="s1">extra</span><span class="s2">} </span><span class="s3">has shape </span><span class="s2">{</span><span class="s1">aval.str_short()</span><span class="s2">}</span><span class="s3">, &quot;</span>
        <span class="s3">f&quot;which has rank </span><span class="s2">{</span><span class="s1">aval.ndim</span><span class="s2">} </span><span class="s3">(and </span><span class="s2">{</span><span class="s1">aval.ndim</span><span class="s2">} </span><span class="s3">&lt; </span><span class="s2">{</span><span class="s1">len(spec)</span><span class="s2">}</span><span class="s3">)&quot;</span><span class="s1">)</span>
  <span class="s2">assert </span><span class="s1">msgs</span>
  <span class="s1">msg = (</span><span class="s3">f&quot;shard_map applied to the function '</span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">' was given an &quot;</span>
         <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">_specs entry which is too long to be compatible with the &quot;</span>
         <span class="s3">f&quot;corresponding </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">put value from the function:</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
         <span class="s1">+ </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">'</span><span class="s1">.join(msgs) + </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">' </span><span class="s1">+</span>
         <span class="s3">f&quot;Entries in </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">_specs must be of length no greater than the &quot;</span>
         <span class="s3">f&quot;number of axes in the corresponding </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">put value.</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
         <span class="s3">f&quot;Either revise the spec to be shorter, or modify '</span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">' so &quot;</span>
         <span class="s3">f&quot;that its </span><span class="s2">{</span><span class="s1">prefix</span><span class="s2">}</span><span class="s3">puts have sufficient rank.&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">msg</span>

<span class="s2">def </span><span class="s1">_spec_divisibility_error(</span>
    <span class="s1">f: Callable</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">, </span><span class="s1">tree: PyTreeDef</span><span class="s2">, </span><span class="s1">specs: Specs</span><span class="s2">,</span>
    <span class="s1">fails: List[Union[core.ShapedArray</span><span class="s2">, </span><span class="s1">NoFail]]) -&gt; str:</span>
  <span class="s1">ba = _try_infer_args(f</span><span class="s2">, </span><span class="s1">tree)</span>
  <span class="s1">msgs = []</span>
  <span class="s2">for </span><span class="s1">(spec_key</span><span class="s2">, </span><span class="s1">spec)</span><span class="s2">, </span><span class="s1">(fail_key</span><span class="s2">, </span><span class="s1">aval) </span><span class="s2">in </span><span class="s1">_iter_paths(tree</span><span class="s2">, </span><span class="s1">specs</span><span class="s2">, </span><span class="s1">fails):</span>
    <span class="s2">if </span><span class="s1">ba </span><span class="s2">is not None</span><span class="s1">:</span>
      <span class="s1">arg_key</span><span class="s2">, </span><span class="s1">*_ = fail_key</span>
      <span class="s1">extra = (</span><span class="s3">f&quot;, where args[</span><span class="s2">{</span><span class="s1">arg_key</span><span class="s2">}</span><span class="s3">] is bound to </span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">'s &quot;</span>
               <span class="s3">f&quot;parameter '</span><span class="s2">{</span><span class="s1">list(ba.arguments.keys())[arg_key.idx]</span><span class="s2">}</span><span class="s3">',&quot;</span><span class="s1">)</span>
    <span class="s1">names = _canonicalize_spec(spec)</span>
    <span class="s2">for </span><span class="s1">d</span><span class="s2">, </span><span class="s1">ns </span><span class="s2">in </span><span class="s1">names.items():</span>
      <span class="s2">if </span><span class="s1">aval.shape[d] % math.prod(mesh.shape[n] </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">ns):</span>
        <span class="s1">axis = </span><span class="s3">f&quot;axes </span><span class="s2">{</span><span class="s1">ns</span><span class="s2">}</span><span class="s3">&quot; </span><span class="s2">if </span><span class="s1">len(ns) &gt; </span><span class="s4">1 </span><span class="s2">else </span><span class="s3">f&quot;axis '</span><span class="s2">{</span><span class="s1">ns[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">}</span><span class="s3">'&quot;</span>
        <span class="s1">total = </span><span class="s3">'total ' </span><span class="s2">if </span><span class="s1">len(ns) &gt; </span><span class="s4">1 </span><span class="s2">else </span><span class="s3">''</span>
        <span class="s1">sz = math.prod(mesh.shape[n] </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">ns)</span>
        <span class="s1">msgs.append(</span>
            <span class="s3">f&quot;args</span><span class="s2">{</span><span class="s1">keystr(fail_key)</span><span class="s2">} </span><span class="s3">of shape </span><span class="s2">{</span><span class="s1">aval.str_short()</span><span class="s2">}{</span><span class="s1">extra</span><span class="s2">} </span><span class="s3">&quot;</span>
            <span class="s3">f&quot;corresponds to in_specs</span><span class="s2">{</span><span class="s1">keystr(spec_key)</span><span class="s2">} </span><span class="s3">of value </span><span class="s2">{</span><span class="s1">spec</span><span class="s2">}</span><span class="s3">, &quot;</span>
            <span class="s3">f&quot;which maps array axis </span><span class="s2">{</span><span class="s1">d</span><span class="s2">} </span><span class="s3">(of size </span><span class="s2">{</span><span class="s1">aval.shape[d]</span><span class="s2">}</span><span class="s3">) to mesh &quot;</span>
            <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">axis</span><span class="s2">} </span><span class="s3">(of </span><span class="s2">{</span><span class="s1">total</span><span class="s2">}</span><span class="s3">size </span><span class="s2">{</span><span class="s1">sz</span><span class="s2">}</span><span class="s3">), but </span><span class="s2">{</span><span class="s1">sz</span><span class="s2">} </span><span class="s3">does not evenly divide &quot;</span>
            <span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">aval.shape[d]</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>
  <span class="s2">assert </span><span class="s1">msgs</span>
  <span class="s1">msg = (</span><span class="s3">f&quot;shard_map applied to the function '</span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">' was given argument &quot;</span>
         <span class="s3">f&quot;arrays with axis sizes that are not evenly divisible by the &quot;</span>
         <span class="s3">f&quot;corresponding mesh axis sizes:</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
         <span class="s3">f&quot;The mesh given has shape </span><span class="s2">{</span><span class="s1">mesh.device_ids.shape</span><span class="s2">} </span><span class="s3">with corresponding &quot;</span>
         <span class="s3">f&quot;axis names </span><span class="s2">{</span><span class="s1">mesh.axis_names</span><span class="s2">}</span><span class="s3">.</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
         <span class="s1">+ </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">'</span><span class="s1">.join(msgs) + </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">' </span><span class="s1">+</span>
         <span class="s3">f&quot;Array arguments' axis sizes must be evenly divisible by the mesh &quot;</span>
         <span class="s3">f&quot;axis or axes indicated by the corresponding elements of the &quot;</span>
         <span class="s3">f&quot;argument's in_specs entry. Consider checking that in_specs are &quot;</span>
         <span class="s3">f&quot;correct, and if so consider changing the mesh axis sizes or else &quot;</span>
         <span class="s3">f&quot;padding the input and adapting '</span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">' appropriately.&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">msg</span>

<span class="s2">def </span><span class="s1">_rep_error(f: Callable</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">, </span><span class="s1">tree: PyTreeDef</span><span class="s2">, </span><span class="s1">specs: Specs</span><span class="s2">,</span>
               <span class="s1">fails: List[Union[Set</span><span class="s2">, </span><span class="s1">NoFail]]) -&gt; str:</span>
  <span class="s1">msgs = []</span>
  <span class="s2">for </span><span class="s1">(spec_key</span><span class="s2">, </span><span class="s1">spec)</span><span class="s2">, </span><span class="s1">(fail_key</span><span class="s2">, </span><span class="s1">rep) </span><span class="s2">in </span><span class="s1">_iter_paths(tree</span><span class="s2">, </span><span class="s1">specs</span><span class="s2">, </span><span class="s1">fails):</span>
    <span class="s1">dst = _canonicalize_spec(spec)</span>
    <span class="s1">unmentioned = _unmentioned(mesh</span><span class="s2">, </span><span class="s1">dst)</span>
    <span class="s2">if </span><span class="s1">len(unmentioned) &gt; </span><span class="s4">1</span><span class="s1">:</span>
      <span class="s1">need_rep = </span><span class="s3">','</span><span class="s1">.join(map(str</span><span class="s2">, </span><span class="s1">unmentioned))</span>
      <span class="s1">got_rep = </span><span class="s3">','</span><span class="s1">.join(map(str</span><span class="s2">, </span><span class="s1">rep))</span>
      <span class="s1">diff = </span><span class="s3">','</span><span class="s1">.join(map(str</span><span class="s2">, </span><span class="s1">unmentioned - rep))</span>
      <span class="s1">msgs.append(</span>
          <span class="s3">f&quot;out_specs</span><span class="s2">{</span><span class="s1">keystr(spec_key)</span><span class="s2">} </span><span class="s3">is </span><span class="s2">{</span><span class="s1">spec</span><span class="s2">} </span><span class="s3">which implies that the &quot;</span>
          <span class="s3">f&quot;corresponding output value is replicated across mesh axes &quot;</span>
          <span class="s3">f&quot;</span><span class="s2">{{{</span><span class="s1">need_rep</span><span class="s2">}}}</span><span class="s3">, but could only infer replication over </span><span class="s2">{{{</span><span class="s1">got_rep</span><span class="s2">}}}</span><span class="s3">, &quot;</span>
          <span class="s3">f&quot;which is missing the required axes </span><span class="s2">{</span><span class="s1">diff</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">need_rep_</span><span class="s2">, </span><span class="s1">= unmentioned</span>
      <span class="s1">msgs.append(</span>
          <span class="s3">f&quot;out_specs</span><span class="s2">{</span><span class="s1">keystr(spec_key)</span><span class="s2">} </span><span class="s3">is </span><span class="s2">{</span><span class="s1">spec</span><span class="s2">} </span><span class="s3">which implies that the &quot;</span>
          <span class="s3">f&quot;corresponding output value is replicated across mesh axis &quot;</span>
          <span class="s3">f&quot;'</span><span class="s2">{</span><span class="s1">need_rep_</span><span class="s2">}</span><span class="s3">', but could not infer replication over any axes&quot;</span><span class="s1">)</span>
  <span class="s2">assert </span><span class="s1">msgs</span>
  <span class="s1">msg = (</span><span class="s3">f&quot;shard_map applied to the function '</span><span class="s2">{</span><span class="s1">f.__name__</span><span class="s2">}</span><span class="s3">' was given &quot;</span>
         <span class="s3">f&quot;out_specs which require replication which can't be statically &quot;</span>
         <span class="s3">f&quot;inferred given the mesh:</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
         <span class="s3">f&quot;The mesh given has shape </span><span class="s2">{</span><span class="s1">mesh.device_ids.shape</span><span class="s2">} </span><span class="s3">with corresponding &quot;</span>
         <span class="s3">f&quot;axis names </span><span class="s2">{</span><span class="s1">mesh.axis_names</span><span class="s2">}</span><span class="s3">.</span><span class="s2">\n\n</span><span class="s3">&quot;</span>
         <span class="s1">+ </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">'</span><span class="s1">.join(msgs) + </span><span class="s3">'</span><span class="s2">\n\n</span><span class="s3">' </span><span class="s1">+</span>
         <span class="s3">&quot;Check if these output values are meant to be replicated over those &quot;</span>
         <span class="s3">&quot;mesh axes. If not, consider revising the corresponding out_specs &quot;</span>
         <span class="s3">&quot;entries. If so, consider disabling the check by passing the &quot;</span>
         <span class="s3">&quot;check_rep=False argument to shard_map.&quot;</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">msg</span>

<span class="s2">def </span><span class="s1">_unmentioned(mesh: Mesh</span><span class="s2">, </span><span class="s1">names: AxisNames) -&gt; Set[AxisName]:</span>
  <span class="s2">return </span><span class="s1">set(mesh.axis_names) - {n </span><span class="s2">for </span><span class="s1">ns </span><span class="s2">in </span><span class="s1">names.values() </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">ns}</span>

<span class="s2">def </span><span class="s1">_try_infer_args(f</span><span class="s2">, </span><span class="s1">tree):</span>
  <span class="s1">dummy_args = tree_unflatten(tree</span><span class="s2">, </span><span class="s1">[</span><span class="s2">False</span><span class="s1">] * tree.num_leaves)</span>
  <span class="s2">try</span><span class="s1">:</span>
    <span class="s2">return </span><span class="s1">inspect.signature(f).bind(*dummy_args)</span>
  <span class="s2">except </span><span class="s1">(TypeError</span><span class="s2">, </span><span class="s1">ValueError):</span>
    <span class="s2">return None</span>

<span class="s1">T = TypeVar(</span><span class="s3">'T'</span><span class="s1">)</span>
<span class="s2">def </span><span class="s1">_iter_paths(tree: PyTreeDef</span><span class="s2">, </span><span class="s1">specs: Specs</span><span class="s2">, </span><span class="s1">fails: List[Union[T</span><span class="s2">, </span><span class="s1">NoFail]]</span>
                <span class="s1">) -&gt; List[Tuple[Tuple[KeyPath</span><span class="s2">, </span><span class="s1">P]</span><span class="s2">, </span><span class="s1">Tuple[KeyPath</span><span class="s2">, </span><span class="s1">T]]]:</span>
  <span class="s1">failures = tree_unflatten(tree</span><span class="s2">, </span><span class="s1">fails)</span>
  <span class="s1">failures_aug = generate_key_paths(failures)</span>
  <span class="s1">specs_ = tree_unflatten(tree_structure(specs)</span><span class="s2">, </span><span class="s1">generate_key_paths(specs))</span>
  <span class="s1">leaf = </span><span class="s2">lambda </span><span class="s1">x: type(x) </span><span class="s2">is </span><span class="s1">tuple </span><span class="s2">and </span><span class="s1">len(x) == </span><span class="s4">2 </span><span class="s2">and </span><span class="s1">type(x[</span><span class="s4">1</span><span class="s1">]) </span><span class="s2">is </span><span class="s1">P</span>
  <span class="s1">specs_aug = broadcast_prefix(specs_</span><span class="s2">, </span><span class="s1">failures</span><span class="s2">, </span><span class="s1">is_leaf=leaf)</span>
  <span class="s2">return </span><span class="s1">[((spec_key</span><span class="s2">, </span><span class="s1">spec)</span><span class="s2">, </span><span class="s1">(fail_key</span><span class="s2">, </span><span class="s1">fail_data))</span>
          <span class="s2">for </span><span class="s1">(spec_key</span><span class="s2">, </span><span class="s1">spec)</span><span class="s2">, </span><span class="s1">(fail_key</span><span class="s2">, </span><span class="s1">fail_data)</span>
          <span class="s2">in </span><span class="s1">zip(specs_aug</span><span class="s2">, </span><span class="s1">failures_aug) </span><span class="s2">if </span><span class="s1">fail_data </span><span class="s2">is not </span><span class="s1">no_fail]</span>

<span class="s0"># Primitive</span>

<span class="s1">JaxType = Any</span>
<span class="s1">MaybeTracer = Union[JaxType</span><span class="s2">, </span><span class="s1">Tracer]</span>

<span class="s2">class </span><span class="s1">ShardMapPrimitive(core.Primitive):</span>
  <span class="s1">multiple_results = </span><span class="s2">True</span>

  <span class="s2">def </span><span class="s1">bind(self</span><span class="s2">, </span><span class="s1">fun: lu.WrappedFun</span><span class="s2">, </span><span class="s1">*args: MaybeTracer</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">,</span>
           <span class="s1">in_names: Tuple[AxisNames</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">,</span>
           <span class="s1">out_names_thunk: Callable[[]</span><span class="s2">, </span><span class="s1">Tuple[AxisNames</span><span class="s2">, </span><span class="s1">...]]</span><span class="s2">,</span>
           <span class="s1">check_rep: bool) -&gt; Sequence[MaybeTracer]:</span>
    <span class="s1">top_trace = core.find_top_trace(args)</span>
    <span class="s1">fun</span><span class="s2">, </span><span class="s1">env_todo = process_env_traces(fun</span><span class="s2">, </span><span class="s1">top_trace.level</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">,</span>
                                       <span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep)</span>

    <span class="s1">@as_hashable_function(closure=out_names_thunk)</span>
    <span class="s2">def </span><span class="s1">new_out_names_thunk():</span>
      <span class="s1">out_names = out_names_thunk()</span>
      <span class="s1">_</span><span class="s2">, </span><span class="s1">xforms = env_todo()</span>
      <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">xforms:</span>
        <span class="s1">out_names = t(out_names)</span>
      <span class="s2">return </span><span class="s1">out_names</span>

    <span class="s1">tracers = map(top_trace.full_raise</span><span class="s2">, </span><span class="s1">args)</span>
    <span class="s1">outs = top_trace.process_shard_map(  </span><span class="s0"># pytype: disable=attribute-error</span>
        <span class="s1">shard_map_p</span><span class="s2">, </span><span class="s1">fun</span><span class="s2">, </span><span class="s1">tracers</span><span class="s2">, </span><span class="s1">mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=in_names</span><span class="s2">,</span>
        <span class="s1">out_names_thunk=new_out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
    <span class="s1">todos</span><span class="s2">, </span><span class="s1">_ = env_todo()</span>
    <span class="s2">return </span><span class="s1">map(core.full_lower</span><span class="s2">, </span><span class="s1">core.apply_todos(todos</span><span class="s2">, </span><span class="s1">outs))</span>

  <span class="s2">def </span><span class="s1">get_bind_params(self</span><span class="s2">, </span><span class="s1">params):</span>
    <span class="s1">new_params = dict(params)</span>
    <span class="s1">jaxpr = new_params.pop(</span><span class="s3">'jaxpr'</span><span class="s1">)</span>
    <span class="s1">subfun = lu.hashable_partial(lu.wrap_init(core.eval_jaxpr)</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">())</span>
    <span class="s1">axes = new_params.pop(</span><span class="s3">'out_names'</span><span class="s1">)</span>
    <span class="s1">new_params[</span><span class="s3">'out_names_thunk'</span><span class="s1">] = HashableFunction(</span><span class="s2">lambda</span><span class="s1">: axes</span><span class="s2">, </span><span class="s1">closure=axes)</span>
    <span class="s2">return </span><span class="s1">[subfun]</span><span class="s2">, </span><span class="s1">new_params</span>

<span class="s1">shard_map_p = ShardMapPrimitive(</span><span class="s3">'shard_map'</span><span class="s1">)</span>

<span class="s1">@lu.transformation_with_aux</span>
<span class="s2">def </span><span class="s1">process_env_traces(level: int</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep</span><span class="s2">,</span>
                       <span class="s1">*args: Any):</span>
  <span class="s1">outs = </span><span class="s2">yield </span><span class="s1">args</span><span class="s2">, </span><span class="s1">{}</span>
  <span class="s1">todos</span><span class="s2">, </span><span class="s1">out_names_transforms = []</span><span class="s2">, </span><span class="s1">[]</span>
  <span class="s2">while True</span><span class="s1">:</span>
    <span class="s1">tracers = [x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">outs </span><span class="s2">if </span><span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">core.Tracer)</span>
               <span class="s2">and </span><span class="s1">(level </span><span class="s2">is None or </span><span class="s1">x._trace.level &gt; level)]</span>
    <span class="s2">if </span><span class="s1">tracers:</span>
      <span class="s1">ans = max(tracers</span><span class="s2">, </span><span class="s1">key=op.attrgetter(</span><span class="s3">'_trace.level'</span><span class="s1">))</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s2">break</span>
    <span class="s1">trace = ans._trace.main.with_cur_sublevel()</span>
    <span class="s1">outs = map(trace.full_raise</span><span class="s2">, </span><span class="s1">outs)</span>
    <span class="s1">outs</span><span class="s2">, </span><span class="s1">(todo</span><span class="s2">, </span><span class="s1">xform) = trace.post_process_shard_map(</span>
        <span class="s1">outs</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep)</span>
    <span class="s1">todos.append(todo)</span>
    <span class="s1">out_names_transforms.append(xform)</span>
  <span class="s2">yield </span><span class="s1">outs</span><span class="s2">, </span><span class="s1">(tuple(todos)</span><span class="s2">, </span><span class="s1">tuple(out_names_transforms))</span>

<span class="s0"># Staging</span>

<span class="s2">def </span><span class="s1">_shard_map_staging(</span>
    <span class="s1">trace: pe.DynamicJaxprTrace</span><span class="s2">, </span><span class="s1">prim: core.Primitive</span><span class="s2">, </span><span class="s1">fun: lu.WrappedFun</span><span class="s2">,</span>
    <span class="s1">in_tracers: Sequence[pe.DynamicJaxprTracer]</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">,</span>
    <span class="s1">in_names: Tuple[AxisNames</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">,</span>
    <span class="s1">out_names_thunk: Callable[[]</span><span class="s2">, </span><span class="s1">Tuple[AxisNames</span><span class="s2">, </span><span class="s1">...]]</span><span class="s2">,</span>
    <span class="s1">check_rep: bool</span><span class="s2">,</span>
  <span class="s1">) -&gt; Sequence[pe.DynamicJaxprTracer]:</span>
  <span class="s1">in_avals = [t.aval </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">in_tracers]</span>
  <span class="s1">in_avals_ = map(partial(_shard_aval</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">in_avals)</span>
  <span class="s2">with </span><span class="s1">core.new_sublevel()</span><span class="s2">, </span><span class="s1">core.extend_axis_env_nd(mesh.shape.items()):</span>
    <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">out_avals_</span><span class="s2">, </span><span class="s1">consts = pe.trace_to_subjaxpr_dynamic(</span>
        <span class="s1">fun</span><span class="s2">, </span><span class="s1">trace.main</span><span class="s2">, </span><span class="s1">in_avals_)</span>
  <span class="s1">_check_names(out_names_thunk()</span><span class="s2">, </span><span class="s1">out_avals_)</span>
  <span class="s2">if </span><span class="s1">check_rep:</span>
    <span class="s1">in_rep = map(partial(_in_names_to_rep</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">in_names)</span>
    <span class="s1">out_rep = _output_rep(mesh</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">in_rep)</span>
    <span class="s1">_check_reps(mesh</span><span class="s2">, </span><span class="s1">out_names_thunk()</span><span class="s2">, </span><span class="s1">out_rep)</span>
  <span class="s1">out_avals = map(partial(_unshard_aval</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">out_names_thunk()</span><span class="s2">, </span><span class="s1">out_avals_)</span>
  <span class="s1">source_info = source_info_util.current()</span>
  <span class="s1">out_tracers = [pe.DynamicJaxprTracer(trace</span><span class="s2">, </span><span class="s1">a</span><span class="s2">, </span><span class="s1">source_info) </span><span class="s2">for </span><span class="s1">a </span><span class="s2">in </span><span class="s1">out_avals]</span>
  <span class="s1">invars = map(trace.getvar</span><span class="s2">, </span><span class="s1">in_tracers)</span>
  <span class="s1">constvars = map(trace.getvar</span><span class="s2">, </span><span class="s1">map(trace.instantiate_const</span><span class="s2">, </span><span class="s1">consts))</span>
  <span class="s1">outvars = map(trace.makevar</span><span class="s2">, </span><span class="s1">out_tracers)</span>
  <span class="s1">in_names_staged = ({}</span><span class="s2">,</span><span class="s1">) * len(consts) + tuple(in_names)  </span><span class="s0"># type: ignore</span>
  <span class="s2">with </span><span class="s1">core.extend_axis_env_nd(mesh.shape.items()):</span>
    <span class="s1">jaxpr = pe.convert_constvars_jaxpr(jaxpr)</span>
  <span class="s1">params = dict(mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=in_names_staged</span><span class="s2">,</span>
                <span class="s1">out_names=tuple(out_names_thunk())</span><span class="s2">, </span><span class="s1">jaxpr=jaxpr</span><span class="s2">,</span>
                <span class="s1">check_rep=check_rep)</span>
  <span class="s1">eqn = pe.new_jaxpr_eqn([*constvars</span><span class="s2">, </span><span class="s1">*invars]</span><span class="s2">, </span><span class="s1">outvars</span><span class="s2">, </span><span class="s1">prim</span><span class="s2">, </span><span class="s1">params</span><span class="s2">,</span>
                         <span class="s1">jaxpr.effects</span><span class="s2">, </span><span class="s1">source_info)</span>
  <span class="s1">trace.frame.add_eqn(eqn)</span>
  <span class="s2">return </span><span class="s1">out_tracers</span>
<span class="s1">pe.DynamicJaxprTrace.process_shard_map = _shard_map_staging</span>

<span class="s2">def </span><span class="s1">_shard_aval(mesh: Mesh</span><span class="s2">, </span><span class="s1">names: AxisNames</span><span class="s2">, </span><span class="s1">aval: core.AbstractValue</span>
                <span class="s1">) -&gt; core.AbstractValue:</span>
  <span class="s2">if </span><span class="s1">isinstance(aval</span><span class="s2">, </span><span class="s1">core.ShapedArray):</span>
    <span class="s2">return </span><span class="s1">aval.update(tuple(sz // math.prod(mesh.shape[n] </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">names.get(i</span><span class="s2">, </span><span class="s1">()))</span>
                             <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sz </span><span class="s2">in </span><span class="s1">enumerate(aval.shape)))</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError  </span><span class="s0"># TODO(mattjj): add table with handlers</span>

<span class="s2">def </span><span class="s1">_unshard_aval(mesh: Mesh</span><span class="s2">, </span><span class="s1">names: AxisNames</span><span class="s2">, </span><span class="s1">aval: core.AbstractValue</span>
                 <span class="s1">) -&gt; core.AbstractValue:</span>
  <span class="s2">if </span><span class="s1">isinstance(aval</span><span class="s2">, </span><span class="s1">core.ShapedArray):</span>
    <span class="s2">return </span><span class="s1">aval.update(tuple(sz * math.prod(mesh.shape[n] </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">names.get(i</span><span class="s2">, </span><span class="s1">()))</span>
                             <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">sz </span><span class="s2">in </span><span class="s1">enumerate(aval.shape))</span><span class="s2">,</span>
                       <span class="s1">named_shape={k: v </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">aval.named_shape.items()</span>
                                    <span class="s2">if </span><span class="s1">k </span><span class="s2">not in </span><span class="s1">mesh.shape})</span>
  <span class="s2">else</span><span class="s1">:</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError  </span><span class="s0"># TODO(mattjj): add table with handlers</span>

<span class="s0"># Type-checking</span>

<span class="s2">def </span><span class="s1">_shard_map_typecheck(_</span><span class="s2">, </span><span class="s1">*in_atoms</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names</span><span class="s2">,</span>
                         <span class="s1">check_rep):</span>
  <span class="s2">for </span><span class="s1">v</span><span class="s2">, </span><span class="s1">x</span><span class="s2">, </span><span class="s1">in_name </span><span class="s2">in </span><span class="s1">zip(jaxpr.invars</span><span class="s2">, </span><span class="s1">in_atoms</span><span class="s2">, </span><span class="s1">in_names):</span>
    <span class="s2">if not </span><span class="s1">core.typecompat(v.aval</span><span class="s2">, </span><span class="s1">_shard_aval(mesh</span><span class="s2">, </span><span class="s1">in_name</span><span class="s2">, </span><span class="s1">x.aval)):</span>
      <span class="s2">raise </span><span class="s1">core.JaxprTypeError(</span><span class="s3">&quot;shard_map argument avals not compatible with &quot;</span>
                                <span class="s3">&quot;jaxpr binder avals and in_names&quot;</span><span class="s1">)</span>
  <span class="s2">with </span><span class="s1">core.extend_axis_env_nd(tuple(mesh.shape.items())):</span>
    <span class="s1">core.check_jaxpr(jaxpr)</span>
  <span class="s2">if </span><span class="s1">check_rep:</span>
    <span class="s1">in_rep = map(partial(_in_names_to_rep</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">in_names)</span>
    <span class="s1">out_rep = _output_rep(mesh</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">in_rep)</span>
    <span class="s2">for </span><span class="s1">rep</span><span class="s2">, </span><span class="s1">dst </span><span class="s2">in </span><span class="s1">zip(out_rep</span><span class="s2">, </span><span class="s1">out_names):</span>
      <span class="s2">if not </span><span class="s1">_valid_repeats(mesh</span><span class="s2">, </span><span class="s1">rep</span><span class="s2">, </span><span class="s1">dst):</span>
        <span class="s2">raise </span><span class="s1">core.JaxprTypeError(</span><span class="s3">&quot;shard_map can't prove output is sufficiently &quot;</span>
                                  <span class="s3">&quot;replicated&quot;</span><span class="s1">)</span>
  <span class="s1">out_avals_sharded = [x.aval </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">jaxpr.outvars]</span>
  <span class="s1">out_avals = map(partial(_unshard_aval</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">out_names</span><span class="s2">, </span><span class="s1">out_avals_sharded)</span>
  <span class="s2">return </span><span class="s1">out_avals</span><span class="s2">, </span><span class="s1">jaxpr.effects</span>
<span class="s1">core.custom_typechecks[shard_map_p] = _shard_map_typecheck</span>

<span class="s2">def </span><span class="s1">_in_names_to_rep(mesh: Mesh</span><span class="s2">, </span><span class="s1">names: AxisNames) -&gt; Set[AxisName]:</span>
  <span class="s2">return </span><span class="s1">set(mesh.axis_names) - set(n </span><span class="s2">for </span><span class="s1">ns </span><span class="s2">in </span><span class="s1">names.values() </span><span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">ns)</span>

<span class="s2">def </span><span class="s1">_output_rep(mesh: Mesh</span><span class="s2">, </span><span class="s1">jaxpr: core.Jaxpr</span><span class="s2">, </span><span class="s1">in_rep: Sequence[Set[AxisName]]</span><span class="s2">,</span>
                <span class="s1">) -&gt; Sequence[Set[AxisName]]:</span>
  <span class="s1">env: Dict[core.Var</span><span class="s2">, </span><span class="s1">Set[AxisName]] = {}</span>

  <span class="s2">def </span><span class="s1">read(x: core.Atom) -&gt; Set[AxisName]:</span>
    <span class="s2">return </span><span class="s1">env[x] </span><span class="s2">if </span><span class="s1">type(x) </span><span class="s2">is </span><span class="s1">core.Var </span><span class="s2">else </span><span class="s1">set(mesh.axis_names)</span>

  <span class="s2">def </span><span class="s1">write(v: core.Var</span><span class="s2">, </span><span class="s1">val: Set[AxisName]) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
    <span class="s1">env[v] = val</span>

  <span class="s1">map(write</span><span class="s2">, </span><span class="s1">jaxpr.constvars</span><span class="s2">, </span><span class="s1">[set(mesh.axis_names)] * len(jaxpr.constvars))</span>
  <span class="s1">map(write</span><span class="s2">, </span><span class="s1">jaxpr.invars</span><span class="s2">, </span><span class="s1">in_rep)</span>
  <span class="s2">for </span><span class="s1">e </span><span class="s2">in </span><span class="s1">jaxpr.eqns:</span>
    <span class="s1">rule = _rep_rules.get(e.primitive</span><span class="s2">, </span><span class="s1">partial(_rep_rule</span><span class="s2">, </span><span class="s1">e.primitive))</span>
    <span class="s1">out_rep = rule(mesh</span><span class="s2">, </span><span class="s1">*map(read</span><span class="s2">, </span><span class="s1">e.invars)</span><span class="s2">, </span><span class="s1">**e.params)</span>
    <span class="s2">if </span><span class="s1">e.primitive.multiple_results:</span>
      <span class="s1">out_rep = [out_rep] * len(e.outvars) </span><span class="s2">if </span><span class="s1">type(out_rep) </span><span class="s2">is </span><span class="s1">set </span><span class="s2">else </span><span class="s1">out_rep</span>
      <span class="s1">map(write</span><span class="s2">, </span><span class="s1">e.outvars</span><span class="s2">, </span><span class="s1">out_rep)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">write(e.outvars[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">out_rep)</span>
  <span class="s2">return </span><span class="s1">map(read</span><span class="s2">, </span><span class="s1">jaxpr.outvars)</span>

<span class="s2">def </span><span class="s1">_valid_repeats(mesh: Mesh</span><span class="s2">, </span><span class="s1">rep: Set[AxisName]</span><span class="s2">, </span><span class="s1">dst: AxisNames) -&gt; bool:</span>
  <span class="s2">return </span><span class="s1">_unmentioned(mesh</span><span class="s2">, </span><span class="s1">dst).issubset(rep)</span>

<span class="s0"># Lowering</span>

<span class="s2">def </span><span class="s1">_shard_map_lowering(ctx</span><span class="s2">, </span><span class="s1">*in_nodes</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names</span><span class="s2">,</span>
                        <span class="s1">check_rep):</span>
  <span class="s2">del </span><span class="s1">check_rep</span>
  <span class="s1">sharded_avals = [v.aval </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">jaxpr.invars]</span>
  <span class="s1">in_nodes_ = map(partial(_xla_shard</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">ctx.avals_in</span><span class="s2">,</span>
                  <span class="s1">sharded_avals</span><span class="s2">, </span><span class="s1">in_nodes)</span>
  <span class="s1">new_axis_context = mlir.SPMDAxisContext(mesh</span><span class="s2">, </span><span class="s1">frozenset(mesh.axis_names))</span>
  <span class="s1">sub_ctx = ctx.module_context.replace(axis_context=new_axis_context)</span>
  <span class="s2">with </span><span class="s1">core.extend_axis_env_nd(tuple(mesh.shape.items())):</span>
    <span class="s1">out_nodes_</span><span class="s2">, </span><span class="s1">_ = mlir.jaxpr_subcomp(sub_ctx</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">mlir.TokenSet()</span><span class="s2">,</span>
                                       <span class="s1">()</span><span class="s2">, </span><span class="s1">*in_nodes_</span><span class="s2">,</span>
                                       <span class="s1">dim_var_values=ctx.dim_var_values)</span>
  <span class="s1">sharded_avals = [v.aval </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">jaxpr.outvars]</span>
  <span class="s2">return </span><span class="s1">map(partial(_xla_unshard</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">out_names</span><span class="s2">, </span><span class="s1">sharded_avals</span><span class="s2">,</span>
             <span class="s1">ctx.avals_out</span><span class="s2">, </span><span class="s1">out_nodes_)</span>
<span class="s1">mlir.register_lowering(shard_map_p</span><span class="s2">, </span><span class="s1">_shard_map_lowering)</span>

<span class="s2">def </span><span class="s1">_xla_shard(mesh</span><span class="s2">, </span><span class="s1">names</span><span class="s2">, </span><span class="s1">aval_in</span><span class="s2">, </span><span class="s1">aval_out</span><span class="s2">, </span><span class="s1">x):</span>
  <span class="s1">manual_proto = pxla.manual_proto(aval_in</span><span class="s2">, </span><span class="s1">frozenset(mesh.axis_names)</span><span class="s2">, </span><span class="s1">mesh)</span>
  <span class="s1">result_type</span><span class="s2">, </span><span class="s1">= mlir.aval_to_ir_types(aval_out)</span>
  <span class="s1">axes = {name: i </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">ns </span><span class="s2">in </span><span class="s1">names.items() </span><span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">ns}</span>
  <span class="s1">sharding_proto = pxla.new_mesh_sharding_specs(mesh.shape</span><span class="s2">, </span><span class="s1">mesh.axis_names)(</span>
      <span class="s1">aval_in.ndim</span><span class="s2">, </span><span class="s1">axes).sharding_proto()</span>
  <span class="s1">sx = mlir.wrap_with_sharding_op(x</span><span class="s2">, </span><span class="s1">sharding_proto</span><span class="s2">, </span><span class="s1">unspecified_dims=set())</span>
  <span class="s2">return </span><span class="s1">[mlir.wrap_with_full_to_shard_op(result_type</span><span class="s2">, </span><span class="s1">sx</span><span class="s2">, </span><span class="s1">manual_proto</span><span class="s2">, </span><span class="s1">set())]</span>

<span class="s2">def </span><span class="s1">_xla_unshard(mesh</span><span class="s2">, </span><span class="s1">names</span><span class="s2">, </span><span class="s1">aval_in</span><span class="s2">, </span><span class="s1">aval_out</span><span class="s2">, </span><span class="s1">xs):</span>
  <span class="s1">x</span><span class="s2">, </span><span class="s1">= xs</span>
  <span class="s1">manual_proto = pxla.manual_proto(aval_in</span><span class="s2">, </span><span class="s1">frozenset(mesh.axis_names)</span><span class="s2">, </span><span class="s1">mesh)</span>
  <span class="s1">result_type</span><span class="s2">, </span><span class="s1">= mlir.aval_to_ir_types(aval_out)</span>
  <span class="s1">sx = mlir.wrap_with_sharding_op(x</span><span class="s2">, </span><span class="s1">manual_proto</span><span class="s2">, </span><span class="s1">unspecified_dims=set())</span>
  <span class="s1">axes = {name: i </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">ns </span><span class="s2">in </span><span class="s1">names.items() </span><span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">ns}</span>
  <span class="s1">sharding_proto = pxla.new_mesh_sharding_specs(mesh.shape</span><span class="s2">, </span><span class="s1">mesh.axis_names)(</span>
      <span class="s1">aval_out.ndim</span><span class="s2">, </span><span class="s1">axes).sharding_proto()</span>
  <span class="s2">return </span><span class="s1">mlir.wrap_with_shard_to_full_op(result_type</span><span class="s2">, </span><span class="s1">sx</span><span class="s2">, </span><span class="s1">sharding_proto</span><span class="s2">, </span><span class="s1">set())</span>

<span class="s0"># Eager evaluation</span>

<span class="s2">def </span><span class="s1">_shard_map_impl(trace</span><span class="s2">, </span><span class="s1">prim</span><span class="s2">, </span><span class="s1">fun</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names_thunk</span><span class="s2">,</span>
                    <span class="s1">check_rep):</span>
  <span class="s2">del </span><span class="s1">prim</span>
  <span class="s1">args = map(partial(_unmatch_spec</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">args)</span>
  <span class="s1">in_rep = map(partial(_in_names_to_rep</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">in_names)</span>
  <span class="s2">with </span><span class="s1">core.new_base_main(ShardMapTrace</span><span class="s2">, </span><span class="s1">mesh=mesh</span><span class="s2">, </span><span class="s1">check=check_rep) </span><span class="s2">as </span><span class="s1">main:</span>
    <span class="s2">with </span><span class="s1">core.new_sublevel()</span><span class="s2">, </span><span class="s1">core.extend_axis_env_nd(mesh.shape.items()):</span>
      <span class="s1">t = main.with_cur_sublevel()</span>
      <span class="s1">in_tracers = map(partial(ShardMapTracer</span><span class="s2">, </span><span class="s1">t)</span><span class="s2">, </span><span class="s1">in_rep</span><span class="s2">, </span><span class="s1">args)</span>
      <span class="s1">ans = fun.call_wrapped(*in_tracers)</span>
      <span class="s1">out_tracers = map(t.full_raise</span><span class="s2">, </span><span class="s1">ans)</span>
      <span class="s1">outs_</span><span class="s2">, </span><span class="s1">out_rep = unzip2((t.val</span><span class="s2">, </span><span class="s1">t.rep) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">out_tracers)</span>
      <span class="s2">del </span><span class="s1">main</span><span class="s2">, </span><span class="s1">t</span><span class="s2">, </span><span class="s1">in_tracers</span><span class="s2">, </span><span class="s1">ans</span><span class="s2">, </span><span class="s1">out_tracers</span>
  <span class="s1">out_avals = [core.mapped_aval(x.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">core.get_aval(x)) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">outs_]</span>
  <span class="s1">_check_names(out_names_thunk()</span><span class="s2">, </span><span class="s1">out_avals)  </span><span class="s0"># pytype: disable=wrong-arg-types</span>
  <span class="s2">if </span><span class="s1">check_rep: _check_reps(mesh</span><span class="s2">, </span><span class="s1">out_names_thunk()</span><span class="s2">, </span><span class="s1">out_rep)</span>
  <span class="s2">return </span><span class="s1">map(partial(_match_spec</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">out_rep</span><span class="s2">, </span><span class="s1">out_names_thunk()</span><span class="s2">, </span><span class="s1">outs_)</span>
<span class="s1">core.EvalTrace.process_shard_map = _shard_map_impl</span>

<span class="s2">def </span><span class="s1">_names_to_pspec(names: AxisNames) -&gt; PartitionSpec:</span>
  <span class="s1">ndmin = max(names) + </span><span class="s4">1 </span><span class="s2">if </span><span class="s1">names </span><span class="s2">else </span><span class="s4">0</span>
  <span class="s2">return </span><span class="s1">PartitionSpec(*(names.get(i) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(ndmin)))</span>

<span class="s2">def </span><span class="s1">_unmatch_spec(mesh: Mesh</span><span class="s2">, </span><span class="s1">src: AxisNames</span><span class="s2">, </span><span class="s1">x: JaxType) -&gt; JaxType:</span>
  <span class="s2">with </span><span class="s1">core.eval_context():</span>
    <span class="s2">return </span><span class="s1">jax.jit(HashablePartial(_unmatch</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">tuple(src.items())))(x)</span>

<span class="s2">def </span><span class="s1">_unmatch(mesh</span><span class="s2">, </span><span class="s1">src_tup</span><span class="s2">, </span><span class="s1">x):</span>
  <span class="s1">src = _names_to_pspec(dict(src_tup))</span>
  <span class="s1">dst = P(mesh.axis_names)</span>
  <span class="s2">return </span><span class="s1">shard_map(_add_singleton</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">(src</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dst)(x)</span>

<span class="s2">def </span><span class="s1">_check_names(names: Sequence[AxisNames]</span><span class="s2">, </span><span class="s1">avals: Sequence[core.ShapedArray]</span>
                 <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
  <span class="s1">fail = [a </span><span class="s2">if </span><span class="s1">n </span><span class="s2">and not </span><span class="s1">max(n) &lt; a.ndim </span><span class="s2">else </span><span class="s1">no_fail</span>
          <span class="s2">for </span><span class="s1">n</span><span class="s2">, </span><span class="s1">a </span><span class="s2">in </span><span class="s1">zip(names</span><span class="s2">, </span><span class="s1">avals)]</span>
  <span class="s2">if </span><span class="s1">any(f </span><span class="s2">is not </span><span class="s1">no_fail </span><span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">fail): </span><span class="s2">raise </span><span class="s1">_SpecError(fail)</span>
<span class="s2">class </span><span class="s1">_SpecError(Exception): </span><span class="s2">pass</span>

<span class="s2">def </span><span class="s1">_check_reps(mesh</span><span class="s2">, </span><span class="s1">names</span><span class="s2">, </span><span class="s1">reps):</span>
  <span class="s1">fail = [r </span><span class="s2">if not </span><span class="s1">_valid_repeats(mesh</span><span class="s2">, </span><span class="s1">r</span><span class="s2">, </span><span class="s1">n) </span><span class="s2">else </span><span class="s1">no_fail</span>
          <span class="s2">for </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r </span><span class="s2">in </span><span class="s1">zip(names</span><span class="s2">, </span><span class="s1">reps)]</span>
  <span class="s2">if </span><span class="s1">any(f </span><span class="s2">is not </span><span class="s1">no_fail </span><span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">fail): </span><span class="s2">raise </span><span class="s1">_RepError(fail)</span>
<span class="s2">class </span><span class="s1">_RepError(Exception): </span><span class="s2">pass</span>

<span class="s2">def </span><span class="s1">_match_spec(mesh: Mesh</span><span class="s2">, </span><span class="s1">rep: Set[AxisName]</span><span class="s2">, </span><span class="s1">dst: AxisNames</span><span class="s2">, </span><span class="s1">x: JaxType</span>
                <span class="s1">) -&gt; JaxType:</span>
  <span class="s2">with </span><span class="s1">core.eval_context():</span>
    <span class="s2">return </span><span class="s1">jax.jit(HashablePartial(_match</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">tuple(dst.items())))(x)</span>

<span class="s2">def </span><span class="s1">_match(mesh</span><span class="s2">, </span><span class="s1">dst_tup</span><span class="s2">, </span><span class="s1">x):</span>
  <span class="s1">src = P(mesh.axis_names)</span>
  <span class="s1">dst = _names_to_pspec(dict(dst_tup))</span>
  <span class="s2">return </span><span class="s1">shard_map(_rem_singleton</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">(src</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">dst</span><span class="s2">, </span><span class="s1">check_rep=</span><span class="s2">False</span><span class="s1">)(x)</span>

<span class="s2">def </span><span class="s1">_rem_singleton(x): </span><span class="s2">return </span><span class="s1">x.reshape(x.shape[</span><span class="s4">1</span><span class="s1">:])</span>
<span class="s2">def </span><span class="s1">_add_singleton(x): </span><span class="s2">return </span><span class="s1">x.reshape(</span><span class="s4">1</span><span class="s2">, </span><span class="s1">*x.shape)</span>

<span class="s2">class </span><span class="s1">ShardMapTrace(core.Trace):</span>
  <span class="s1">mesh: Mesh</span>
  <span class="s1">check: bool</span>

  <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">check):</span>
    <span class="s1">super().__init__(*args)</span>
    <span class="s1">self.mesh = mesh</span>
    <span class="s1">self.check = check</span>

  <span class="s2">def </span><span class="s1">pure(self</span><span class="s2">, </span><span class="s1">val):</span>
    <span class="s1">val_ = _unmatch_spec(self.mesh</span><span class="s2">, </span><span class="s1">{}</span><span class="s2">, </span><span class="s1">val)</span>
    <span class="s2">return </span><span class="s1">ShardMapTracer(self</span><span class="s2">, </span><span class="s1">set(self.mesh.axis_names)</span><span class="s2">, </span><span class="s1">val_)</span>

  <span class="s2">def </span><span class="s1">sublift(self</span><span class="s2">, </span><span class="s1">tracer):</span>
    <span class="s2">return </span><span class="s1">ShardMapTracer(self</span><span class="s2">, </span><span class="s1">tracer.rep</span><span class="s2">, </span><span class="s1">tracer.val)</span>

  <span class="s2">def </span><span class="s1">process_primitive(self</span><span class="s2">, </span><span class="s1">prim</span><span class="s2">, </span><span class="s1">tracers</span><span class="s2">, </span><span class="s1">params):</span>
    <span class="s1">in_vals</span><span class="s2">, </span><span class="s1">in_rep = unzip2((t.val</span><span class="s2">, </span><span class="s1">t.rep) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tracers)</span>
    <span class="s1">eager_rule = eager_rules.get(prim)</span>
    <span class="s2">if </span><span class="s1">eager_rule:</span>
      <span class="s1">out_vals = eager_rule(self.mesh</span><span class="s2">, </span><span class="s1">*in_vals</span><span class="s2">, </span><span class="s1">**params)</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">f = HashablePartial(_prim_applier</span><span class="s2">, </span><span class="s1">prim</span><span class="s2">, </span><span class="s1">tuple(params.items())</span><span class="s2">, </span><span class="s1">self.mesh)</span>
      <span class="s2">with </span><span class="s1">core.eval_context()</span><span class="s2">, </span><span class="s1">jax.disable_jit(</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s1">out_vals = jax.jit(f)(*in_vals)</span>
    <span class="s1">rep_rule = _rep_rules.get(prim</span><span class="s2">, </span><span class="s1">partial(_rep_rule</span><span class="s2">, </span><span class="s1">prim))</span>
    <span class="s1">out_rep = rep_rule(self.mesh</span><span class="s2">, </span><span class="s1">*in_rep</span><span class="s2">, </span><span class="s1">**params) </span><span class="s2">if </span><span class="s1">self.check </span><span class="s2">else </span><span class="s1">set()</span>
    <span class="s2">if </span><span class="s1">prim.multiple_results:</span>
      <span class="s1">out_rep = [out_rep] * len(out_vals) </span><span class="s2">if </span><span class="s1">type(out_rep) </span><span class="s2">is </span><span class="s1">set </span><span class="s2">else </span><span class="s1">out_rep</span>
      <span class="s2">return </span><span class="s1">map(partial(ShardMapTracer</span><span class="s2">, </span><span class="s1">self)</span><span class="s2">, </span><span class="s1">out_rep</span><span class="s2">, </span><span class="s1">out_vals)</span>
    <span class="s2">return </span><span class="s1">ShardMapTracer(self</span><span class="s2">, </span><span class="s1">out_rep</span><span class="s2">, </span><span class="s1">out_vals)</span>

  <span class="s2">def </span><span class="s1">process_call(self</span><span class="s2">, </span><span class="s1">call_primitive</span><span class="s2">, </span><span class="s1">fun</span><span class="s2">, </span><span class="s1">tracers</span><span class="s2">, </span><span class="s1">params):</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError</span>


<span class="s2">class </span><span class="s1">ShardMapTracer(core.Tracer):</span>
  <span class="s1">rep: Set[AxisName]</span>
  <span class="s1">val: JaxType</span>

  <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">trace</span><span class="s2">, </span><span class="s1">rep</span><span class="s2">, </span><span class="s1">val):</span>
    <span class="s1">self._trace = trace</span>
    <span class="s1">self.rep = rep</span>
    <span class="s1">self.val = val</span>

  <span class="s1">@property</span>
  <span class="s2">def </span><span class="s1">aval(self):</span>
    <span class="s1">aval = core.get_aval(self.val)</span>
    <span class="s2">if </span><span class="s1">(isinstance(aval</span><span class="s2">, </span><span class="s1">core.ConcreteArray) </span><span class="s2">and</span>
        <span class="s1">self.rep == set(self._trace.mesh.axis_names)):</span>
      <span class="s2">with </span><span class="s1">core.eval_context():</span>
        <span class="s2">return </span><span class="s1">core.get_aval(self.val[</span><span class="s4">0</span><span class="s1">])</span>
    <span class="s2">else</span><span class="s1">:</span>
      <span class="s1">aval = core.raise_to_shaped(aval)</span>
      <span class="s2">return </span><span class="s1">core.mapped_aval(self._trace.mesh.size</span><span class="s2">, </span><span class="s4">0</span><span class="s2">, </span><span class="s1">aval)</span>

  <span class="s2">def </span><span class="s1">full_lower(self) -&gt; ShardMapTracer:</span>
    <span class="s2">return </span><span class="s1">self</span>

  <span class="s2">def </span><span class="s1">__str__(self) -&gt; str:</span>
    <span class="s2">with </span><span class="s1">core.eval_context():</span>
      <span class="s1">blocks = list(self.val)</span>
    <span class="s1">mesh = self._trace.mesh</span>
    <span class="s1">axis_names = </span><span class="s3">f&quot;(</span><span class="s2">{</span><span class="s3">', '</span><span class="s1">.join(map(str</span><span class="s2">, </span><span class="s1">mesh.axis_names))</span><span class="s2">}</span><span class="s3">,)&quot;</span>
    <span class="s2">return </span><span class="s3">'</span><span class="s2">\n</span><span class="s3">'</span><span class="s1">.join(</span>
        <span class="s3">f&quot;On </span><span class="s2">{</span><span class="s1">device</span><span class="s2">} </span><span class="s3">at mesh coordinates </span><span class="s2">{</span><span class="s1">axis_names</span><span class="s2">} </span><span class="s3">= </span><span class="s2">{</span><span class="s1">idx</span><span class="s2">}</span><span class="s3">:</span><span class="s2">\n{</span><span class="s1">block</span><span class="s2">}\n</span><span class="s3">&quot;</span>
        <span class="s2">for </span><span class="s1">(idx</span><span class="s2">, </span><span class="s1">device)</span><span class="s2">, </span><span class="s1">block </span><span class="s2">in </span><span class="s1">zip(np.ndenumerate(mesh.devices)</span><span class="s2">, </span><span class="s1">blocks))</span>

<span class="s2">def </span><span class="s1">_prim_applier(prim</span><span class="s2">, </span><span class="s1">params_tup</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">*args):</span>
  <span class="s2">def </span><span class="s1">apply(*args):</span>
    <span class="s1">outs = prim.bind(*map(_rem_singleton</span><span class="s2">, </span><span class="s1">args)</span><span class="s2">, </span><span class="s1">**dict(params_tup))</span>
    <span class="s2">return </span><span class="s1">tree_map(_add_singleton</span><span class="s2">, </span><span class="s1">outs)</span>
  <span class="s1">spec = P(mesh.axis_names)</span>
  <span class="s2">return </span><span class="s1">shard_map(apply</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">spec</span><span class="s2">, </span><span class="s1">spec</span><span class="s2">, False</span><span class="s1">)(*args)</span>

<span class="s1">eager_rules: Dict[core.Primitive</span><span class="s2">, </span><span class="s1">Callable] = {}</span>

<span class="s0"># TODO(mattjj): working around an apparent XLA or PjRt bug, remove eventually</span>
<span class="s2">def </span><span class="s1">_debug_callback_eager_rule(mesh</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">callback: Callable[...</span><span class="s2">, </span><span class="s1">Any]</span><span class="s2">,</span>
                               <span class="s1">effect: debugging.DebugEffect):</span>
  <span class="s2">del </span><span class="s1">effect</span>
  <span class="s2">with </span><span class="s1">core.eval_context():</span>
    <span class="s1">all_blocks = zip(*map(list</span><span class="s2">, </span><span class="s1">args))</span>
  <span class="s2">for </span><span class="s1">(idx</span><span class="s2">, </span><span class="s1">device)</span><span class="s2">, </span><span class="s1">blocks </span><span class="s2">in </span><span class="s1">zip(np.ndenumerate(mesh.devices)</span><span class="s2">, </span><span class="s1">all_blocks):</span>
    <span class="s1">callback(*blocks)</span>
  <span class="s2">return </span><span class="s1">[]</span>
<span class="s1">eager_rules[debugging.debug_callback_p] = _debug_callback_eager_rule</span>

<span class="s0"># Static replication checking</span>

<span class="s2">def </span><span class="s1">_rep_rule(prim: core.Primitive</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">, </span><span class="s1">*in_rep: Set[AxisName]</span><span class="s2">,</span>
              <span class="s1">**params: Any) -&gt; Union[Set[AxisName]</span><span class="s2">, </span><span class="s1">List[Set[AxisName]]]:</span>
  <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">f&quot;no replication rule for </span><span class="s2">{</span><span class="s1">prim</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>

<span class="s1">_rep_rules: Dict[core.Primitive</span><span class="s2">, </span><span class="s1">Callable] = {}</span>
<span class="s1">register_rule = </span><span class="s2">lambda </span><span class="s1">prim: </span><span class="s2">lambda </span><span class="s1">rule: _rep_rules.setdefault(prim</span><span class="s2">, </span><span class="s1">rule)</span>
<span class="s1">register_standard = </span><span class="s2">lambda </span><span class="s1">prim: _rep_rules.setdefault(prim</span><span class="s2">, </span><span class="s1">_standard_rep_rule)</span>

<span class="s2">def </span><span class="s1">_standard_rep_rule(_</span><span class="s2">, </span><span class="s1">*in_rep</span><span class="s2">, </span><span class="s1">**__):</span>
  <span class="s2">return </span><span class="s1">set.intersection(*in_rep) </span><span class="s2">if </span><span class="s1">in_rep </span><span class="s2">else </span><span class="s1">set()</span>

<span class="s2">for </span><span class="s1">o </span><span class="s2">in </span><span class="s1">it.chain(lax.__dict__.values()</span><span class="s2">, </span><span class="s1">slicing.__dict__.values()</span><span class="s2">,</span>
                  <span class="s1">windowed_reductions.__dict__.values()</span><span class="s2">, </span><span class="s1">fft.__dict__.values()</span><span class="s2">,</span>
                  <span class="s1">linalg.__dict__.values()</span><span class="s2">, </span><span class="s1">ops.__dict__.values()</span><span class="s2">,</span>
                  <span class="s1">ad_util.__dict__.values()</span><span class="s2">,</span>
                  <span class="s1">custom_derivatives.__dict__.values()):</span>
  <span class="s2">if </span><span class="s1">isinstance(o</span><span class="s2">, </span><span class="s1">core.Primitive): register_standard(o)</span>

<span class="s1">register_standard(lax_parallel.ppermute_p)  </span><span class="s0"># doesn't change replication</span>

<span class="s1">@register_rule(lax_parallel.psum_p)</span>
<span class="s2">def </span><span class="s1">_psum_rule(_</span><span class="s2">, </span><span class="s1">*in_rep</span><span class="s2">, </span><span class="s1">axes</span><span class="s2">, </span><span class="s1">axis_index_groups):</span>
  <span class="s2">if </span><span class="s1">axis_index_groups </span><span class="s2">is not None</span><span class="s1">: </span><span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s1">axes = (axes</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if not </span><span class="s1">isinstance(axes</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">else </span><span class="s1">axes</span>
  <span class="s2">return </span><span class="s1">[r | set(axes) </span><span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span class="s1">in_rep]  </span><span class="s0"># introduces replication</span>

<span class="s1">@register_rule(lax_parallel.all_gather_p)</span>
<span class="s2">def </span><span class="s1">_all_gather_rule(_</span><span class="s2">, </span><span class="s1">in_rep</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">all_gather_dimension</span><span class="s2">, </span><span class="s1">axis_name</span><span class="s2">, </span><span class="s1">axis_size</span><span class="s2">,</span>
                     <span class="s1">axis_index_groups</span><span class="s2">, </span><span class="s1">tiled):</span>
  <span class="s2">if </span><span class="s1">axis_index_groups </span><span class="s2">is not None</span><span class="s1">: </span><span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s2">if not </span><span class="s1">tiled: </span><span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s1">axis_name = (axis_name</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if not </span><span class="s1">isinstance(axis_name</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">else </span><span class="s1">axis_name</span>
  <span class="s2">return </span><span class="s1">in_rep | set(axis_name)  </span><span class="s0"># introduces replication</span>

<span class="s1">@register_rule(lax_parallel.reduce_scatter_p)</span>
<span class="s2">def </span><span class="s1">_reduce_scatter_rule(_</span><span class="s2">, </span><span class="s1">in_rep</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">scatter_dimension</span><span class="s2">, </span><span class="s1">axis_name</span><span class="s2">, </span><span class="s1">axis_size</span><span class="s2">,</span>
                         <span class="s1">axis_index_groups</span><span class="s2">, </span><span class="s1">tiled):</span>
  <span class="s2">if </span><span class="s1">axis_index_groups </span><span class="s2">is not None</span><span class="s1">: </span><span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s2">if not </span><span class="s1">tiled: </span><span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s2">return </span><span class="s1">in_rep - {axis_name}  </span><span class="s0"># removes replication</span>

<span class="s1">@register_rule(lax_parallel.all_to_all_p)</span>
<span class="s2">def </span><span class="s1">_all_to_all_rule(_</span><span class="s2">, </span><span class="s1">in_rep</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">split_axis</span><span class="s2">, </span><span class="s1">concat_axis</span><span class="s2">, </span><span class="s1">axis_name</span><span class="s2">,</span>
                     <span class="s1">axis_index_groups):</span>
  <span class="s2">if </span><span class="s1">axis_index_groups </span><span class="s2">is not None</span><span class="s1">: </span><span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s2">return </span><span class="s1">in_rep - {axis_name}  </span><span class="s0"># removes replication</span>

<span class="s1">@register_rule(lax_parallel.axis_index_p)</span>
<span class="s2">def </span><span class="s1">_axis_index_rule(mesh</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">axis_name):</span>
  <span class="s1">axis_name = (axis_name</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if not </span><span class="s1">isinstance(axis_name</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">else </span><span class="s1">axis_name</span>
  <span class="s2">return </span><span class="s1">set(mesh.shape) - set(axis_name)</span>

<span class="s1">@register_rule(pjit.pjit_p)</span>
<span class="s2">def </span><span class="s1">_pjit_rule(mesh</span><span class="s2">, </span><span class="s1">*in_rep</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">**kwargs):</span>
  <span class="s2">return </span><span class="s1">_output_rep(mesh</span><span class="s2">, </span><span class="s1">jaxpr.jaxpr</span><span class="s2">, </span><span class="s1">in_rep)</span>

<span class="s1">@register_rule(debugging.debug_callback_p)</span>
<span class="s2">def </span><span class="s1">_debug_callback_rule(mesh</span><span class="s2">, </span><span class="s1">*in_rep</span><span class="s2">, </span><span class="s1">**_):</span>
  <span class="s2">return </span><span class="s1">[]</span>

<span class="s0"># Batching</span>

<span class="s2">def </span><span class="s1">_shard_map_batch(</span>
    <span class="s1">trace: batching.BatchTrace</span><span class="s2">, </span><span class="s1">prim: core.Primitive</span><span class="s2">, </span><span class="s1">fun: lu.WrappedFun</span><span class="s2">,</span>
    <span class="s1">in_tracers: Sequence[batching.BatchTracer]</span><span class="s2">, </span><span class="s1">mesh: Mesh</span><span class="s2">,</span>
    <span class="s1">in_names: Tuple[AxisNames</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">,</span>
    <span class="s1">out_names_thunk: Callable[[]</span><span class="s2">, </span><span class="s1">Tuple[AxisNames</span><span class="s2">, </span><span class="s1">...]]</span><span class="s2">,</span>
    <span class="s1">check_rep: bool) -&gt; Sequence[batching.BatchTracer]:</span>
  <span class="s1">in_vals</span><span class="s2">, </span><span class="s1">in_dims = unzip2((t.val</span><span class="s2">, </span><span class="s1">t.batch_dim) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">in_tracers)</span>
  <span class="s2">if </span><span class="s1">all(bdim </span><span class="s2">is </span><span class="s1">batching.not_mapped </span><span class="s2">for </span><span class="s1">bdim </span><span class="s2">in </span><span class="s1">in_dims):</span>
    <span class="s2">return </span><span class="s1">prim.bind(fun</span><span class="s2">, </span><span class="s1">*in_vals</span><span class="s2">, </span><span class="s1">mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=in_names</span><span class="s2">,</span>
                     <span class="s1">out_names_thunk=out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
  <span class="s2">if </span><span class="s1">any(isinstance(d</span><span class="s2">, </span><span class="s1">batching.ConcatAxis) </span><span class="s2">for </span><span class="s1">d </span><span class="s2">in </span><span class="s1">in_dims):</span>
    <span class="s2">raise </span><span class="s1">NotImplementedError</span>
  <span class="s1">fun</span><span class="s2">, </span><span class="s1">out_dims = batching.batch_subtrace(fun</span><span class="s2">, </span><span class="s1">trace.main</span><span class="s2">, </span><span class="s1">tuple(in_dims))</span>
  <span class="s1">new_in_names = [{ax + (d </span><span class="s2">is not </span><span class="s1">batching.not_mapped </span><span class="s2">and </span><span class="s1">d &lt;= ax): names[ax]  </span><span class="s0"># type: ignore</span>
                   <span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">names} </span><span class="s2">for </span><span class="s1">names</span><span class="s2">, </span><span class="s1">d </span><span class="s2">in </span><span class="s1">zip(in_names</span><span class="s2">, </span><span class="s1">in_dims)]</span>
  <span class="s1">spmd_axis_name = trace.spmd_axis_name</span>
  <span class="s2">if </span><span class="s1">spmd_axis_name </span><span class="s2">is not None</span><span class="s1">:</span>
    <span class="s1">new_in_names = [{**ns</span><span class="s2">, </span><span class="s1">d:spmd_axis_name} </span><span class="s2">if </span><span class="s1">d </span><span class="s2">is not </span><span class="s1">batching.not_mapped  </span><span class="s0"># type: ignore</span>
                    <span class="s2">else </span><span class="s1">ns </span><span class="s2">for </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">d </span><span class="s2">in </span><span class="s1">zip(new_in_names</span><span class="s2">, </span><span class="s1">in_dims)]</span>
  <span class="s1">@as_hashable_function(closure=out_names_thunk)</span>
  <span class="s2">def </span><span class="s1">new_out_names_thunk():</span>
    <span class="s1">out_names = out_names_thunk()</span>
    <span class="s1">out_names_ = [{ax + (d </span><span class="s2">is not </span><span class="s1">batching.not_mapped </span><span class="s2">and </span><span class="s1">d &lt;= ax): names[ax]</span>
                   <span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">names} </span><span class="s2">for </span><span class="s1">names</span><span class="s2">, </span><span class="s1">d </span><span class="s2">in </span><span class="s1">zip(out_names</span><span class="s2">, </span><span class="s1">out_dims())]</span>
    <span class="s2">if </span><span class="s1">spmd_axis_name </span><span class="s2">is not None</span><span class="s1">:</span>
      <span class="s1">out_names_ = [{**ns</span><span class="s2">, </span><span class="s1">d:spmd_axis_name} </span><span class="s2">if </span><span class="s1">d </span><span class="s2">is not </span><span class="s1">batching.not_mapped</span>
                    <span class="s2">else </span><span class="s1">ns </span><span class="s2">for </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">d </span><span class="s2">in </span><span class="s1">zip(out_names_</span><span class="s2">, </span><span class="s1">out_dims())]</span>
    <span class="s2">return </span><span class="s1">out_names_</span>

  <span class="s1">new_params = dict(mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=new_in_names</span><span class="s2">,</span>
                    <span class="s1">out_names_thunk=new_out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
  <span class="s1">out_vals = prim.bind(fun</span><span class="s2">, </span><span class="s1">*in_vals</span><span class="s2">, </span><span class="s1">**new_params)</span>
  <span class="s1">make_tracer = partial(batching.BatchTracer</span><span class="s2">, </span><span class="s1">trace</span><span class="s2">,</span>
                        <span class="s1">source_info=source_info_util.current())</span>
  <span class="s2">return </span><span class="s1">map(make_tracer</span><span class="s2">, </span><span class="s1">out_vals</span><span class="s2">, </span><span class="s1">out_dims())</span>
<span class="s1">batching.BatchTrace.process_shard_map = _shard_map_batch</span>

<span class="s0"># Autodiff</span>

<span class="s2">def </span><span class="s1">_shard_map_jvp(trace</span><span class="s2">, </span><span class="s1">shard_map_p</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">tracers</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">,</span>
                   <span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep):</span>
  <span class="s1">primals</span><span class="s2">, </span><span class="s1">tangents = unzip2((t.primal</span><span class="s2">, </span><span class="s1">t.tangent) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tracers)</span>
  <span class="s1">which_nz = [     type(t) </span><span class="s2">is not </span><span class="s1">ad.Zero           </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tangents]</span>
  <span class="s1">tangents = [t </span><span class="s2">if </span><span class="s1">type(t) </span><span class="s2">is not </span><span class="s1">ad.Zero </span><span class="s2">else None for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tangents]</span>
  <span class="s1">args</span><span class="s2">, </span><span class="s1">in_tree = tree_flatten((primals</span><span class="s2">, </span><span class="s1">tangents))</span>
  <span class="s1">f_jvp = ad.jvp_subtrace(f</span><span class="s2">, </span><span class="s1">trace.main)</span>
  <span class="s1">f_jvp</span><span class="s2">, </span><span class="s1">which_nz_out = ad.nonzero_tangent_outputs(f_jvp)</span>
  <span class="s1">tangent_in_names = [ax </span><span class="s2">for </span><span class="s1">ax</span><span class="s2">, </span><span class="s1">nz </span><span class="s2">in </span><span class="s1">zip(in_names</span><span class="s2">, </span><span class="s1">which_nz) </span><span class="s2">if </span><span class="s1">nz]</span>

  <span class="s1">@as_hashable_function(closure=out_names_thunk)</span>
  <span class="s2">def </span><span class="s1">new_out_names_thunk():</span>
    <span class="s1">out_ax = out_names_thunk()</span>
    <span class="s2">return </span><span class="s1">(*out_ax</span><span class="s2">, </span><span class="s1">*(ax </span><span class="s2">for </span><span class="s1">ax</span><span class="s2">, </span><span class="s1">nz </span><span class="s2">in </span><span class="s1">zip(out_ax</span><span class="s2">, </span><span class="s1">which_nz_out()) </span><span class="s2">if </span><span class="s1">nz))</span>
  <span class="s1">params = dict(mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=(*in_names</span><span class="s2">, </span><span class="s1">*tangent_in_names)</span><span class="s2">,</span>
                <span class="s1">out_names_thunk=new_out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
  <span class="s1">f_jvp</span><span class="s2">, </span><span class="s1">out_tree = ad.traceable(f_jvp</span><span class="s2">, </span><span class="s1">in_tree)</span>
  <span class="s1">result = shard_map_p.bind(f_jvp</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**params)</span>
  <span class="s1">primal_out</span><span class="s2">, </span><span class="s1">tangent_out = tree_unflatten(out_tree()</span><span class="s2">, </span><span class="s1">result)</span>
  <span class="s1">tangent_out = [ad.Zero(core.get_aval(p).at_least_vspace()) </span><span class="s2">if </span><span class="s1">t </span><span class="s2">is None else </span><span class="s1">t</span>
                 <span class="s2">for </span><span class="s1">p</span><span class="s2">, </span><span class="s1">t </span><span class="s2">in </span><span class="s1">zip(primal_out</span><span class="s2">, </span><span class="s1">tangent_out)]</span>
  <span class="s2">return </span><span class="s1">[ad.JVPTracer(trace</span><span class="s2">, </span><span class="s1">p</span><span class="s2">, </span><span class="s1">t) </span><span class="s2">for </span><span class="s1">p</span><span class="s2">, </span><span class="s1">t </span><span class="s2">in </span><span class="s1">zip(primal_out</span><span class="s2">, </span><span class="s1">tangent_out)]</span>
<span class="s1">ad.JVPTrace.process_shard_map = _shard_map_jvp</span>

<span class="s2">def </span><span class="s1">_shard_map_jvp_post_process(trace</span><span class="s2">, </span><span class="s1">out_tracers</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">,</span>
                                <span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep):</span>
  <span class="s2">del </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep</span>
  <span class="s1">primals</span><span class="s2">, </span><span class="s1">tangents = unzip2((t.primal</span><span class="s2">, </span><span class="s1">t.tangent) </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">out_tracers)</span>
  <span class="s1">out</span><span class="s2">, </span><span class="s1">treedef = tree_flatten((primals</span><span class="s2">, </span><span class="s1">tangents))</span>
  <span class="s1">tangents_nz = [type(t) </span><span class="s2">is not </span><span class="s1">ad.Zero </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tangents]</span>
  <span class="s1">m = trace.main</span>
  <span class="s2">def </span><span class="s1">todo(x):</span>
    <span class="s1">primals</span><span class="s2">, </span><span class="s1">tangents = tree_unflatten(treedef</span><span class="s2">, </span><span class="s1">x)</span>
    <span class="s2">return </span><span class="s1">map(partial(ad.JVPTracer</span><span class="s2">, </span><span class="s1">m.with_cur_sublevel())</span><span class="s2">, </span><span class="s1">primals</span><span class="s2">, </span><span class="s1">tangents)</span>
  <span class="s2">def </span><span class="s1">out_names_transform(out_names):</span>
    <span class="s2">return </span><span class="s1">(*out_names</span><span class="s2">, </span><span class="s1">*(n </span><span class="s2">for </span><span class="s1">n</span><span class="s2">, </span><span class="s1">nz </span><span class="s2">in </span><span class="s1">zip(out_names</span><span class="s2">, </span><span class="s1">tangents_nz) </span><span class="s2">if </span><span class="s1">nz))</span>
  <span class="s2">return </span><span class="s1">out</span><span class="s2">, </span><span class="s1">(todo</span><span class="s2">, </span><span class="s1">out_names_transform)</span>
<span class="s1">ad.JVPTrace.post_process_shard_map = _shard_map_jvp_post_process</span>

<span class="s2">def </span><span class="s1">_shard_map_partial_eval(trace</span><span class="s2">, </span><span class="s1">shard_map_p</span><span class="s2">, </span><span class="s1">f</span><span class="s2">, </span><span class="s1">tracers</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">,</span>
                            <span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep):</span>
  <span class="s1">in_pvals = [t.pval </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tracers]</span>
  <span class="s1">in_knowns</span><span class="s2">, </span><span class="s1">in_avals</span><span class="s2">, </span><span class="s1">in_consts = pe.partition_pvals(in_pvals)</span>
  <span class="s1">unk_in_names</span><span class="s2">, </span><span class="s1">known_in_names = pe.partition_list(in_knowns</span><span class="s2">, </span><span class="s1">in_names)</span>
  <span class="s1">in_avals_sharded = map(partial(_shard_aval</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">unk_in_names</span><span class="s2">, </span><span class="s1">in_avals)</span>
  <span class="s1">f = pe.trace_to_subjaxpr_nounits(f</span><span class="s2">, </span><span class="s1">trace.main</span><span class="s2">, False</span><span class="s1">)</span>
  <span class="s1">f = _promote_scalar_residuals(f)</span>
  <span class="s1">f_known</span><span class="s2">, </span><span class="s1">aux = pe.partial_eval_wrapper_nounits(</span>
      <span class="s1">f</span><span class="s2">, </span><span class="s1">(*in_knowns</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(*in_avals_sharded</span><span class="s2">,</span><span class="s1">))</span>

  <span class="s1">@as_hashable_function(closure=out_names_thunk)</span>
  <span class="s2">def </span><span class="s1">known_out_names():</span>
    <span class="s1">out_knowns</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">_ = aux()</span>
    <span class="s1">_</span><span class="s2">, </span><span class="s1">out_known_names = pe.partition_list(out_knowns</span><span class="s2">, </span><span class="s1">out_names_thunk())</span>
    <span class="s2">assert not </span><span class="s1">any(</span><span class="s2">not </span><span class="s1">v.aval.shape </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">jaxpr.constvars)</span>
    <span class="s1">res_names = ({</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}</span><span class="s2">,</span><span class="s1">) * len(jaxpr.constvars)</span>
    <span class="s2">return </span><span class="s1">(*out_known_names</span><span class="s2">, </span><span class="s1">*res_names)</span>

  <span class="s1">known_params = dict(mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=(*known_in_names</span><span class="s2">,</span><span class="s1">)</span><span class="s2">,</span>
                      <span class="s1">out_names_thunk=known_out_names</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
  <span class="s1">out = shard_map_p.bind(f_known</span><span class="s2">, </span><span class="s1">*in_consts</span><span class="s2">, </span><span class="s1">**known_params)</span>
  <span class="s1">out_knowns</span><span class="s2">, </span><span class="s1">out_avals_sharded</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">env = aux()</span>
  <span class="s1">out_consts</span><span class="s2">, </span><span class="s1">res = pe.split_list(out</span><span class="s2">, </span><span class="s1">[len(out) - len(jaxpr.constvars)])</span>
  <span class="s2">with </span><span class="s1">core.extend_axis_env_nd(mesh.shape.items()):</span>
    <span class="s1">jaxpr = pe.convert_constvars_jaxpr(jaxpr)</span>
  <span class="s1">unk_out_names</span><span class="s2">, </span><span class="s1">_ = pe.partition_list(out_knowns</span><span class="s2">, </span><span class="s1">out_names_thunk())</span>
  <span class="s1">unk_in_names = (({</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}</span><span class="s2">,</span><span class="s1">) * len(res) + ({}</span><span class="s2">,</span><span class="s1">) * len(env)</span>
                      <span class="s1">+ (*unk_in_names</span><span class="s2">,</span><span class="s1">))</span>
  <span class="s1">const_tracers = map(trace.new_instantiated_const</span><span class="s2">, </span><span class="s1">res)</span>
  <span class="s1">env_tracers = map(trace.full_raise</span><span class="s2">, </span><span class="s1">env)</span>
  <span class="s1">unk_arg_tracers = [t </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tracers </span><span class="s2">if not </span><span class="s1">t.is_known()]</span>
  <span class="s1">unk_params = dict(mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=unk_in_names</span><span class="s2">,</span>
                    <span class="s1">out_names=unk_out_names</span><span class="s2">, </span><span class="s1">jaxpr=jaxpr</span><span class="s2">, </span><span class="s1">check_rep=</span><span class="s2">False</span><span class="s1">)</span>
  <span class="s1">out_avals = map(partial(_unshard_aval</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">unk_out_names</span><span class="s2">, </span><span class="s1">out_avals_sharded)</span>
  <span class="s1">out_tracers = [pe.JaxprTracer(trace</span><span class="s2">, </span><span class="s1">pe.PartialVal.unknown(a)</span><span class="s2">, None</span><span class="s1">)</span>
                 <span class="s2">for </span><span class="s1">a </span><span class="s2">in </span><span class="s1">out_avals]</span>
  <span class="s1">eqn = pe.new_eqn_recipe((*const_tracers</span><span class="s2">, </span><span class="s1">*env_tracers</span><span class="s2">, </span><span class="s1">*unk_arg_tracers)</span><span class="s2">,  </span><span class="s0"># type: ignore[arg-type]</span>
                          <span class="s1">out_tracers</span><span class="s2">, </span><span class="s1">shard_map_p</span><span class="s2">, </span><span class="s1">unk_params</span><span class="s2">,</span>
                          <span class="s1">jaxpr.effects</span><span class="s2">, </span><span class="s1">source_info_util.current())</span>
  <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">out_tracers: t.recipe = eqn</span>
  <span class="s2">return </span><span class="s1">pe.merge_lists(out_knowns</span><span class="s2">, </span><span class="s1">out_tracers</span><span class="s2">, </span><span class="s1">out_consts)</span>
<span class="s1">pe.JaxprTrace.process_shard_map = _shard_map_partial_eval</span>

<span class="s2">def </span><span class="s1">_shard_map_partial_eval_post_process(</span>
    <span class="s1">trace</span><span class="s2">, </span><span class="s1">tracers</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep):</span>
  <span class="s2">del </span><span class="s1">check_rep</span>
  <span class="s1">unk_tracers = [t </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tracers </span><span class="s2">if not </span><span class="s1">t.is_known()]</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">res</span><span class="s2">, </span><span class="s1">env = pe.tracers_to_jaxpr([]</span><span class="s2">, </span><span class="s1">unk_tracers)</span>
  <span class="s1">out_knowns</span><span class="s2">, </span><span class="s1">out_avals_</span><span class="s2">, </span><span class="s1">consts = pe.partition_pvals([t.pval </span><span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">tracers])</span>
  <span class="s1">out = [*consts</span><span class="s2">, </span><span class="s1">*res]</span>
  <span class="s1">main = trace.main</span>
  <span class="s2">with </span><span class="s1">core.extend_axis_env_nd(mesh.shape.items()):</span>
    <span class="s1">jaxpr_ = pe.convert_constvars_jaxpr(jaxpr)</span>

  <span class="s2">def </span><span class="s1">todo(out):</span>
    <span class="s1">trace = main.with_cur_sublevel()</span>
    <span class="s1">out_consts</span><span class="s2">, </span><span class="s1">res = pe.split_list(out</span><span class="s2">, </span><span class="s1">[len(out) - len(jaxpr.constvars)])</span>
    <span class="s1">const_tracers = map(trace.new_instantiated_const</span><span class="s2">, </span><span class="s1">res)</span>
    <span class="s1">env_tracers = map(trace.full_raise</span><span class="s2">, </span><span class="s1">env)</span>

    <span class="s1">staged_in_names = ({</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}</span><span class="s2">,</span><span class="s1">) * len(res) + ({}</span><span class="s2">,</span><span class="s1">) * len(env)</span>
    <span class="s1">staged_params = dict(jaxpr=jaxpr_</span><span class="s2">, </span><span class="s1">mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=staged_in_names</span><span class="s2">,</span>
                         <span class="s1">out_names=(*out_names_unknown</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, </span><span class="s1">check_rep=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s1">out_avals = map(partial(_unshard_aval</span><span class="s2">, </span><span class="s1">mesh)</span><span class="s2">, </span><span class="s1">out_names_unknown</span><span class="s2">, </span><span class="s1">out_avals_)</span>
    <span class="s1">out_tracers = [pe.JaxprTracer(trace</span><span class="s2">, </span><span class="s1">pe.PartialVal.unknown(a)</span><span class="s2">, None</span><span class="s1">)</span>
                   <span class="s2">for </span><span class="s1">a </span><span class="s2">in </span><span class="s1">out_avals]</span>
    <span class="s1">name_stack = trace._current_truncated_name_stack()</span>
    <span class="s1">source = source_info_util.current().replace(name_stack=name_stack)</span>
    <span class="s1">eqn = pe.new_eqn_recipe((*const_tracers</span><span class="s2">, </span><span class="s1">*env_tracers)</span><span class="s2">, </span><span class="s1">out_tracers</span><span class="s2">,</span>
                            <span class="s1">shard_map_p</span><span class="s2">, </span><span class="s1">staged_params</span><span class="s2">, </span><span class="s1">jaxpr.effects</span><span class="s2">, </span><span class="s1">source)</span>
    <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">out_tracers: t.recipe = eqn</span>
    <span class="s2">return </span><span class="s1">merge_lists(out_knowns</span><span class="s2">, </span><span class="s1">out_tracers</span><span class="s2">, </span><span class="s1">out_consts)</span>

  <span class="s2">def </span><span class="s1">out_names_transform(out_names):</span>
    <span class="s2">nonlocal </span><span class="s1">out_names_unknown</span>
    <span class="s1">out_names_unknown</span><span class="s2">, </span><span class="s1">out_names_known = partition_list(out_knowns</span><span class="s2">, </span><span class="s1">out_names)</span>
    <span class="s2">return </span><span class="s1">(*out_names_known</span><span class="s2">,</span><span class="s1">) + ({</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}</span><span class="s2">,</span><span class="s1">) * len(jaxpr.constvars)</span>
  <span class="s1">out_names_unknown: Optional[list] = </span><span class="s2">None</span>

  <span class="s2">return </span><span class="s1">out</span><span class="s2">, </span><span class="s1">(todo</span><span class="s2">, </span><span class="s1">out_names_transform)</span>
<span class="s1">pe.JaxprTrace.post_process_shard_map = _shard_map_partial_eval_post_process</span>

<span class="s1">@lu.transformation</span>
<span class="s2">def </span><span class="s1">_promote_scalar_residuals(*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">(out_pvals</span><span class="s2">, </span><span class="s1">out_consts</span><span class="s2">, </span><span class="s1">env) = </span><span class="s2">yield </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwargs</span>
  <span class="s1">which_scalar = [isinstance(v.aval</span><span class="s2">, </span><span class="s1">core.ShapedArray) </span><span class="s2">and not </span><span class="s1">v.aval.shape</span>
                  <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">jaxpr.constvars]</span>
  <span class="s1">out_consts_ = [jax.lax.broadcast(x</span><span class="s2">, </span><span class="s1">(</span><span class="s4">1</span><span class="s2">,</span><span class="s1">)) </span><span class="s2">if </span><span class="s1">scalar </span><span class="s2">else </span><span class="s1">x</span>
                 <span class="s2">for </span><span class="s1">x</span><span class="s2">, </span><span class="s1">scalar </span><span class="s2">in </span><span class="s1">zip(out_consts</span><span class="s2">, </span><span class="s1">which_scalar)]</span>

  <span class="s1">@lu.wrap_init</span>
  <span class="s2">def </span><span class="s1">fun(*args):</span>
    <span class="s1">out_consts = [x.reshape(*x.shape[</span><span class="s4">1</span><span class="s1">:]) </span><span class="s2">if </span><span class="s1">scalar </span><span class="s2">else </span><span class="s1">x</span>
                  <span class="s2">for </span><span class="s1">x</span><span class="s2">, </span><span class="s1">scalar </span><span class="s2">in </span><span class="s1">zip(out_consts_</span><span class="s2">, </span><span class="s1">which_scalar)]</span>
    <span class="s2">return </span><span class="s1">core.eval_jaxpr(jaxpr</span><span class="s2">, </span><span class="s1">out_consts</span><span class="s2">, </span><span class="s1">*args)</span>
  <span class="s1">in_avals = [v.aval </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">jaxpr.invars]</span>
  <span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">out_consts  = pe.trace_to_jaxpr_dynamic(fun</span><span class="s2">, </span><span class="s1">in_avals)</span>
  <span class="s2">yield </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">(out_pvals</span><span class="s2">, </span><span class="s1">out_consts</span><span class="s2">, </span><span class="s1">env)</span>

<span class="s2">def </span><span class="s1">_shard_map_transpose(out_cts</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">jaxpr</span><span class="s2">, </span><span class="s1">mesh</span><span class="s2">, </span><span class="s1">in_names</span><span class="s2">, </span><span class="s1">out_names</span><span class="s2">,</span>
                         <span class="s1">check_rep):</span>
  <span class="s1">mb_div = </span><span class="s2">lambda </span><span class="s1">x</span><span class="s2">, </span><span class="s1">y: x / y </span><span class="s2">if </span><span class="s1">y != </span><span class="s4">1 </span><span class="s2">else </span><span class="s1">x</span>
  <span class="s1">out_cts = [ad.Zero(_shard_aval(mesh</span><span class="s2">, </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">x.aval)) </span><span class="s2">if </span><span class="s1">type(x) </span><span class="s2">is </span><span class="s1">ad.Zero</span>
             <span class="s2">else </span><span class="s1">mb_div(x</span><span class="s2">, </span><span class="s1">math.prod(map(mesh.shape.get</span><span class="s2">, </span><span class="s1">_unmentioned(mesh</span><span class="s2">, </span><span class="s1">ns))))</span>
             <span class="s2">for </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">zip(out_names</span><span class="s2">, </span><span class="s1">out_cts)]</span>
  <span class="s1">args = [x </span><span class="s2">if </span><span class="s1">type(x) </span><span class="s2">is not </span><span class="s1">ad.UndefinedPrimal </span><span class="s2">else</span>
          <span class="s1">ad.UndefinedPrimal(_shard_aval(mesh</span><span class="s2">, </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">x.aval))</span>
          <span class="s2">for </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">zip(in_names</span><span class="s2">, </span><span class="s1">args)]</span>
  <span class="s1">all_args</span><span class="s2">, </span><span class="s1">in_tree = tree_flatten((out_cts</span><span class="s2">, </span><span class="s1">args))</span>

  <span class="s1">@lu.wrap_init</span>
  <span class="s2">def </span><span class="s1">fun_trans(out_cts</span><span class="s2">, </span><span class="s1">args):</span>
    <span class="s1">res</span><span class="s2">, </span><span class="s1">undefs = partition_list(map(ad.is_undefined_primal</span><span class="s2">, </span><span class="s1">args)</span><span class="s2">, </span><span class="s1">args)</span>
    <span class="s1">jaxpr_known</span><span class="s2">, </span><span class="s1">jaxpr_unknown</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = pe.partial_eval_jaxpr_nounits(</span>
        <span class="s1">pe.close_jaxpr(jaxpr)</span><span class="s2">, </span><span class="s1">map(ad.is_undefined_primal</span><span class="s2">, </span><span class="s1">args)</span><span class="s2">, False</span><span class="s1">)</span>
    <span class="s1">res_reshaped = core.jaxpr_as_fun(jaxpr_known)(*res)</span>
    <span class="s1">out = ad.backward_pass(</span>
        <span class="s1">jaxpr_unknown.jaxpr</span><span class="s2">, </span><span class="s1">()</span><span class="s2">, False, </span><span class="s1">()</span><span class="s2">, </span><span class="s1">(*res_reshaped</span><span class="s2">, </span><span class="s1">*undefs)</span><span class="s2">, </span><span class="s1">out_cts</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">[ad.Zero(_unshard_aval(mesh</span><span class="s2">, </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">x.aval)) </span><span class="s2">if </span><span class="s1">type(x) </span><span class="s2">is </span><span class="s1">ad.Zero</span>
            <span class="s2">else </span><span class="s1">jax.lax.psum(x</span><span class="s2">, </span><span class="s1">tuple(_unmentioned(mesh</span><span class="s2">, </span><span class="s1">ns)))</span>
            <span class="s2">for </span><span class="s1">ns</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">zip(in_names</span><span class="s2">, </span><span class="s1">out)]</span>

  <span class="s1">fun_trans</span><span class="s2">, </span><span class="s1">nz_arg_cts = ad.nonzero_outputs(fun_trans)</span>
  <span class="s1">fun_trans_flat</span><span class="s2">, </span><span class="s1">out_tree = flatten_fun_nokwargs(fun_trans</span><span class="s2">, </span><span class="s1">in_tree)</span>

  <span class="s1">new_in_names = \</span>
      <span class="s1">[n </span><span class="s2">for </span><span class="s1">n</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">zip(out_names</span><span class="s2">, </span><span class="s1">out_cts) </span><span class="s2">if </span><span class="s1">type(x) </span><span class="s2">is not </span><span class="s1">ad.Zero] + \</span>
      <span class="s1">[n </span><span class="s2">for </span><span class="s1">n</span><span class="s2">, </span><span class="s1">x </span><span class="s2">in </span><span class="s1">zip(in_names</span><span class="s2">, </span><span class="s1">args) </span><span class="s2">if </span><span class="s1">type(x) </span><span class="s2">is not </span><span class="s1">ad.UndefinedPrimal]</span>

  <span class="s2">def </span><span class="s1">new_out_names_thunk():</span>
    <span class="s2">return </span><span class="s1">tuple(names </span><span class="s2">for </span><span class="s1">names</span><span class="s2">, </span><span class="s1">nz </span><span class="s2">in </span><span class="s1">zip(in_names</span><span class="s2">, </span><span class="s1">nz_arg_cts()) </span><span class="s2">if </span><span class="s1">nz)</span>

  <span class="s1">out_flat = shard_map_p.bind(</span>
      <span class="s1">fun_trans_flat</span><span class="s2">, </span><span class="s1">*all_args</span><span class="s2">, </span><span class="s1">mesh=mesh</span><span class="s2">, </span><span class="s1">in_names=tuple(new_in_names)</span><span class="s2">,</span>
      <span class="s1">out_names_thunk=new_out_names_thunk</span><span class="s2">, </span><span class="s1">check_rep=check_rep)</span>
  <span class="s2">return </span><span class="s1">tree_unflatten(out_tree()</span><span class="s2">, </span><span class="s1">out_flat)</span>
<span class="s1">ad.primitive_transposes[shard_map_p] = _shard_map_transpose</span>

<span class="s2">def </span><span class="s1">_shard_map_axis_subst(params</span><span class="s2">, </span><span class="s1">subst</span><span class="s2">, </span><span class="s1">traverse):</span>
  <span class="s2">if </span><span class="s3">'jaxpr' </span><span class="s2">not in </span><span class="s1">params:</span>
    <span class="s2">return </span><span class="s1">params</span>
  <span class="s2">if not </span><span class="s1">traverse:</span>
    <span class="s2">return </span><span class="s1">params</span>
  <span class="s2">def </span><span class="s1">shadowed_subst(name):</span>
    <span class="s2">return </span><span class="s1">(name</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">params[</span><span class="s3">'mesh'</span><span class="s1">].shape </span><span class="s2">else </span><span class="s1">subst(name)</span>
  <span class="s2">with </span><span class="s1">core.extend_axis_env_nd(params[</span><span class="s3">'mesh'</span><span class="s1">].shape.items()):</span>
    <span class="s1">new_jaxpr = core.subst_axis_names_jaxpr(params[</span><span class="s3">'jaxpr'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">shadowed_subst)</span>
  <span class="s2">return </span><span class="s1">dict(params</span><span class="s2">, </span><span class="s1">jaxpr=new_jaxpr)</span>
<span class="s1">core.axis_substitution_rules[shard_map_p] = _shard_map_axis_subst</span>

<span class="s0"># Remat</span>

<span class="s2">def </span><span class="s1">_pe_custom_params(</span>
    <span class="s1">unks_in: List[bool]</span><span class="s2">, </span><span class="s1">inst_in: List[bool]</span><span class="s2">, </span><span class="s1">kept_outs_known: List[bool]</span><span class="s2">,</span>
    <span class="s1">kept_outs_staged: List[bool]</span><span class="s2">, </span><span class="s1">num_res: int</span><span class="s2">, </span><span class="s1">params_known: Dict[str</span><span class="s2">, </span><span class="s1">Any]</span><span class="s2">,</span>
    <span class="s1">params_staged: Dict[str</span><span class="s2">, </span><span class="s1">Any]</span>
  <span class="s1">) -&gt; Tuple[Dict[str</span><span class="s2">, </span><span class="s1">Any]</span><span class="s2">, </span><span class="s1">Dict[str</span><span class="s2">, </span><span class="s1">Any]]:</span>
  <span class="s0"># prune inputs to jaxpr_known according to unks_in</span>
  <span class="s1">mesh = params_known[</span><span class="s3">'mesh'</span><span class="s1">]</span>
  <span class="s1">in_names_known</span><span class="s2">, </span><span class="s1">_ = partition_list(unks_in</span><span class="s2">, </span><span class="s1">params_known[</span><span class="s3">'in_names'</span><span class="s1">])</span>
  <span class="s1">_</span><span class="s2">, </span><span class="s1">out_names_known = partition_list(kept_outs_known</span><span class="s2">, </span><span class="s1">params_known[</span><span class="s3">'out_names'</span><span class="s1">])</span>
  <span class="s1">out_names_known = out_names_known + [{</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}] * num_res</span>
  <span class="s1">new_params_known = dict(params_known</span><span class="s2">, </span><span class="s1">in_names=tuple(in_names_known)</span><span class="s2">,</span>
                          <span class="s1">out_names=tuple(out_names_known))</span>

  <span class="s0"># added num_res new inputs to jaxpr_staged, pruning according to inst_in</span>
  <span class="s1">_</span><span class="s2">, </span><span class="s1">in_names_staged = partition_list(inst_in</span><span class="s2">, </span><span class="s1">params_staged[</span><span class="s3">'in_names'</span><span class="s1">])</span>
  <span class="s1">in_names_staged = [{</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}] * num_res + in_names_staged</span>
  <span class="s1">_</span><span class="s2">, </span><span class="s1">out_names_staged = partition_list(kept_outs_staged</span><span class="s2">, </span><span class="s1">params_staged[</span><span class="s3">'out_names'</span><span class="s1">])</span>
  <span class="s1">new_params_staged = dict(params_staged</span><span class="s2">, </span><span class="s1">in_names=tuple(in_names_staged)</span><span class="s2">,</span>
                           <span class="s1">out_names=tuple(out_names_staged)</span><span class="s2">, </span><span class="s1">check_rep=</span><span class="s2">False</span><span class="s1">)</span>
  <span class="s2">return </span><span class="s1">new_params_known</span><span class="s2">, </span><span class="s1">new_params_staged</span>

<span class="s2">def </span><span class="s1">_pe_custom_res(params_known</span><span class="s2">, </span><span class="s1">aval):</span>
  <span class="s1">mesh = params_known[</span><span class="s3">'mesh'</span><span class="s1">]</span>
  <span class="s2">return </span><span class="s1">_unshard_aval(mesh</span><span class="s2">, </span><span class="s1">{</span><span class="s4">0</span><span class="s1">: (*mesh.axis_names</span><span class="s2">,</span><span class="s1">)}</span><span class="s2">, </span><span class="s1">aval)</span>

<span class="s2">def </span><span class="s1">_pe_custom_ctx(params):</span>
  <span class="s2">return </span><span class="s1">core.extend_axis_env_nd(params[</span><span class="s3">'mesh'</span><span class="s1">].shape.items())</span>

<span class="s1">pe.partial_eval_jaxpr_custom_rules[shard_map_p] = \</span>
    <span class="s1">partial(pe.call_partial_eval_custom_rule</span><span class="s2">, </span><span class="s3">'jaxpr'</span><span class="s2">, </span><span class="s1">_pe_custom_params</span><span class="s2">,</span>
            <span class="s1">res_aval=_pe_custom_res</span><span class="s2">, </span><span class="s1">ctx=_pe_custom_ctx)</span>
</pre>
</body>
</html>